{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#import kerastuner as kt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# only the number of maxima\n",
    "df_spectra_all=pd.read_csv(\"spectrum_energy_input_numberOfPeaks.csv\",index_col=[0])\n",
    "all_data = df_spectra_all[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\",\"no_of_max\"]]\n",
    "# drop all rows containing 0.5 to make it binary\n",
    "print(len(all_data))\n",
    "all_data = all_data.query('k6a1 != 0.5 & k6a2 != 0.5 & k11 != 0.5 & k12 != 0.5 & k9a1 != 0.5 & k9a2 != 0.5')\n",
    "print(len(all_data))\n",
    "#set the values to zero and one\n",
    "#labels = ['k6a1','k6a2','k11','k12','k9a1','k9a2']\n",
    "#[all_data[i].mask(all_data[i] == 0.25, 0, inplace=True) for i in labels]\n",
    "#[all_data[i].mask(all_data[i] == 0.75, 1, inplace=True) for i in labels]\n",
    "#print(all_data.head(10))\n",
    "data_train, data_test = train_test_split(all_data, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_A = []\n",
    "\n",
    "no_of_max = tf.feature_column.numeric_column(\"no_of_max\")\n",
    "#my_feature_layer_A = tf.keras.layers.DenseFeatures(no_of_max_bucket)\n",
    "feature_columns_A.append(no_of_max)\n",
    "k11 = tf.feature_column.numeric_column(\"k11\")\n",
    "feature_columns_A.append(k11)\n",
    "k12 = tf.feature_column.numeric_column(\"k12\")\n",
    "feature_columns_A.append(k12)\n",
    "k9a1 = tf.feature_column.numeric_column(\"k9a1\")\n",
    "feature_columns_A.append(k9a1)\n",
    "k9a2 = tf.feature_column.numeric_column(\"k9a2\")\n",
    "feature_columns_A.append(k9a2)\n",
    "\n",
    "my_feature_layer_A = tf.keras.layers.DenseFeatures(feature_columns_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "    \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    for m in list_of_metrics:\n",
    "        x = hist[m]\n",
    "        plt.plot(epochs[1:], x[1:], label=m)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for activation functions check https://keras.io/api/layers/activations/\n",
    "def create_model2(my_learning_rate, my_feature_layer,my_metrics,my_act_function = \"softmax\"):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(my_feature_layer)\n",
    "    layers=[20,12]\n",
    "    for layer in layers:\n",
    "        model.add(tf.keras.layers.Dense(units = layer, activation = my_act_function))\n",
    "    model.add(tf.keras.layers.Dense(units=6,name='Output', activation = 'softmax'))                             \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),                                       \n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=my_metrics)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, dataset, epochs, label_name,\n",
    "                batch_size=None,shuffle=True):\n",
    "    features = {name:np.array(value) for name, value in dataset.items()}\n",
    "    label=dataset[label_name].to_numpy()\n",
    "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=shuffle)\n",
    "  \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    return epochs, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51 samples\n",
      "Epoch 1/50\n",
      "51/51 [==============================] - 2s 47ms/sample - loss: 1.0833 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.5196\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0109 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7026\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 0s 825us/sample - loss: 1.0077 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7680\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 0s 952us/sample - loss: 1.0100 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7647\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0062 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8824\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0081 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7614\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 0s 962us/sample - loss: 1.0064 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.9510\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0070 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.9412\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0064 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8464\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0051 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.9216\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0057 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8399\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 939us/sample - loss: 1.0058 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.9216\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 864us/sample - loss: 1.0064 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8431\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 0s 748us/sample - loss: 1.0051 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7908\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 0s 902us/sample - loss: 1.0051 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.9314\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 0s 826us/sample - loss: 1.0042 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8660\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 1.0046 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.9314\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 0s 588us/sample - loss: 1.0017 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.9804\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 0s 576us/sample - loss: 1.0057 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7549\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 563us/sample - loss: 1.0011 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8366\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 0s 679us/sample - loss: 1.0008 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8170\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 0s 692us/sample - loss: 1.0000 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7386\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 0s 958us/sample - loss: 0.9989 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8366\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 0s 959us/sample - loss: 0.9972 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8268\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 0s 844us/sample - loss: 1.0022 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7712\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 0s 907us/sample - loss: 0.9974 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8170\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 774us/sample - loss: 0.9982 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8235\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 591us/sample - loss: 0.9958 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.8007\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 0s 583us/sample - loss: 0.9934 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7549\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 0s 625us/sample - loss: 0.9933 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7288\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 0s 550us/sample - loss: 0.9904 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7353\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 0s 627us/sample - loss: 0.9942 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7712\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 0s 675us/sample - loss: 0.9906 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7451\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 0s 911us/sample - loss: 0.9916 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6536\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 0s 923us/sample - loss: 0.9853 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7712\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 0s 868us/sample - loss: 0.9896 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7255\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 0s 799us/sample - loss: 0.9842 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6863\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 0s 1ms/sample - loss: 0.9871 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6765\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 0s 767us/sample - loss: 0.9849 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7353\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 0s 686us/sample - loss: 0.9831 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.7059\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 0s 712us/sample - loss: 0.9854 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6928\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 0s 892us/sample - loss: 0.9814 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 0s 621us/sample - loss: 0.9823 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6634\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 0s 607us/sample - loss: 0.9851 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6634\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 0s 578us/sample - loss: 0.9781 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6438\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 0s 573us/sample - loss: 0.9793 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6503\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 0s 571us/sample - loss: 0.9811 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6471\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 0s 597us/sample - loss: 0.9766 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6895\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 0s 576us/sample - loss: 0.9777 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6307\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 0s 580us/sample - loss: 0.9807 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.6438\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "epochs = 50\n",
    "batch_size = 12\n",
    "\n",
    "#specify the classification threshold\n",
    "classification_threshold = 0.15\n",
    "\n",
    "# Establish the metrics the model will measure.\n",
    "metric = [tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=classification_threshold),\n",
    "      tf.keras.metrics.Precision(thresholds=classification_threshold,name='precision'),\n",
    "      tf.keras.metrics.Recall(thresholds=classification_threshold,name='recall'),]\n",
    "\n",
    "label_name = [\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]\n",
    "#label_name = \"k6a1\"\n",
    "my_model = create_model2(learning_rate, my_feature_layer_A,metric,my_act_function=\"sigmoid\")\n",
    "epochs, hist = train_model(my_model, data_train, epochs, \n",
    "                          label_name, batch_size)\n",
    "# Plot a graph of the metric(s) vs. epochs.\n",
    "#list_of_metrics_to_plot = ['accuracy'] \n",
    "list_of_metrics_to_plot = ['accuracy', 'precision', 'recall'] \n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluate the new model against the test set:\n",
      "13/1 [======================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 852us/sample - loss: 0.8579 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.5513\n",
      "[[0.13655457 0.17596427 0.16525982 0.26237363 0.14800842 0.11183929]\n",
      " [0.14511466 0.15023044 0.232265   0.15708901 0.14270364 0.17259729]\n",
      " [0.16751677 0.17861402 0.15458232 0.16845924 0.16583404 0.16499366]\n",
      " [0.11532    0.14389776 0.29317856 0.24952509 0.09801608 0.10006253]\n",
      " [0.14162816 0.16428527 0.15988643 0.18285441 0.15954997 0.1917958 ]\n",
      " [0.13871638 0.17749234 0.164097   0.26046348 0.14813651 0.11109424]\n",
      " [0.17003666 0.18009403 0.1531572  0.16741246 0.1658885  0.16341114]\n",
      " [0.11378159 0.14277546 0.29444054 0.25028273 0.09788992 0.10082971]\n",
      " [0.13364643 0.12965111 0.26873028 0.11687359 0.11231484 0.23878384]\n",
      " [0.11719683 0.1335673  0.29624578 0.17835356 0.10361623 0.17102027]\n",
      " [0.1342342  0.14231853 0.2978224  0.16720517 0.10758606 0.1508336 ]\n",
      " [0.13364643 0.12965111 0.26873028 0.11687359 0.11231484 0.23878384]\n",
      " [0.13635063 0.14367722 0.29588076 0.16653635 0.10785013 0.14970483]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k6a1_test</th>\n",
       "      <th>k6a2_test</th>\n",
       "      <th>k11_test</th>\n",
       "      <th>k12_test</th>\n",
       "      <th>k9a1_test</th>\n",
       "      <th>k9a2_test</th>\n",
       "      <th>k6a1_hat</th>\n",
       "      <th>k6a2_hat</th>\n",
       "      <th>k11_hat</th>\n",
       "      <th>k12_hat</th>\n",
       "      <th>k9a1_hat</th>\n",
       "      <th>k9a2_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.136555</td>\n",
       "      <td>0.175964</td>\n",
       "      <td>0.165260</td>\n",
       "      <td>0.262374</td>\n",
       "      <td>0.148008</td>\n",
       "      <td>0.111839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.145115</td>\n",
       "      <td>0.150230</td>\n",
       "      <td>0.232265</td>\n",
       "      <td>0.157089</td>\n",
       "      <td>0.142704</td>\n",
       "      <td>0.172597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.167517</td>\n",
       "      <td>0.178614</td>\n",
       "      <td>0.154582</td>\n",
       "      <td>0.168459</td>\n",
       "      <td>0.165834</td>\n",
       "      <td>0.164994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.115320</td>\n",
       "      <td>0.143898</td>\n",
       "      <td>0.293179</td>\n",
       "      <td>0.249525</td>\n",
       "      <td>0.098016</td>\n",
       "      <td>0.100063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.141628</td>\n",
       "      <td>0.164285</td>\n",
       "      <td>0.159886</td>\n",
       "      <td>0.182854</td>\n",
       "      <td>0.159550</td>\n",
       "      <td>0.191796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k6a1_test  k6a2_test  k11_test  k12_test  k9a1_test  k9a2_test  k6a1_hat  \\\n",
       "0       0.75       0.75      0.25      0.75       0.25       0.25  0.136555   \n",
       "1       0.75       0.75      0.75      0.25       0.75       0.25  0.145115   \n",
       "2       0.25       0.25      0.25      0.25       0.25       0.25  0.167517   \n",
       "3       0.75       0.25      0.75      0.75       0.25       0.25  0.115320   \n",
       "4       0.25       0.25      0.25      0.75       0.25       0.75  0.141628   \n",
       "\n",
       "   k6a2_hat   k11_hat   k12_hat  k9a1_hat  k9a2_hat  \n",
       "0  0.175964  0.165260  0.262374  0.148008  0.111839  \n",
       "1  0.150230  0.232265  0.157089  0.142704  0.172597  \n",
       "2  0.178614  0.154582  0.168459  0.165834  0.164994  \n",
       "3  0.143898  0.293179  0.249525  0.098016  0.100063  \n",
       "4  0.164285  0.159886  0.182854  0.159550  0.191796  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = {name:np.array(value) for name, value in data_test.items()}\n",
    "label=data_test[label_name].to_numpy()\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "evaluation=my_model.evaluate(x = features, y = label, batch_size=batch_size)\n",
    "predicted = my_model.predict(features)\n",
    "print(predicted)\n",
    "df_test=pd.DataFrame(label,columns=[\"k6a1_test\",\"k6a2_test\",\"k11_test\",\"k12_test\",\"k9a1_test\",\"k9a2_test\"])\n",
    "#df_test=pd.DataFrame(label,columns=[\"k6a1_test\"])\n",
    "df_predict=pd.DataFrame(predicted,columns=[\"k6a1_hat\",\"k6a2_hat\",\"k11_hat\",\"k12_hat\",\"k9a1_hat\",\"k9a2_hat\"])\n",
    "#df_predict=pd.DataFrame(predicted,columns=[\"k6a1_hat\"])\n",
    "#df_test = df_test.round(0)\n",
    "#df_predict = df_predict.round(0)\n",
    "pd.concat([df_test,df_predict], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umbauen in ein echtes Klassifizierungsproblem\n",
    "\n",
    "see https://sebastianraschka.com/faq/docs/softmax_regression.html\n",
    "\n",
    "Wir haben für jede Konstante drei mögliche Werte: 0.25, 0.5 und 0.75 - das ist somit ein \"ternary\" (dreifaltiges?) Klassifikationsproblem. Die softmax Funktion am Ende des Modells gibt eine Wahrscheinlichkeit an, inwiefern das \"feature\" zu welcher Klasse gehört (prozentual). \n",
    "\n",
    "Ich würde mal anfangen und für k6a1 ein Modell bauen mit one-hot encoding für die drei möglichen Werte und als feature die Anzahl der Peaks. Das gleiche für ausschliesslich k6a2, k11, k12, k9a1, k9a2. Vermutlich wird das nicht so gut funktionieren weil die Information einfach nicht ausreichend ist. Da würde ich mal versuchen zu verstehen, welche Vorhersagen dir das Modell gibt, und dass du die Wahrscheinlichkeiten für die drei möglichen Klassen bekommst, für jedes Beispiel.\n",
    "\n",
    "Im zweiten Schritt würde ich dann andere Klassen-Kombinationen probieren:\n",
    "Klasse 1 - k6a1, k11, k9a1 \n",
    "Klasse 2 - k6a2, k12, k9a2 \n",
    "\n",
    "Sagen wir, die jeweiligen Werte liegen bei -1 (momentan 0.25), 0 (momentan 0.5), 1 (momentan 0.75). Die Summe aller Werte liegt damit zwischen -3 und +3.\n",
    "\n",
    "Dann wäre Fall A: sum(Klasse 1) < -1; Fall B: -1 < sum(Klasse 1) < 1; Fall C: sum(Klasse 1) > 1. Mit den Grenzen kann man etwas herumspielen; und das gleiche jeweils für Klasse 2.\n",
    "\n",
    "Oder vielleicht hast du noch andere Ideen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
