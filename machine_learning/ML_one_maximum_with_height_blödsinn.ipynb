{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>k6a1</th>\n",
       "      <th>k6a2</th>\n",
       "      <th>k11</th>\n",
       "      <th>k12</th>\n",
       "      <th>k9a1</th>\n",
       "      <th>k9a2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.019935</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.213</td>\n",
       "      <td>0.060488</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.020153</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.019641</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.220</td>\n",
       "      <td>0.060471</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.021991</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.021101</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0.213</td>\n",
       "      <td>0.060723</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.149</td>\n",
       "      <td>0.017403</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Energy  Intensity  k6a1  k6a2   k11   k12  k9a1  k9a2\n",
       "0     0.874   0.019935  0.25  0.25  0.25  0.25  0.25  0.25\n",
       "1     0.213   0.060488  0.25  0.25  0.25  0.25  0.25  0.50\n",
       "2     0.866   0.020153  0.25  0.25  0.25  0.25  0.25  0.75\n",
       "3     0.867   0.019641  0.25  0.25  0.25  0.25  0.50  0.25\n",
       "4     0.220   0.060471  0.25  0.25  0.25  0.25  0.50  0.50\n",
       "..      ...        ...   ...   ...   ...   ...   ...   ...\n",
       "674   0.868   0.021991  0.75  0.75  0.25  0.75  0.75  0.75\n",
       "675   0.865   0.021101  0.75  0.75  0.50  0.25  0.25  0.25\n",
       "676   0.213   0.060723  0.75  0.75  0.50  0.25  0.25  0.50\n",
       "677   0.868   0.019078  0.75  0.75  0.50  0.25  0.25  0.75\n",
       "678   0.149   0.017403  0.75  0.75  0.50  0.25  0.50  0.25\n",
       "\n",
       "[679 rows x 8 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spectra=pd.read_csv(\"spectrum_energy_intensity2.csv\",index_col=[0])\n",
    "df_spectra.head(-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_input=df_spectra[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]].to_numpy()\n",
    "numpy_energy_intensity=df_spectra[[\"Energy\",\"Intensity\"]].to_numpy()\n",
    "\n",
    "\n",
    "df_training=df_spectra.sample(frac=0.8,random_state=20)\n",
    "df_testing=df_spectra.drop(df_training.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_A = []\n",
    "\n",
    "k6a1 = tf.feature_column.numeric_column(\"k6a1\")\n",
    "feature_columns_A.append(k6a1)\n",
    "\n",
    "k6a2 = tf.feature_column.numeric_column(\"k6a2\")\n",
    "feature_columns_A.append(k6a2)\n",
    "\n",
    "k11 = tf.feature_column.numeric_column(\"k11\")\n",
    "feature_columns_A.append(k11)\n",
    "\n",
    "k12 = tf.feature_column.numeric_column(\"k12\")\n",
    "feature_columns_A.append(k12)\n",
    "\n",
    "k9a1 = tf.feature_column.numeric_column(\"k9a1\")\n",
    "feature_columns_A.append(k9a1)\n",
    "\n",
    "k9a2 = tf.feature_column.numeric_column(\"k9a2\")\n",
    "feature_columns_A.append(k9a2)\n",
    "\n",
    "my_feature_layer_A = tf.keras.layers.DenseFeatures(feature_columns_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the plot_the_loss_curve function.\n"
     ]
    }
   ],
   "source": [
    "#define the plotting function.\n",
    "\n",
    "def plot_the_loss_curve(epochs, mse,mse_test=0):\n",
    "    \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "\n",
    "    plt.plot(epochs, mse, label=\"Loss\")\n",
    "    if(mse_test!=0):\n",
    "        plt.plot(epochs,mse_test)\n",
    "    plt.legend()\n",
    "    plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
    "    plt.show()  \n",
    "\n",
    "print(\"Defined the plot_the_loss_curve function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate, my_feature_layer,unit_layer_list=[10,12],regulations=0.04):\n",
    "    \"\"\"Create and compile a regression model.\"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Add the layer containing the feature columns to the model.\n",
    "    model.add(my_feature_layer)\n",
    "\n",
    "    # Describe the topography of the model by calling the tf.keras.layers.Dense\n",
    "    # method once for each layer. We've specified the following arguments:\n",
    "    #   * units specifies the number of nodes in this layer.\n",
    "    #   * activation specifies the activation function (Rectified Linear Unit).\n",
    "    #   * name is just a string that can be useful when debugging.\n",
    "\n",
    "    # Define the first hidden layer with 10 nodes.   \n",
    "    for n in unit_layer_list:\n",
    "        print(n)\n",
    "        model.add(tf.keras.layers.Dense(units=n, activation='relu', \n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(regulations),name='Hidden'+str(n)))\n",
    "                \n",
    "   \n",
    "   \n",
    "\n",
    "    # Define the output layer.\n",
    "    model.add(tf.keras.layers.Dense(units=2,  \n",
    "                                    name='Output'))                              \n",
    "  \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multilabel_model(my_learning_rate, my_feature_layer,unit_layer_list=[10,12],regulations=0.04):\n",
    "    \"\"\"Create and compile a regression model.\"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Add the layer containing the feature columns to the model.\n",
    "    model.add(my_feature_layer)\n",
    "\n",
    "    # Describe the topography of the model by calling the tf.keras.layers.Dense\n",
    "    # method once for each layer. We've specified the following arguments:\n",
    "    #   * units specifies the number of nodes in this layer.\n",
    "    #   * activation specifies the activation function (Rectified Linear Unit).\n",
    "    #   * name is just a string that can be useful when debugging.\n",
    "\n",
    "    # Define the first hidden layer with 10 nodes.   \n",
    "    model.add(tf.keras.layers.Dense(20, input_dim=5, kernel_initializer='he_uniform', activation='relu'))\n",
    "    #outputlayer\n",
    "    model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, epochs, label_name,\n",
    "                batch_size=None):\n",
    "    \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "    # Split the dataset into features and label.\n",
    "    \n",
    "    print(dataset.items())\n",
    "\n",
    "    features = {name:np.array(value) for name, value in dataset.items()}\n",
    "    label = [np.array(features.pop(label)) for label in label_name]\n",
    "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                          epochs=epochs, shuffle=True) \n",
    "    \n",
    "   \n",
    "    # The list of epochs is stored separately from the rest of history.\n",
    "    epochs = history.epoch\n",
    "  \n",
    "    # To track the progression of training, gather a snapshot\n",
    "    # of the model's mean squared error at each epoch. \n",
    "    hist = pd.DataFrame(history.history)\n",
    "    mse = hist[\"mean_squared_error\"]\n",
    "\n",
    "    return epochs, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object DataFrame.items at 0x000001A6D2587EC8>\n",
      "Epoch 1/8000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:533 train_step  **\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:205 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1595 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4692 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:172 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((None, 2) vs (None, 1))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-edc3db88a18d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m epochs, mse = train_model(my_model, df_training, epochs_ini, \n\u001b[1;32m---> 14\u001b[1;33m                           label_name, batch_size)\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-125-39180821364a>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataset, epochs, label_name, batch_size)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     history = model.fit(x=features, y=label, batch_size=batch_size,\n\u001b[1;32m---> 12\u001b[1;33m                           epochs=epochs, shuffle=True) \n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    625\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 506\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2667\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:533 train_step  **\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:205 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1595 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4692 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:172 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((None, 2) vs (None, 1))\n"
     ]
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.0001\n",
    "epochs_ini = 8000\n",
    "batch_size = 500\n",
    "\n",
    "# Specify the label\n",
    "label_name = [\"Energy\",\"Intensity\"]\n",
    "\n",
    "#try different things:\n",
    "\n",
    "my_model = create_multilabel_model(learning_rate, my_feature_layer_A,unit_layer_list=[10,15,10],regulations=1e-7)\n",
    "\n",
    "epochs, mse = train_model(my_model, df_training, epochs_ini, \n",
    "                          label_name, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.37709868  0.36820948]\n",
      " [-0.49683225 -0.48805594]\n",
      " [-0.5092186  -0.5223993 ]\n",
      " [-0.49062806 -0.48549956]\n",
      " [ 0.43057132  0.42041242]\n",
      " [-0.4063732  -0.42487228]\n",
      " [-0.58303154 -0.6164681 ]\n",
      " [-0.52944577 -0.53274256]\n",
      " [-0.44129103 -0.4378969 ]\n",
      " [-0.4347006  -0.46810448]\n",
      " [ 0.27060664  0.29598427]\n",
      " [ 0.47858703  0.47076666]\n",
      " [-0.48137194 -0.5125185 ]\n",
      " [ 0.31988382  0.32947946]\n",
      " [-0.54751563 -0.47290266]\n",
      " [ 0.30206168  0.29654324]\n",
      " [ 0.26698768  0.29482174]\n",
      " [ 0.22406638  0.26966596]\n",
      " [ 0.3525566   0.3383478 ]\n",
      " [ 0.2903434   0.27980816]\n",
      " [-0.50131273 -0.51070666]\n",
      " [ 0.33987784  0.31987846]\n",
      " [-0.4298271  -0.40482557]\n",
      " [ 0.19293511  0.16845214]\n",
      " [ 0.18797994  0.18977809]\n",
      " [ 0.29798377  0.3206017 ]\n",
      " [ 0.21533239  0.14310014]\n",
      " [ 0.20442617  0.17751598]\n",
      " [ 0.30347002  0.3155415 ]\n",
      " [ 0.3580885   0.36838734]\n",
      " [ 0.36614776  0.37378192]\n",
      " [-0.49405807 -0.4940989 ]\n",
      " [ 0.38048363  0.38772702]\n",
      " [ 0.36828446  0.3656149 ]\n",
      " [ 0.2683159   0.22420526]\n",
      " [ 0.3131888   0.31936717]\n",
      " [-0.40545124 -0.41796976]\n",
      " [ 0.19008553  0.24393606]\n",
      " [ 0.4122932   0.38450766]\n",
      " [ 0.41388702  0.41528308]\n",
      " [ 0.28749     0.2768116 ]\n",
      " [ 0.24141824  0.19533825]\n",
      " [ 0.22099018  0.21780074]\n",
      " [ 0.29530704  0.28041077]\n",
      " [ 0.3482039   0.35363662]\n",
      " [-0.41789687 -0.4114682 ]\n",
      " [ 0.36191773  0.35164523]\n",
      " [ 0.38687658  0.37672985]\n",
      " [ 0.2886423   0.31716084]\n",
      " [ 0.35601962  0.3342029 ]\n",
      " [ 0.30731046  0.28046   ]\n",
      " [-0.44314355 -0.45205998]\n",
      " [ 0.34272552  0.3205757 ]\n",
      " [-0.5378555  -0.5228485 ]\n",
      " [ 0.3058002   0.33993316]\n",
      " [-0.45712113 -0.48027498]\n",
      " [ 0.3925736   0.42332935]\n",
      " [ 0.22203732  0.2531551 ]\n",
      " [ 0.3849262   0.37229252]\n",
      " [-0.45901918 -0.4541577 ]\n",
      " [-0.4135992  -0.4158005 ]\n",
      " [ 0.26923     0.27726114]\n",
      " [-0.3688295  -0.41127193]\n",
      " [ 0.35602927  0.34881556]\n",
      " [-0.45251054 -0.49113506]\n",
      " [ 0.33411026  0.3122121 ]\n",
      " [ 0.21214092  0.27028966]\n",
      " [-0.44809932 -0.47651196]\n",
      " [ 0.3499483   0.3445989 ]\n",
      " [ 0.38685548  0.43153954]\n",
      " [-0.56343246 -0.5041692 ]\n",
      " [ 0.31288242  0.32706106]\n",
      " [-0.41212875 -0.46182096]\n",
      " [ 0.329373    0.33924627]\n",
      " [-0.5257671  -0.472629  ]\n",
      " [ 0.39203072  0.43498504]\n",
      " [ 0.27362025  0.28517652]\n",
      " [ 0.21622956  0.21804976]\n",
      " [ 0.38056982  0.37248445]\n",
      " [ 0.42129135  0.41660523]\n",
      " [-0.41119385 -0.41553503]\n",
      " [ 0.32766116  0.32463682]\n",
      " [-0.4088813  -0.42656904]\n",
      " [ 0.2815374   0.25446808]\n",
      " [-0.44499654 -0.47997224]\n",
      " [ 0.226102    0.24368405]\n",
      " [ 0.2634015   0.25324476]\n",
      " [ 0.3966453   0.33891332]\n",
      " [-0.43880874 -0.49020427]\n",
      " [ 0.15941858  0.13285255]\n",
      " [-0.47889358 -0.46239227]\n",
      " [ 0.29519296  0.29881918]\n",
      " [ 0.40147758  0.3768822 ]\n",
      " [ 0.3771944   0.39958715]\n",
      " [ 0.19501555  0.18127716]\n",
      " [ 0.32178867  0.319085  ]\n",
      " [-0.521664   -0.51589763]\n",
      " [ 0.3395753   0.32299733]\n",
      " [ 0.34134722  0.350806  ]\n",
      " [ 0.30128706  0.31538284]\n",
      " [ 0.30021608  0.30544233]\n",
      " [ 0.25819397  0.2573712 ]\n",
      " [-0.55225396 -0.5084746 ]\n",
      " [-0.48161238 -0.50060034]\n",
      " [ 0.36720645  0.38602793]\n",
      " [-0.57649815 -0.5632595 ]\n",
      " [ 0.36782002  0.35814083]\n",
      " [-0.50410426 -0.4822324 ]\n",
      " [-0.5347239  -0.5064995 ]\n",
      " [ 0.21120548  0.19630706]\n",
      " [ 0.2312231   0.23434663]\n",
      " [ 0.29343963  0.28746164]\n",
      " [-0.43813056 -0.4767037 ]\n",
      " [-0.5581949  -0.49730676]\n",
      " [ 0.2832266   0.27605605]\n",
      " [ 0.34794974  0.35562456]\n",
      " [-0.40309185 -0.43676275]]\n",
      "[0.37709868, -0.49683225, -0.5092186, -0.49062806, 0.43057132]\n",
      "[0.36820948, -0.48805594, -0.5223993, -0.48549956, 0.42041242]\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0610 - mean_squared_error: 0.0610\n",
      "Intensity: [0.06102638319134712, 0.061023443937301636]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted1</th>\n",
       "      <th>predicted2</th>\n",
       "      <th>Reference Energy</th>\n",
       "      <th>Reference Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.377099</td>\n",
       "      <td>0.368209</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.021675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.496832</td>\n",
       "      <td>-0.488056</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>0.074461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.509219</td>\n",
       "      <td>-0.522399</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>0.076080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.490628</td>\n",
       "      <td>-0.485500</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>0.001645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430571</td>\n",
       "      <td>0.420412</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.063414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.406373</td>\n",
       "      <td>-0.424872</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>0.076080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.583032</td>\n",
       "      <td>-0.616468</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>0.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.529446</td>\n",
       "      <td>-0.532743</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>0.074461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.441291</td>\n",
       "      <td>-0.437897</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>0.001604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.434701</td>\n",
       "      <td>-0.468104</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>0.076485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.270607</td>\n",
       "      <td>0.295984</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.021682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.478587</td>\n",
       "      <td>0.470767</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.021680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.481372</td>\n",
       "      <td>-0.512519</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.189952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.319884</td>\n",
       "      <td>0.329479</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.143332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.547516</td>\n",
       "      <td>-0.472903</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>0.074420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.302062</td>\n",
       "      <td>0.296543</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.153311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.266988</td>\n",
       "      <td>0.294822</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.063408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.224066</td>\n",
       "      <td>0.269666</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.021377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.352557</td>\n",
       "      <td>0.338348</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.069937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.290343</td>\n",
       "      <td>0.279808</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.021779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.501313</td>\n",
       "      <td>-0.510707</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>0.073557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.339878</td>\n",
       "      <td>0.319878</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.022135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.429827</td>\n",
       "      <td>-0.404826</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>0.075473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.192935</td>\n",
       "      <td>0.168452</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.021878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.187980</td>\n",
       "      <td>0.189778</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.020157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.297984</td>\n",
       "      <td>0.320602</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.021310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.215332</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>-0.574</td>\n",
       "      <td>0.060490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.204426</td>\n",
       "      <td>0.177516</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.021139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.303470</td>\n",
       "      <td>0.315542</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.021377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.358088</td>\n",
       "      <td>0.368387</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>0.018372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.366148</td>\n",
       "      <td>0.373782</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>0.060535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.494058</td>\n",
       "      <td>-0.494099</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>0.001604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.380484</td>\n",
       "      <td>0.387727</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.069847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.368284</td>\n",
       "      <td>0.365615</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.069813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.268316</td>\n",
       "      <td>0.224205</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.021470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.313189</td>\n",
       "      <td>0.319367</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.020767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.405451</td>\n",
       "      <td>-0.417970</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>0.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.190086</td>\n",
       "      <td>0.243936</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.020767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.412293</td>\n",
       "      <td>0.384508</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.069629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.413887</td>\n",
       "      <td>0.415283</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.021714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.287490</td>\n",
       "      <td>0.276812</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.069445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.241418</td>\n",
       "      <td>0.195338</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.144756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.220990</td>\n",
       "      <td>0.217801</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.152887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.295307</td>\n",
       "      <td>0.280411</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.070662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.348204</td>\n",
       "      <td>0.353637</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.019689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.417897</td>\n",
       "      <td>-0.411468</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>0.076307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.361918</td>\n",
       "      <td>0.351645</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.068146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.386877</td>\n",
       "      <td>0.376730</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.021813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.288642</td>\n",
       "      <td>0.317161</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>0.059404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.356020</td>\n",
       "      <td>0.334203</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.020167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted1  predicted2  Reference Energy  Reference Intensity\n",
       "0     0.377099    0.368209             0.732             0.021675\n",
       "1    -0.496832   -0.488056            -0.632             0.074461\n",
       "2    -0.509219   -0.522399            -0.630             0.076080\n",
       "3    -0.490628   -0.485500            -0.756             0.001645\n",
       "4     0.430571    0.420412             0.176             0.063414\n",
       "5    -0.406373   -0.424872            -0.630             0.076080\n",
       "6    -0.583032   -0.616468            -0.630             0.076000\n",
       "7    -0.529446   -0.532743            -0.632             0.074461\n",
       "8    -0.441291   -0.437897            -0.756             0.001604\n",
       "9    -0.434701   -0.468104            -0.630             0.076485\n",
       "10    0.270607    0.295984             0.732             0.021682\n",
       "11    0.478587    0.470767             0.732             0.021680\n",
       "12   -0.481372   -0.512519            -0.428             0.189952\n",
       "13    0.319884    0.329479             0.924             0.143332\n",
       "14   -0.547516   -0.472903            -0.628             0.074420\n",
       "15    0.302062    0.296543             0.924             0.153311\n",
       "16    0.266988    0.294822             0.176             0.063408\n",
       "17    0.224066    0.269666             0.732             0.021377\n",
       "18    0.352557    0.338348             0.466             0.069937\n",
       "19    0.290343    0.279808             0.732             0.021779\n",
       "20   -0.501313   -0.510707            -0.632             0.073557\n",
       "21    0.339878    0.319878             0.732             0.022135\n",
       "22   -0.429827   -0.404826            -0.632             0.075473\n",
       "23    0.192935    0.168452             0.732             0.021878\n",
       "24    0.187980    0.189778             0.732             0.020157\n",
       "25    0.297984    0.320602             0.732             0.021310\n",
       "26    0.215332    0.143100            -0.574             0.060490\n",
       "27    0.204426    0.177516             0.730             0.021139\n",
       "28    0.303470    0.315542             0.732             0.021377\n",
       "29    0.358088    0.368387            -0.706             0.018372\n",
       "30    0.366148    0.373782            -0.572             0.060535\n",
       "31   -0.494058   -0.494099            -0.756             0.001604\n",
       "32    0.380484    0.387727             0.466             0.069847\n",
       "33    0.368284    0.365615             0.466             0.069813\n",
       "34    0.268316    0.224205             0.728             0.021470\n",
       "35    0.313189    0.319367             0.730             0.020767\n",
       "36   -0.405451   -0.417970            -0.630             0.076000\n",
       "37    0.190086    0.243936             0.730             0.020767\n",
       "38    0.412293    0.384508             0.468             0.069629\n",
       "39    0.413887    0.415283             0.732             0.021714\n",
       "40    0.287490    0.276812             0.182             0.069445\n",
       "41    0.241418    0.195338             0.922             0.144756\n",
       "42    0.220990    0.217801             0.924             0.152887\n",
       "43    0.295307    0.280411             0.470             0.070662\n",
       "44    0.348204    0.353637             0.734             0.019689\n",
       "45   -0.417897   -0.411468            -0.630             0.076307\n",
       "46    0.361918    0.351645             0.180             0.068146\n",
       "47    0.386877    0.376730             0.728             0.021813\n",
       "48    0.288642    0.317161            -0.586             0.059404\n",
       "49    0.356020    0.334203             0.732             0.020167"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = {name:np.array(value) for name, value in df_testing.items()}\n",
    "test_label = [np.array(test_features.pop(label)) for label in label_name]\n",
    "\n",
    "\n",
    "#print(test_label)\n",
    "example_mydata = df_testing.sample(frac=0.8,random_state=20)\n",
    "#run the evaluation\n",
    "# i checked and they should be correct\n",
    "example_features = {name:np.array(value) for name, value in example_mydata.items()}\n",
    "#print(example_features)\n",
    "\n",
    "predicted = 2*my_model.predict(example_features)-1\n",
    "\n",
    "#print(predicted)\n",
    "\n",
    "\n",
    "predicted=predicted.reshape(len(predicted),2)\n",
    "#print(predicted)\n",
    "predicted_1=[predicted[i][0] for i in range(len(predicted))]\n",
    "predicted_2=[predicted[i][1] for i in range(len(predicted))]\n",
    "\n",
    "\n",
    "print(predicted[:])\n",
    "print(predicted_1[:5])\n",
    "print(predicted_2[:5])\n",
    "\n",
    "exact_energy = example_mydata[\"Energy\"].to_numpy()*2-1\n",
    "exact_intensity = example_mydata[\"Intensity\"].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Intensity:\",my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size))\n",
    "\n",
    "df_compare=pd.DataFrame({\"predicted1\":predicted_1,\"predicted2\":predicted_2, \"Reference Energy\":exact_energy, \"Reference Intensity\":exact_intensity})\n",
    "\n",
    "#df_compare.plot.scatter(x=\"exact\", y=\"predicted\")\n",
    "df_compare.to_csv(\"first_test.csv\")\n",
    "df_compare.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>k6a1</th>\n",
       "      <th>k6a2</th>\n",
       "      <th>k11</th>\n",
       "      <th>k12</th>\n",
       "      <th>k9a1</th>\n",
       "      <th>k9a2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.019935</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.213</td>\n",
       "      <td>0.060488</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.020153</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.019641</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.220</td>\n",
       "      <td>0.060471</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.021991</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.021101</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>0.213</td>\n",
       "      <td>0.060723</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.149</td>\n",
       "      <td>0.017403</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Energy  Intensity  k6a1  k6a2   k11   k12  k9a1  k9a2\n",
       "0     0.874   0.019935  0.25  0.25  0.25  0.25  0.25  0.25\n",
       "1     0.213   0.060488  0.25  0.25  0.25  0.25  0.25  0.50\n",
       "2     0.866   0.020153  0.25  0.25  0.25  0.25  0.25  0.75\n",
       "3     0.867   0.019641  0.25  0.25  0.25  0.25  0.50  0.25\n",
       "4     0.220   0.060471  0.25  0.25  0.25  0.25  0.50  0.50\n",
       "..      ...        ...   ...   ...   ...   ...   ...   ...\n",
       "674   0.868   0.021991  0.75  0.75  0.25  0.75  0.75  0.75\n",
       "675   0.865   0.021101  0.75  0.75  0.50  0.25  0.25  0.25\n",
       "676   0.213   0.060723  0.75  0.75  0.50  0.25  0.25  0.50\n",
       "677   0.868   0.019078  0.75  0.75  0.50  0.25  0.25  0.75\n",
       "678   0.149   0.017403  0.75  0.75  0.50  0.25  0.50  0.25\n",
       "\n",
       "[679 rows x 8 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spectra=pd.read_csv(\"spectrum_energy_intensity2.csv\",index_col=[0])\n",
    "df_spectra.head(-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numpy_input=df_spectra[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]].to_numpy()\n",
    "numpy_energy_intensity=df_spectra[[\"Energy\",\"Intensity\"]].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "\n",
    "    model.add(Dense(n_outputs, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y):\n",
    "    results = list()\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        \n",
    "        print(X_train,y_train)\n",
    "        # define model\n",
    "        model = get_model(n_inputs, n_outputs)\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=8000)\n",
    "        # make a prediction on the test set\n",
    "        yhat = model.predict(X_test)\n",
    "        # round probabilities to class labels\n",
    "        yhat = yhat\n",
    "        # calculate accuracy\n",
    "        #print(y_test,yhat)\n",
    "        #no idea\n",
    "        clf = RandomForestRegressor(n_estimators=10)\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc=clf.score(X_test, y_test)\n",
    "        \n",
    "        \n",
    "        #acc = score(y_test, yhat)\n",
    "        # store result\n",
    "        print('>%.3f' % acc)\n",
    "        results.append(acc)\n",
    "    \n",
    "    y_predict1=[yhat[i][0] for i in range(len(yhat))]\n",
    "    y_predict2=[yhat[i][1] for i in range(len(yhat))]\n",
    "    y_test1=[y_test[i][0] for i in range(len(y_test))]\n",
    "    y_test2=[y_test[i][1] for i in range(len(y_test))]\n",
    "\n",
    "    df_compare=pd.DataFrame({\"predicted1\":y_predict1,\"predicted2\":y_predict2, \"Reference Energy\":y_test1, \"Reference Intensity\":y_test2})\n",
    "\n",
    "    return results,df_compare\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25 0.25 0.25 0.25 0.25 0.5 ]\n",
      " [0.25 0.25 0.25 0.25 0.75 0.5 ]\n",
      " [0.25 0.25 0.25 0.5  0.25 0.5 ]\n",
      " ...\n",
      " [0.75 0.75 0.75 0.75 0.5  0.5 ]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.5 ]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.75]] [[2.13000000e-01 6.04876653e-02]\n",
      " [2.13000000e-01 6.03352854e-02]\n",
      " [9.61000000e-01 1.45894112e-01]\n",
      " [5.91000000e-01 6.94445602e-02]\n",
      " [5.91000000e-01 6.94319200e-02]\n",
      " [7.33000000e-01 6.94625128e-02]\n",
      " [8.64000000e-01 2.18520311e-02]\n",
      " [8.64000000e-01 2.11114439e-02]\n",
      " [2.21000000e-01 5.85569916e-02]\n",
      " [8.64000000e-01 2.17968878e-02]\n",
      " [2.12000000e-01 6.31091435e-02]\n",
      " [8.68000000e-01 2.19550364e-02]\n",
      " [8.65000000e-01 2.10939210e-02]\n",
      " [2.13000000e-01 6.07196599e-02]\n",
      " [1.49000000e-01 1.74026571e-02]\n",
      " [1.49000000e-01 1.74013446e-02]\n",
      " [6.00000000e-01 6.76882947e-02]\n",
      " [9.61000000e-01 1.44199737e-01]\n",
      " [9.61000000e-01 1.44756338e-01]\n",
      " [6.00000000e-01 6.71246529e-02]\n",
      " [1.49000000e-01 1.74024096e-02]\n",
      " [8.68000000e-01 1.90841095e-02]\n",
      " [8.65000000e-01 2.10925686e-02]\n",
      " [8.68000000e-01 2.19903235e-02]\n",
      " [2.12000000e-01 6.31382933e-02]\n",
      " [7.55000000e-01 3.42133951e-02]\n",
      " [9.62000000e-01 1.45573578e-01]\n",
      " [9.61000000e-01 1.45621357e-01]\n",
      " [7.55000000e-01 3.43385898e-02]\n",
      " [8.73000000e-01 2.00775966e-02]\n",
      " [2.13000000e-01 6.06145739e-02]\n",
      " [8.67000000e-01 1.96030193e-02]\n",
      " [8.67000000e-01 1.96491664e-02]\n",
      " [2.13000000e-01 6.04900446e-02]\n",
      " [1.81000000e-01 7.23283340e-02]\n",
      " [1.84000000e-01 7.44611417e-02]\n",
      " [1.81000000e-01 7.23447467e-02]\n",
      " [1.85000000e-01 7.60633938e-02]\n",
      " [7.31000000e-01 9.90073720e-01]\n",
      " [1.22000000e-01 1.64489484e-03]\n",
      " [7.31000000e-01 9.96892466e-01]\n",
      " [1.22000000e-01 1.71059774e-03]\n",
      " [1.23000000e-01 4.08993659e-03]\n",
      " [2.88000000e-01 2.00930482e-01]\n",
      " [1.85000000e-01 7.59998394e-02]\n",
      " [2.88000000e-01 2.00930472e-01]\n",
      " [2.84000000e-01 1.86844609e-01]\n",
      " [2.86000000e-01 1.99229897e-01]\n",
      " [1.85000000e-01 7.64853770e-02]\n",
      " [1.85000000e-01 7.63066008e-02]\n",
      " [2.84000000e-01 1.86844609e-01]\n",
      " [1.22000000e-01 1.73660070e-03]\n",
      " [1.22000000e-01 1.71032204e-03]\n",
      " [1.19000000e-01 7.46237347e-03]\n",
      " [1.86000000e-01 7.44204886e-02]\n",
      " [2.84000000e-01 1.86844609e-01]\n",
      " [1.85000000e-01 7.64853770e-02]\n",
      " [2.86000000e-01 1.99230130e-01]\n",
      " [1.85000000e-01 7.64853770e-02]\n",
      " [2.88000000e-01 2.00930487e-01]\n",
      " [1.85000000e-01 7.59998397e-02]\n",
      " [1.85000000e-01 7.60798966e-02]\n",
      " [1.85000000e-01 7.60798963e-02]\n",
      " [1.85000000e-01 7.59998415e-02]\n",
      " [1.86000000e-01 7.52480686e-02]\n",
      " [1.23000000e-01 4.08992860e-03]\n",
      " [7.31000000e-01 9.90073723e-01]\n",
      " [1.22000000e-01 1.64489485e-03]\n",
      " [1.22000000e-01 1.71059720e-03]\n",
      " [7.31000000e-01 9.90073715e-01]\n",
      " [1.23000000e-01 4.08997479e-03]\n",
      " [1.85000000e-01 7.59636027e-02]\n",
      " [1.81000000e-01 7.24103867e-02]\n",
      " [1.84000000e-01 7.44611661e-02]\n",
      " [1.84000000e-01 7.44611354e-02]\n",
      " [2.08000000e-01 5.82404339e-02]\n",
      " [8.64000000e-01 2.14331193e-02]\n",
      " [2.11000000e-01 5.96943783e-02]\n",
      " [8.65000000e-01 2.03134652e-02]\n",
      " [8.64000000e-01 2.13942636e-02]\n",
      " [2.08000000e-01 5.82322526e-02]\n",
      " [8.66000000e-01 2.16819791e-02]\n",
      " [5.88000000e-01 6.34099207e-02]\n",
      " [7.33000000e-01 6.99375898e-02]\n",
      " [7.33000000e-01 6.99365350e-02]\n",
      " [9.63000000e-01 1.34493926e-01]\n",
      " [8.65000000e-01 2.07666998e-02]\n",
      " [8.65000000e-01 2.05161302e-02]\n",
      " [2.11000000e-01 6.02185869e-02]\n",
      " [8.66000000e-01 2.13149155e-02]\n",
      " [2.17000000e-01 5.22153739e-02]\n",
      " [8.65000000e-01 2.11108649e-02]\n",
      " [2.11000000e-01 5.95064484e-02]\n",
      " [2.17000000e-01 5.22153759e-02]\n",
      " [7.34000000e-01 6.97763469e-02]\n",
      " [9.62000000e-01 1.46858379e-01]\n",
      " [7.33000000e-01 6.99010340e-02]\n",
      " [9.62000000e-01 1.46844544e-01]\n",
      " [7.34000000e-01 6.98315601e-02]\n",
      " [2.17000000e-01 5.22153752e-02]\n",
      " [8.65000000e-01 2.11108681e-02]\n",
      " [8.66000000e-01 2.01670951e-02]\n",
      " [2.11000000e-01 5.95013351e-02]\n",
      " [8.66000000e-01 2.01670953e-02]\n",
      " [8.65000000e-01 2.11108682e-02]\n",
      " [8.66000000e-01 2.13768678e-02]\n",
      " [8.65000000e-01 2.05161300e-02]\n",
      " [2.11000000e-01 6.02192153e-02]\n",
      " [8.65000000e-01 2.05161308e-02]\n",
      " [8.65000000e-01 2.07666986e-02]\n",
      " [9.63000000e-01 1.34493504e-01]\n",
      " [7.34000000e-01 6.96289644e-02]\n",
      " [7.33000000e-01 6.99360941e-02]\n",
      " [9.62000000e-01 1.47283351e-01]\n",
      " [7.33000000e-01 6.99371180e-02]\n",
      " [7.34000000e-01 6.96289261e-02]\n",
      " [8.66000000e-01 2.16753328e-02]\n",
      " [2.08000000e-01 5.82521025e-02]\n",
      " [2.11000000e-01 5.96469794e-02]\n",
      " [8.65000000e-01 2.03206492e-02]\n",
      " [8.64000000e-01 2.14550221e-02]\n",
      " [8.66000000e-01 2.21447790e-02]\n",
      " [2.14000000e-01 6.05086279e-02]\n",
      " [8.64000000e-01 2.18131921e-02]\n",
      " [1.47000000e-01 1.84224848e-02]\n",
      " [8.66000000e-01 2.21457458e-02]\n",
      " [5.92000000e-01 7.20716604e-02]\n",
      " [9.62000000e-01 1.43417394e-01]\n",
      " [7.32000000e-01 6.93091955e-02]\n",
      " [9.64000000e-01 1.39025080e-01]\n",
      " [7.32000000e-01 6.93094352e-02]\n",
      " [8.65000000e-01 2.09571836e-02]\n",
      " [8.65000000e-01 2.06452167e-02]\n",
      " [2.07000000e-01 5.94042128e-02]\n",
      " [8.65000000e-01 2.06452166e-02]\n",
      " [8.66000000e-01 2.19887522e-02]\n",
      " [8.66000000e-01 2.17168602e-02]\n",
      " [2.13000000e-01 5.89293950e-02]\n",
      " [8.65000000e-01 2.11394415e-02]\n",
      " [8.65000000e-01 2.09131118e-02]\n",
      " [8.65000000e-01 2.11394415e-02]\n",
      " [8.66000000e-01 2.17190441e-02]\n",
      " [7.35000000e-01 7.06669072e-02]\n",
      " [7.36000000e-01 7.26438387e-02]\n",
      " [7.33000000e-01 7.03332379e-02]\n",
      " [9.63000000e-01 1.45767240e-01]\n",
      " [7.35000000e-01 7.06619547e-02]\n",
      " [8.66000000e-01 2.17137699e-02]\n",
      " [8.65000000e-01 2.11394415e-02]\n",
      " [8.65000000e-01 2.09131118e-02]\n",
      " [2.04000000e-01 5.55892549e-02]\n",
      " [8.65000000e-01 2.11394415e-02]\n",
      " [2.13000000e-01 5.89293950e-02]\n",
      " [8.66000000e-01 2.17143711e-02]\n",
      " [8.66000000e-01 2.18951118e-02]\n",
      " [8.65000000e-01 2.06452166e-02]\n",
      " [8.65000000e-01 2.06452166e-02]\n",
      " [8.65000000e-01 2.09571738e-02]\n",
      " [7.32000000e-01 6.93094667e-02]\n",
      " [5.90000000e-01 6.81464213e-02]\n",
      " [9.62000000e-01 1.43345379e-01]\n",
      " [8.66000000e-01 2.21351876e-02]\n",
      " [2.14000000e-01 6.05746686e-02]\n",
      " [1.48000000e-01 1.82931684e-02]\n",
      " [2.06000000e-01 5.74991398e-02]\n",
      " [1.47000000e-01 1.86366439e-02]\n",
      " [2.14000000e-01 6.05417481e-02]\n",
      " [1.94000000e-01 6.82217505e-02]\n",
      " [2.87000000e-01 1.83314314e-01]\n",
      " [1.84000000e-01 7.73901099e-02]\n",
      " [1.83000000e-01 7.32457135e-02]\n",
      " [2.94000000e-01 1.71813880e-01]\n",
      " [1.84000000e-01 7.54731766e-02]\n",
      " [1.94000000e-01 6.80839861e-02]\n",
      " [1.21000000e-01 1.73897967e-03]\n",
      " [7.55000000e-01 4.78311909e-01]\n",
      " [1.21000000e-01 1.73897451e-03]\n",
      " [7.31000000e-01 9.97433299e-01]\n",
      " [1.84000000e-01 7.38251881e-02]\n",
      " [1.85000000e-01 7.64361016e-02]\n",
      " [1.85000000e-01 7.64370899e-02]\n",
      " [1.84000000e-01 8.25234589e-02]\n",
      " [1.85000000e-01 7.64172568e-02]\n",
      " [1.85000000e-01 7.66458877e-02]\n",
      " [1.84000000e-01 8.39018212e-02]\n",
      " [1.23000000e-01 1.97535683e-03]\n",
      " [1.21000000e-01 1.67830171e-03]\n",
      " [7.31000000e-01 1.00000000e+00]\n",
      " [1.84000000e-01 8.38807881e-02]\n",
      " [2.88000000e-01 1.91973447e-01]\n",
      " [2.88000000e-01 1.91973906e-01]\n",
      " [1.85000000e-01 7.64363301e-02]\n",
      " [1.85000000e-01 7.65859804e-02]\n",
      " [1.85000000e-01 7.64377495e-02]\n",
      " [9.70000000e-02 9.50651799e-04]\n",
      " [1.21000000e-01 1.73897923e-03]\n",
      " [7.55000000e-01 4.78319684e-01]\n",
      " [1.22000000e-01 1.60448955e-03]\n",
      " [1.85000000e-01 7.58821686e-02]\n",
      " [1.83000000e-01 7.35530847e-02]\n",
      " [8.66000000e-01 2.21469216e-02]\n",
      " [1.47000000e-01 1.83089664e-02]\n",
      " [2.06000000e-01 5.75023269e-02]\n",
      " [8.64000000e-01 2.17694472e-02]\n",
      " [8.66000000e-01 2.21348518e-02]\n",
      " [7.32000000e-01 6.93089771e-02]\n",
      " [5.90000000e-01 6.81464213e-02]\n",
      " [9.64000000e-01 1.39574731e-01]\n",
      " [7.32000000e-01 6.93088015e-02]\n",
      " [8.66000000e-01 2.18784888e-02]\n",
      " [2.14000000e-01 5.99348927e-02]\n",
      " [8.65000000e-01 2.06452167e-02]\n",
      " [2.14000000e-01 5.99348904e-02]\n",
      " [8.66000000e-01 2.19497728e-02]\n",
      " [8.65000000e-01 2.11394415e-02]\n",
      " [8.65000000e-01 2.11394415e-02]\n",
      " [8.66000000e-01 2.17149089e-02]\n",
      " [9.62000000e-01 1.53310848e-01]\n",
      " [7.33000000e-01 7.03514337e-02]\n",
      " [7.33000000e-01 7.03682029e-02]\n",
      " [9.62000000e-01 1.53365916e-01]\n",
      " [8.66000000e-01 2.17209252e-02]\n",
      " [2.13000000e-01 5.89293950e-02]\n",
      " [2.04000000e-01 5.55885456e-02]\n",
      " [8.65000000e-01 2.11394414e-02]\n",
      " [8.66000000e-01 2.17278818e-02]\n",
      " [8.65000000e-01 2.09571586e-02]\n",
      " [8.65000000e-01 2.06452166e-02]\n",
      " [2.07000000e-01 5.94008240e-02]\n",
      " [8.65000000e-01 2.09573500e-02]\n",
      " [2.14000000e-01 5.99348942e-02]\n",
      " [5.92000000e-01 7.28633309e-02]\n",
      " [9.62000000e-01 1.43332076e-01]\n",
      " [7.32000000e-01 6.93092851e-02]\n",
      " [5.90000000e-01 6.81464213e-02]\n",
      " [9.64000000e-01 1.39672382e-01]\n",
      " [5.90000000e-01 6.81464213e-02]\n",
      " [7.32000000e-01 6.93086998e-02]\n",
      " [9.62000000e-01 1.43285122e-01]\n",
      " [5.92000000e-01 7.22601205e-02]\n",
      " [8.66000000e-01 2.21383056e-02]\n",
      " [2.14000000e-01 6.05352788e-02]\n",
      " [8.66000000e-01 2.21348385e-02]\n",
      " [2.08000000e-01 5.82385100e-02]\n",
      " [8.65000000e-01 2.03147122e-02]\n",
      " [2.11000000e-01 5.96906537e-02]\n",
      " [8.64000000e-01 2.14395641e-02]\n",
      " [8.66000000e-01 2.16799707e-02]\n",
      " [7.34000000e-01 6.96288565e-02]\n",
      " [9.62000000e-01 1.47279674e-01]\n",
      " [7.33000000e-01 6.99368402e-02]\n",
      " [5.88000000e-01 6.34049749e-02]\n",
      " [2.09000000e-01 5.89279325e-02]\n",
      " [8.65000000e-01 2.07667062e-02]\n",
      " [8.65000000e-01 2.05161245e-02]\n",
      " [2.11000000e-01 6.02200476e-02]\n",
      " [8.66000000e-01 2.13777559e-02]\n",
      " [2.17000000e-01 5.22153343e-02]\n",
      " [8.65000000e-01 2.11108639e-02]\n",
      " [8.66000000e-01 2.01670951e-02]\n",
      " [2.17000000e-01 5.22153785e-02]\n",
      " [9.62000000e-01 1.46674028e-01]\n",
      " [7.33000000e-01 6.98309000e-02]\n",
      " [7.33000000e-01 6.99025066e-02]\n",
      " [2.17000000e-01 5.22153749e-02]\n",
      " [8.66000000e-01 2.01670950e-02]\n",
      " [8.66000000e-01 2.01670952e-02]\n",
      " [8.66000000e-01 2.13074089e-02]\n",
      " [8.65000000e-01 2.07667072e-02]\n",
      " [8.65000000e-01 2.05161206e-02]\n",
      " [8.65000000e-01 2.05161328e-02]\n",
      " [2.09000000e-01 5.89279277e-02]\n",
      " [8.66000000e-01 2.13144074e-02]\n",
      " [9.63000000e-01 1.34493783e-01]\n",
      " [7.33000000e-01 6.99362849e-02]\n",
      " [9.63000000e-01 1.34493733e-01]\n",
      " [5.88000000e-01 6.34063077e-02]\n",
      " [8.66000000e-01 2.16872090e-02]\n",
      " [8.64000000e-01 2.13205153e-02]\n",
      " [8.65000000e-01 2.03198953e-02]\n",
      " [2.11000000e-01 5.96671976e-02]\n",
      " [8.64000000e-01 2.14704858e-02]\n",
      " [2.09000000e-01 5.82579941e-02]\n",
      " [8.66000000e-01 2.16817871e-02]\n",
      " [2.86000000e-01 1.89948714e-01]\n",
      " [1.81000000e-01 7.23821103e-02]\n",
      " [1.84000000e-01 7.44611417e-02]\n",
      " [2.86000000e-01 1.89951348e-01]\n",
      " [1.23000000e-01 4.08996683e-03]\n",
      " [7.31000000e-01 9.96892946e-01]\n",
      " [1.22000000e-01 1.64489486e-03]\n",
      " [7.31000000e-01 9.90073708e-01]\n",
      " [1.86000000e-01 7.52474998e-02]\n",
      " [2.88000000e-01 2.00930352e-01]\n",
      " [1.85000000e-01 7.59998399e-02]\n",
      " [1.85000000e-01 7.60798966e-02]\n",
      " [2.80000000e-01 1.60532197e-01]\n",
      " [1.85000000e-01 7.60798963e-02]\n",
      " [2.88000000e-01 2.00930393e-01]\n",
      " [2.84000000e-01 1.86844609e-01]\n",
      " [2.84000000e-01 1.86844609e-01]\n",
      " [1.22000000e-01 1.73602666e-03]\n",
      " [1.22000000e-01 1.73622120e-03]\n",
      " [1.22000000e-01 1.70990370e-03]\n",
      " [1.20000000e-01 7.42602348e-03]\n",
      " [1.85000000e-01 7.64853770e-02]\n",
      " [2.86000000e-01 1.99230330e-01]\n",
      " [1.85000000e-01 7.63065998e-02]\n",
      " [2.84000000e-01 1.86844609e-01]\n",
      " [1.86000000e-01 7.44204972e-02]\n",
      " [1.86000000e-01 7.52475429e-02]\n",
      " [2.88000000e-01 2.00930348e-01]\n",
      " [1.85000000e-01 7.59998415e-02]\n",
      " [1.86000000e-01 7.52476782e-02]\n",
      " [1.23000000e-01 4.08989344e-03]\n",
      " [1.22000000e-01 1.71059759e-03]\n",
      " [1.22000000e-01 1.64489488e-03]\n",
      " [1.22000000e-01 1.64489487e-03]\n",
      " [1.22000000e-01 1.71059721e-03]\n",
      " [7.31000000e-01 9.90073705e-01]\n",
      " [2.86000000e-01 1.89952203e-01]\n",
      " [1.81000000e-01 7.23189162e-02]\n",
      " [1.84000000e-01 7.44611371e-02]\n",
      " [1.81000000e-01 7.23209135e-02]\n",
      " [8.74000000e-01 1.98924835e-02]\n",
      " [8.66000000e-01 2.01561235e-02]\n",
      " [8.67000000e-01 1.97019300e-02]\n",
      " [8.67000000e-01 1.96692992e-02]\n",
      " [2.13000000e-01 6.05175188e-02]\n",
      " [9.86000000e-01 7.07103116e-02]\n",
      " [9.61000000e-01 1.45599380e-01]\n",
      " [7.55000000e-01 3.41311991e-02]\n",
      " [8.64000000e-01 2.18811811e-02]\n",
      " [8.64000000e-01 2.11109560e-02]\n",
      " [8.64000000e-01 2.11113128e-02]\n",
      " [8.64000000e-01 2.17883960e-02]\n",
      " [8.65000000e-01 2.11006538e-02]\n",
      " [2.13000000e-01 6.07228272e-02]\n",
      " [1.49000000e-01 1.74030425e-02]\n",
      " [2.15000000e-01 5.45901313e-02]\n",
      " [1.49000000e-01 1.74021587e-02]\n",
      " [2.13000000e-01 6.07214365e-02]\n",
      " [6.00000000e-01 6.73175185e-02]\n",
      " [7.34000000e-01 6.91287991e-02]\n",
      " [7.34000000e-01 7.05746341e-02]\n",
      " [7.34000000e-01 6.88657107e-02]\n",
      " [6.00000000e-01 6.76322652e-02]\n",
      " [2.14000000e-01 5.49256429e-02]\n",
      " [8.65000000e-01 2.10961148e-02]\n",
      " [8.68000000e-01 2.20524105e-02]\n",
      " [2.12000000e-01 6.30699833e-02]\n",
      " [8.64000000e-01 2.11111866e-02]\n",
      " [2.21000000e-01 5.86362679e-02]\n",
      " [8.64000000e-01 2.11113386e-02]\n",
      " [8.64000000e-01 2.18383092e-02]\n",
      " [8.68000000e-01 2.19547426e-02]\n",
      " [7.33000000e-01 6.91895370e-02]\n",
      " [9.86000000e-01 7.09915570e-02]\n",
      " [7.33000000e-01 6.99505433e-02]\n",
      " [8.74000000e-01 2.00602089e-02]\n",
      " [8.67000000e-01 1.96061278e-02]\n",
      " [2.20000000e-01 6.06438642e-02]\n",
      " [2.13000000e-01 6.04017133e-02]\n",
      " [8.73000000e-01 2.01974041e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\sklearn\\base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.814\n",
      "[[0.25 0.25 0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25 0.25 0.75]\n",
      " [0.25 0.25 0.25 0.25 0.5  0.25]\n",
      " ...\n",
      " [0.75 0.75 0.75 0.75 0.25 0.75]\n",
      " [0.75 0.75 0.75 0.75 0.5  0.75]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.25]] [[8.74000000e-01 1.99354751e-02]\n",
      " [8.66000000e-01 2.01526467e-02]\n",
      " [8.67000000e-01 1.96407851e-02]\n",
      " [2.20000000e-01 6.04711762e-02]\n",
      " [8.67000000e-01 1.96734450e-02]\n",
      " [8.66000000e-01 2.01568340e-02]\n",
      " [8.74000000e-01 2.00017725e-02]\n",
      " [7.55000000e-01 3.43193538e-02]\n",
      " [7.33000000e-01 6.98470869e-02]\n",
      " [9.86000000e-01 7.08146629e-02]\n",
      " [9.61000000e-01 1.46052855e-01]\n",
      " [7.55000000e-01 3.42133063e-02]\n",
      " [8.68000000e-01 2.19944234e-02]\n",
      " [2.12000000e-01 6.32058546e-02]\n",
      " [8.64000000e-01 2.11120033e-02]\n",
      " [8.68000000e-01 1.90769131e-02]\n",
      " [2.15000000e-01 5.52185383e-02]\n",
      " [8.68000000e-01 1.90990647e-02]\n",
      " [2.13000000e-01 6.07190130e-02]\n",
      " [8.65000000e-01 2.11018418e-02]\n",
      " [7.34000000e-01 6.85879306e-02]\n",
      " [7.34000000e-01 7.05798993e-02]\n",
      " [9.69000000e-01 1.30275415e-01]\n",
      " [7.34000000e-01 7.06091848e-02]\n",
      " [7.34000000e-01 6.90823122e-02]\n",
      " [8.65000000e-01 2.10986250e-02]\n",
      " [2.13000000e-01 6.07211742e-02]\n",
      " [8.68000000e-01 1.90856672e-02]\n",
      " [2.15000000e-01 5.61705461e-02]\n",
      " [1.49000000e-01 1.74031502e-02]\n",
      " [2.13000000e-01 6.07285940e-02]\n",
      " [8.64000000e-01 2.18415531e-02]\n",
      " [8.64000000e-01 2.11093594e-02]\n",
      " [2.21000000e-01 5.83401154e-02]\n",
      " [8.64000000e-01 2.11117086e-02]\n",
      " [8.64000000e-01 2.18576923e-02]\n",
      " [2.12000000e-01 6.31944621e-02]\n",
      " [8.68000000e-01 2.19271776e-02]\n",
      " [7.33000000e-01 6.88907472e-02]\n",
      " [5.91000000e-01 6.94377008e-02]\n",
      " [9.86000000e-01 7.06508311e-02]\n",
      " [5.91000000e-01 6.94446896e-02]\n",
      " [7.33000000e-01 6.98379948e-02]\n",
      " [8.66000000e-01 2.01558614e-02]\n",
      " [2.20000000e-01 6.03332313e-02]\n",
      " [8.66000000e-01 2.01514719e-02]\n",
      " [8.74000000e-01 2.00322853e-02]\n",
      " [1.85000000e-01 7.62612636e-02]\n",
      " [2.86000000e-01 1.89949225e-01]\n",
      " [1.84000000e-01 7.44611772e-02]\n",
      " [2.87000000e-01 2.23163982e-01]\n",
      " [2.86000000e-01 1.89949032e-01]\n",
      " [1.23000000e-01 4.08991348e-03]\n",
      " [1.22000000e-01 1.71059705e-03]\n",
      " [1.22000000e-01 1.64489486e-03]\n",
      " [7.31000000e-01 9.90073723e-01]\n",
      " [1.86000000e-01 7.52473867e-02]\n",
      " [1.85000000e-01 7.59998425e-02]\n",
      " [1.85000000e-01 7.60798963e-02]\n",
      " [2.80000000e-01 1.60532995e-01]\n",
      " [1.85000000e-01 7.60798963e-02]\n",
      " [1.86000000e-01 7.52479083e-02]\n",
      " [1.86000000e-01 7.44204668e-02]\n",
      " [1.85000000e-01 7.63066013e-02]\n",
      " [1.85000000e-01 7.64853770e-02]\n",
      " [1.86000000e-01 7.44204916e-02]\n",
      " [1.19000000e-01 7.58759066e-03]\n",
      " [7.30000000e-01 9.84631915e-01]\n",
      " [1.22000000e-01 1.70996107e-03]\n",
      " [1.22000000e-01 1.73597897e-03]\n",
      " [7.31000000e-01 9.99097224e-01]\n",
      " [7.30000000e-01 9.84625943e-01]\n",
      " [1.85000000e-01 7.63066003e-02]\n",
      " [1.85000000e-01 7.63066016e-02]\n",
      " [2.84000000e-01 1.86844609e-01]\n",
      " [1.86000000e-01 7.44204713e-02]\n",
      " [1.86000000e-01 7.52473560e-02]\n",
      " [2.80000000e-01 1.60533753e-01]\n",
      " [2.88000000e-01 2.00930467e-01]\n",
      " [1.22000000e-01 1.71059770e-03]\n",
      " [1.22000000e-01 1.64489486e-03]\n",
      " [7.31000000e-01 9.96889653e-01]\n",
      " [2.86000000e-01 1.89950236e-01]\n",
      " [2.87000000e-01 2.23276019e-01]\n",
      " [1.81000000e-01 7.23218727e-02]\n",
      " [2.86000000e-01 1.89948600e-01]\n",
      " [1.85000000e-01 7.61288802e-02]\n",
      " [8.66000000e-01 2.16848949e-02]\n",
      " [8.65000000e-01 2.03180972e-02]\n",
      " [9.63000000e-01 1.34493543e-01]\n",
      " [7.34000000e-01 6.96288872e-02]\n",
      " [9.62000000e-01 1.47270454e-01]\n",
      " [7.34000000e-01 6.96288309e-02]\n",
      " [5.88000000e-01 6.34058922e-02]\n",
      " [8.66000000e-01 2.13121588e-02]\n",
      " [2.09000000e-01 5.89280027e-02]\n",
      " [8.65000000e-01 2.05161238e-02]\n",
      " [8.65000000e-01 2.07667063e-02]\n",
      " [2.09000000e-01 5.89279426e-02]\n",
      " [8.66000000e-01 2.13778054e-02]\n",
      " [8.66000000e-01 2.01670953e-02]\n",
      " [8.66000000e-01 2.01670950e-02]\n",
      " [8.65000000e-01 2.11108668e-02]\n",
      " [8.66000000e-01 2.13770150e-02]\n",
      " [7.33000000e-01 6.99051328e-02]\n",
      " [7.33000000e-01 6.98282987e-02]\n",
      " [9.62000000e-01 1.46674028e-01]\n",
      " [7.33000000e-01 6.98128982e-02]\n",
      " [8.66000000e-01 2.13770913e-02]\n",
      " [2.17000000e-01 5.22153731e-02]\n",
      " [8.66000000e-01 2.12951615e-02]\n",
      " [2.09000000e-01 5.89279408e-02]\n",
      " [8.65000000e-01 2.07667001e-02]\n",
      " [2.09000000e-01 5.89279307e-02]\n",
      " [8.66000000e-01 2.13096256e-02]\n",
      " [5.88000000e-01 6.34135086e-02]\n",
      " [9.63000000e-01 1.34493775e-01]\n",
      " [5.88000000e-01 6.34082895e-02]\n",
      " [8.64000000e-01 2.14551463e-02]\n",
      " [8.65000000e-01 2.03151356e-02]\n",
      " [2.08000000e-01 5.82342706e-02]\n",
      " [8.66000000e-01 2.16739602e-02]\n",
      " [1.47000000e-01 1.83719104e-02]\n",
      " [2.06000000e-01 5.74946465e-02]\n",
      " [8.64000000e-01 2.17837537e-02]\n",
      " [2.14000000e-01 6.05043360e-02]\n",
      " [5.90000000e-01 6.81464213e-02]\n",
      " [5.90000000e-01 6.81464213e-02]\n",
      " [9.62000000e-01 1.43348507e-01]\n",
      " [5.92000000e-01 7.30798103e-02]\n",
      " [8.66000000e-01 2.18621619e-02]\n",
      " [2.14000000e-01 5.99348942e-02]\n",
      " [8.65000000e-01 2.09569945e-02]\n",
      " [2.14000000e-01 5.99348904e-02]\n",
      " [8.65000000e-01 2.09131118e-02]\n",
      " [2.04000000e-01 5.55808599e-02]\n",
      " [2.13000000e-01 5.89293950e-02]\n",
      " [9.62000000e-01 1.53119775e-01]\n",
      " [7.33000000e-01 7.03669492e-02]\n",
      " [7.36000000e-01 7.29988904e-02]\n",
      " [9.62000000e-01 1.52887279e-01]\n",
      " [2.13000000e-01 5.89293950e-02]\n",
      " [8.65000000e-01 2.09131118e-02]\n",
      " [2.14000000e-01 5.99348871e-02]\n",
      " [8.65000000e-01 2.09572422e-02]\n",
      " [2.07000000e-01 5.93883445e-02]\n",
      " [2.14000000e-01 5.99348975e-02]\n",
      " [8.66000000e-01 2.18889918e-02]\n",
      " [5.92000000e-01 7.28036742e-02]\n",
      " [9.62000000e-01 1.43398055e-01]\n",
      " [9.64000000e-01 1.39429662e-01]\n",
      " [5.90000000e-01 6.81464213e-02]\n",
      " [7.32000000e-01 6.93087746e-02]\n",
      " [5.92000000e-01 7.21445017e-02]\n",
      " [8.64000000e-01 2.18038310e-02]\n",
      " [8.64000000e-01 2.17902423e-02]\n",
      " [8.66000000e-01 2.21432803e-02]\n",
      " [1.83000000e-01 7.31717686e-02]\n",
      " [2.86000000e-01 1.72730885e-01]\n",
      " [9.50000000e-02 9.51628012e-04]\n",
      " [7.31000000e-01 9.97429661e-01]\n",
      " [1.22000000e-01 1.60415730e-03]\n",
      " [1.22000000e-01 1.60487972e-03]\n",
      " [9.40000000e-02 9.56808011e-04]\n",
      " [2.89000000e-01 1.98616410e-01]\n",
      " [1.85000000e-01 7.65859824e-02]\n",
      " [2.87000000e-01 2.05244110e-01]\n",
      " [1.85000000e-01 7.65859677e-02]\n",
      " [2.89000000e-01 1.98595746e-01]\n",
      " [1.84000000e-01 7.41385037e-02]\n",
      " [2.88000000e-01 1.91974000e-01]\n",
      " [1.85000000e-01 7.66458530e-02]\n",
      " [1.85000000e-01 7.64172555e-02]\n",
      " [2.90000000e-01 1.97537417e-01]\n",
      " [2.88000000e-01 1.91973765e-01]\n",
      " [1.48000000e-01 9.64148799e-03]\n",
      " [7.31000000e-01 1.00000000e+00]\n",
      " [1.21000000e-01 1.67830171e-03]\n",
      " [7.39000000e-01 9.72957395e-01]\n",
      " [1.23000000e-01 1.97535684e-03]\n",
      " [1.47000000e-01 9.79047967e-03]\n",
      " [1.85000000e-01 7.66458555e-02]\n",
      " [1.85000000e-01 7.64172563e-02]\n",
      " [2.90000000e-01 1.96870728e-01]\n",
      " [1.85000000e-01 7.64172557e-02]\n",
      " [1.85000000e-01 7.66458489e-02]\n",
      " [1.85000000e-01 8.42837892e-02]\n",
      " [1.84000000e-01 7.39831260e-02]\n",
      " [2.89000000e-01 1.98612759e-01]\n",
      " [2.87000000e-01 2.05606907e-01]\n",
      " [1.85000000e-01 7.65860357e-02]\n",
      " [2.89000000e-01 1.98649038e-01]\n",
      " [1.84000000e-01 7.35567512e-02]\n",
      " [7.31000000e-01 9.97425714e-01]\n",
      " [1.22000000e-01 1.60502250e-03]\n",
      " [1.21000000e-01 1.73897931e-03]\n",
      " [7.31000000e-01 9.97429623e-01]\n",
      " [9.40000000e-02 9.51257910e-04]\n",
      " [1.94000000e-01 6.84157757e-02]\n",
      " [2.87000000e-01 1.79462505e-01]\n",
      " [1.82000000e-01 7.31764514e-02]\n",
      " [2.94000000e-01 1.72411312e-01]\n",
      " [1.84000000e-01 7.87708124e-02]\n",
      " [2.87000000e-01 1.84337227e-01]\n",
      " [1.94000000e-01 6.77483530e-02]\n",
      " [2.14000000e-01 6.05789222e-02]\n",
      " [8.64000000e-01 2.17707660e-02]\n",
      " [1.47000000e-01 1.86040126e-02]\n",
      " [2.14000000e-01 6.04729525e-02]\n",
      " [5.92000000e-01 7.31574123e-02]\n",
      " [9.62000000e-01 1.43295734e-01]\n",
      " [5.90000000e-01 6.81464213e-02]\n",
      " [9.62000000e-01 1.43330969e-01]\n",
      " [5.92000000e-01 7.30125641e-02]\n",
      " [8.65000000e-01 2.09572171e-02]\n",
      " [2.07000000e-01 5.94003278e-02]\n",
      " [8.65000000e-01 2.06452166e-02]\n",
      " [8.65000000e-01 2.09574538e-02]\n",
      " [8.66000000e-01 2.17074274e-02]\n",
      " [2.13000000e-01 5.89293950e-02]\n",
      " [8.65000000e-01 2.09131118e-02]\n",
      " [2.04000000e-01 5.55933098e-02]\n",
      " [8.65000000e-01 2.09131118e-02]\n",
      " [2.13000000e-01 5.89293950e-02]\n",
      " [7.35000000e-01 7.06470177e-02]\n",
      " [7.36000000e-01 7.32261325e-02]\n",
      " [9.63000000e-01 1.45767235e-01]\n",
      " [7.36000000e-01 7.31722481e-02]\n",
      " [7.35000000e-01 7.06516970e-02]\n",
      " [8.65000000e-01 2.11394415e-02]\n",
      " [8.65000000e-01 2.09131118e-02]\n",
      " [8.65000000e-01 2.09131118e-02]\n",
      " [2.13000000e-01 5.89293950e-02]\n",
      " [8.66000000e-01 2.17792799e-02]\n",
      " [2.14000000e-01 5.99348924e-02]\n",
      " [8.65000000e-01 2.06452168e-02]\n",
      " [8.66000000e-01 2.19350746e-02]\n",
      " [1.47000000e-01 1.86237419e-02]\n",
      " [8.64000000e-01 2.17938415e-02]\n",
      " [2.06000000e-01 5.74955402e-02]\n",
      " [8.64000000e-01 2.17771058e-02]\n",
      " [1.47000000e-01 1.82639004e-02]\n",
      " [2.14000000e-01 6.05179369e-02]\n",
      " [8.66000000e-01 2.16797012e-02]\n",
      " [8.64000000e-01 2.14047100e-02]\n",
      " [8.65000000e-01 2.03169772e-02]\n",
      " [2.09000000e-01 5.82462986e-02]\n",
      " [5.88000000e-01 6.34047806e-02]\n",
      " [9.63000000e-01 1.34493662e-01]\n",
      " [7.33000000e-01 6.99357369e-02]\n",
      " [7.34000000e-01 6.96289633e-02]\n",
      " [9.63000000e-01 1.34493570e-01]\n",
      " [8.66000000e-01 2.12995116e-02]\n",
      " [8.65000000e-01 2.05161325e-02]\n",
      " [8.65000000e-01 2.07667018e-02]\n",
      " [2.09000000e-01 5.89279269e-02]\n",
      " [8.66000000e-01 2.13053307e-02]\n",
      " [2.11000000e-01 5.95055295e-02]\n",
      " [8.66000000e-01 2.01670951e-02]\n",
      " [8.65000000e-01 2.11108665e-02]\n",
      " [8.66000000e-01 2.13773747e-02]\n",
      " [7.34000000e-01 6.98318211e-02]\n",
      " [9.62000000e-01 1.46850079e-01]\n",
      " [7.33000000e-01 6.99046759e-02]\n",
      " [7.33000000e-01 6.98410599e-02]\n",
      " [9.62000000e-01 1.46844988e-01]\n",
      " [7.34000000e-01 6.98701071e-02]\n",
      " [8.66000000e-01 2.13772522e-02]\n",
      " [8.65000000e-01 2.11108640e-02]\n",
      " [2.11000000e-01 5.95049346e-02]\n",
      " [8.65000000e-01 2.11108637e-02]\n",
      " [2.17000000e-01 5.22153668e-02]\n",
      " [8.66000000e-01 2.13770073e-02]\n",
      " [2.09000000e-01 5.89279353e-02]\n",
      " [2.11000000e-01 6.02192130e-02]\n",
      " [8.65000000e-01 2.07667069e-02]\n",
      " [5.88000000e-01 6.34143331e-02]\n",
      " [7.34000000e-01 6.96289631e-02]\n",
      " [9.62000000e-01 1.47269297e-01]\n",
      " [7.33000000e-01 6.99368212e-02]\n",
      " [7.34000000e-01 6.96288883e-02]\n",
      " [2.08000000e-01 5.83485578e-02]\n",
      " [8.65000000e-01 2.03138842e-02]\n",
      " [1.85000000e-01 7.61583068e-02]\n",
      " [1.84000000e-01 7.44611826e-02]\n",
      " [2.87000000e-01 2.23251178e-01]\n",
      " [1.81000000e-01 7.23680480e-02]\n",
      " [1.85000000e-01 7.62590690e-02]\n",
      " [7.31000000e-01 9.90073710e-01]\n",
      " [1.22000000e-01 1.71059735e-03]\n",
      " [1.22000000e-01 1.64489488e-03]\n",
      " [1.22000000e-01 1.71059775e-03]\n",
      " [1.23000000e-01 4.08996343e-03]\n",
      " [1.85000000e-01 7.59998402e-02]\n",
      " [1.86000000e-01 7.52475054e-02]\n",
      " [1.86000000e-01 7.44204949e-02]\n",
      " [1.85000000e-01 7.63066011e-02]\n",
      " [1.85000000e-01 7.64853770e-02]\n",
      " [2.86000000e-01 1.99230726e-01]\n",
      " [1.85000000e-01 7.64853770e-02]\n",
      " [1.85000000e-01 7.63066003e-02]\n",
      " [1.86000000e-01 7.44204850e-02]\n",
      " [1.19000000e-01 7.54612643e-03]\n",
      " [7.30000000e-01 9.84630126e-01]\n",
      " [1.22000000e-01 1.70996460e-03]\n",
      " [7.31000000e-01 9.99097515e-01]\n",
      " [7.30000000e-01 9.84630877e-01]\n",
      " [1.86000000e-01 7.44204891e-02]\n",
      " [2.84000000e-01 1.86844609e-01]\n",
      " [1.85000000e-01 7.63066011e-02]\n",
      " [1.85000000e-01 7.64853770e-02]\n",
      " [1.85000000e-01 7.59998417e-02]\n",
      " [1.85000000e-01 7.60798963e-02]\n",
      " [2.80000000e-01 1.60534685e-01]\n",
      " [1.85000000e-01 7.60798966e-02]\n",
      " [2.88000000e-01 2.00930476e-01]\n",
      " [7.31000000e-01 9.90073723e-01]\n",
      " [7.31000000e-01 9.96893633e-01]\n",
      " [1.23000000e-01 4.08993973e-03]\n",
      " [1.85000000e-01 7.61156361e-02]\n",
      " [2.87000000e-01 2.23184837e-01]\n",
      " [1.84000000e-01 7.44611912e-02]\n",
      " [2.86000000e-01 1.89949707e-01]\n",
      " [1.85000000e-01 7.59892212e-02]\n",
      " [2.13000000e-01 6.06083208e-02]\n",
      " [2.20000000e-01 5.99109777e-02]\n",
      " [8.66000000e-01 2.01602833e-02]\n",
      " [8.73000000e-01 2.03675191e-02]\n",
      " [7.55000000e-01 3.42994483e-02]\n",
      " [9.62000000e-01 1.45614743e-01]\n",
      " [7.33000000e-01 6.95350070e-02]\n",
      " [5.91000000e-01 6.94462414e-02]\n",
      " [5.91000000e-01 6.94308409e-02]\n",
      " [7.33000000e-01 6.91533718e-02]\n",
      " [8.68000000e-01 2.19603359e-02]\n",
      " [2.12000000e-01 6.31277785e-02]\n",
      " [2.21000000e-01 5.86205501e-02]\n",
      " [2.12000000e-01 6.30035753e-02]\n",
      " [8.68000000e-01 2.19905669e-02]\n",
      " [8.68000000e-01 1.90777068e-02]\n",
      " [8.68000000e-01 1.90906030e-02]\n",
      " [8.65000000e-01 2.10958591e-02]\n",
      " [9.61000000e-01 1.43939585e-01]\n",
      " [9.69000000e-01 1.31211357e-01]\n",
      " [7.34000000e-01 7.05862189e-02]\n",
      " [9.61000000e-01 1.44632382e-01]\n",
      " [8.65000000e-01 2.10930296e-02]\n",
      " [2.13000000e-01 6.07248511e-02]\n",
      " [8.68000000e-01 1.90967582e-02]\n",
      " [1.49000000e-01 1.74027393e-02]\n",
      " [1.49000000e-01 1.74030530e-02]\n",
      " [8.68000000e-01 1.90798339e-02]\n",
      " [2.13000000e-01 6.07229195e-02]\n",
      " [8.64000000e-01 2.19166987e-02]\n",
      " [2.12000000e-01 6.31675691e-02]\n",
      " [7.55000000e-01 3.40855425e-02]\n",
      " [9.61000000e-01 1.45457276e-01]\n",
      " [5.91000000e-01 6.94327925e-02]\n",
      " [5.91000000e-01 6.94311506e-02]\n",
      " [9.62000000e-01 1.45687084e-01]\n",
      " [7.55000000e-01 3.37854597e-02]\n",
      " [2.13000000e-01 6.05495281e-02]\n",
      " [8.66000000e-01 2.01558940e-02]\n",
      " [8.67000000e-01 1.96886731e-02]\n",
      " [8.66000000e-01 2.01623956e-02]]\n"
     ]
    }
   ],
   "source": [
    "results,compare = evaluate_model(numpy_input, numpy_energy_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "compare.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy: 0.837 (0.008)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
