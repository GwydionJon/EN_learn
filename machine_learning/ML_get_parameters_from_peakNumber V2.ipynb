{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import kerastuner as kt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 729\n",
      "(583, 22)\n"
     ]
    }
   ],
   "source": [
    "#input with all maxima\n",
    "df_spectra_all=pd.read_csv(\"spectrum_energy_input_numberOfPeaks.csv\",index_col=[0])\n",
    "x_data_string=df_spectra_all[\"all_maxima\"].values\n",
    "\n",
    "max_nr_of_max=df_spectra_all['no_of_max'].max()\n",
    "len_array=len(df_spectra_all[\"all_maxima\"].values)\n",
    "\n",
    "print(max_nr_of_max,len_array)\n",
    "x_data_padded=np.zeros((len_array,max_nr_of_max))\n",
    "\n",
    "for i,x_string in enumerate(x_data_string):\n",
    "    x_string=x_string.replace('\\n','').replace('[','').replace(']','')\n",
    "    x_split= x_string.split(' ')\n",
    "    j=0\n",
    "    for x in (x_split):\n",
    "        if(x!=''):\n",
    "            #print(x)\n",
    "            x_data_padded[i,j]=float(x)\n",
    "            j=j+1\n",
    "    #print(\"cut\")\n",
    "\n",
    "y_data=df_spectra[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]].to_numpy()\n",
    "\n",
    "\n",
    "y_data=y_data-0.5\n",
    "y_data=y_data*4\n",
    "\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(x_data_padded, y_data, test_size=0.20, random_state=42)\n",
    "   \n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def transform_data(df,index):\n",
    "    data=df[index].to_numpy()\n",
    "    new_data=np.zeros((len(data),max(data)+1))    \n",
    "    for i in range(len(data)):\n",
    "        new_data[i,data[i]]=1\n",
    "    return new_data\n",
    "    \n",
    "df_spectra=pd.read_csv(\"spectrum_energy_input_numberOfPeaks.csv\",index_col=[0])\n",
    "df_new=df_spectra.loc[df_spectra[\"k11\"] == 0]\n",
    "\n",
    "\n",
    "x_data=transform_data(df_new,\"no_of_max\")\n",
    "print(x_data[0:2])\n",
    "\n",
    "\n",
    "\n",
    "y_data=df_spectra[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]].to_numpy()\n",
    "\n",
    "\n",
    "y_data=y_data-0.5\n",
    "y_data=y_data*4\n",
    "print(y_data[0:10])\n",
    "\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(x_data, y_data, test_size=0.20, random_state=42)\n",
    "\n",
    "print(data_train.shape)\n",
    "print(labels_train.shape)\n",
    "\n",
    "#df_training = df_spectra.sample(frac=0.8,random_state=10)\n",
    "#df_testing=df_spectra.drop(df_training.index)\n",
    "#df_spectra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_A = []\n",
    "\n",
    "no_of_max = tf.feature_column.numeric_column(\"all_maxima\")\n",
    "my_feature_layer_A = tf.keras.layers.DenseFeatures(no_of_max_bucket)\n",
    "\n",
    "#transform data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_the_loss_curve(epochs, mse,val_mse):\n",
    "    \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "\n",
    "    plt.plot(epochs, mse, label=\"Loss\")\n",
    "    plt.plot(epochs, val_mse, label=\"Val Loss\")\n",
    "\n",
    "    plt.legend()\n",
    "    #plt.ylim([0, 15])\n",
    "    plt.show()  \n",
    "\n",
    "def create_model(my_learning_rate, my_feature_layer):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Add the layer containing the feature columns to the model.\n",
    "    # Define the first hidden layer with 10 nodes.   \n",
    "   # model.add(my_feature_layer_A)\n",
    "    #layers=[5,10]\n",
    "    layers=[2000,3500,300,2000,3000,30,200,300,30]\n",
    "    for layer in layers:\n",
    "        model.add(tf.keras.layers.Dense(units = layer, activation = 'sigmoid',kernel_regularizer=tf.keras.regularizers.l1(0.0)))\n",
    "    # Define the output layer.\n",
    "    model.add(tf.keras.layers.Dense(units=6,  \n",
    "                                    name='Output',activation=\"sigmoid\"))#,kernel_regularizer=tf.keras.regularizers.l2(0.04)))                              \n",
    "  \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=my_learning_rate,momentum=0.1),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, x,y, epochs, label_name,\n",
    "                batch_size=None):\n",
    "\n",
    "    #features = {name:np.array(value) for name, value in dataset.items()}\n",
    "    #label=dataset[label_name].to_numpy()\n",
    "    history = model.fit(x=x, y=y, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, verbose=1,validation_split=0.2) \n",
    "    \n",
    "    epochs = history.epoch\n",
    "  \n",
    "    df_hist = pd.DataFrame(history.history)\n",
    "    #hist.head()\n",
    "    #mse = hist[\"mean_squared_error\"]\n",
    "    mae = df_hist[\"mean_squared_error\"].to_numpy()\n",
    "    val_mae = df_hist[\"val_mean_squared_error\"].to_numpy()\n",
    "    return epochs,mae,val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:Layer dense_340 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9329 - mean_squared_error: 0.93 - 0s 70ms/step - loss: 0.9385 - mean_squared_error: 0.9385 - val_loss: 0.9229 - val_mean_squared_error: 0.9229\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9101 - mean_squared_error: 0.91 - 0s 39ms/step - loss: 0.9073 - mean_squared_error: 0.9073 - val_loss: 0.8939 - val_mean_squared_error: 0.8939\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8814 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8782 - mean_squared_error: 0.87 - 0s 41ms/step - loss: 0.8782 - mean_squared_error: 0.8782 - val_loss: 0.8683 - val_mean_squared_error: 0.8683\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8605 - mean_squared_error: 0.86 - 0s 39ms/step - loss: 0.8523 - mean_squared_error: 0.8523 - val_loss: 0.8457 - val_mean_squared_error: 0.8457\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8341 - mean_squared_error: 0.83 - ETA: 0s - loss: 0.8293 - mean_squared_error: 0.82 - 0s 41ms/step - loss: 0.8293 - mean_squared_error: 0.8293 - val_loss: 0.8271 - val_mean_squared_error: 0.8271\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8079 - mean_squared_error: 0.80 - ETA: 0s - loss: 0.8096 - mean_squared_error: 0.80 - 0s 42ms/step - loss: 0.8096 - mean_squared_error: 0.8096 - val_loss: 0.8100 - val_mean_squared_error: 0.8100\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7907 - mean_squared_error: 0.79 - ETA: 0s - loss: 0.7916 - mean_squared_error: 0.79 - 0s 41ms/step - loss: 0.7916 - mean_squared_error: 0.7916 - val_loss: 0.7947 - val_mean_squared_error: 0.7947\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7752 - mean_squared_error: 0.77 - ETA: 0s - loss: 0.7757 - mean_squared_error: 0.77 - 0s 42ms/step - loss: 0.7757 - mean_squared_error: 0.7757 - val_loss: 0.7816 - val_mean_squared_error: 0.7816\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7657 - mean_squared_error: 0.76 - 0s 38ms/step - loss: 0.7622 - mean_squared_error: 0.7622 - val_loss: 0.7719 - val_mean_squared_error: 0.7719\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7549 - mean_squared_error: 0.75 - ETA: 0s - loss: 0.7518 - mean_squared_error: 0.75 - 0s 44ms/step - loss: 0.7518 - mean_squared_error: 0.7518 - val_loss: 0.7636 - val_mean_squared_error: 0.7636\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7365 - mean_squared_error: 0.73 - ETA: 0s - loss: 0.7428 - mean_squared_error: 0.74 - 0s 42ms/step - loss: 0.7428 - mean_squared_error: 0.7428 - val_loss: 0.7557 - val_mean_squared_error: 0.7557\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7344 - mean_squared_error: 0.73 - ETA: 0s - loss: 0.7346 - mean_squared_error: 0.73 - 0s 41ms/step - loss: 0.7346 - mean_squared_error: 0.7346 - val_loss: 0.7495 - val_mean_squared_error: 0.7495\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7349 - mean_squared_error: 0.73 - ETA: 0s - loss: 0.7279 - mean_squared_error: 0.72 - 0s 42ms/step - loss: 0.7279 - mean_squared_error: 0.7279 - val_loss: 0.7443 - val_mean_squared_error: 0.7443\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7166 - mean_squared_error: 0.71 - 0s 39ms/step - loss: 0.7225 - mean_squared_error: 0.7225 - val_loss: 0.7397 - val_mean_squared_error: 0.7397\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7199 - mean_squared_error: 0.71 - ETA: 0s - loss: 0.7174 - mean_squared_error: 0.71 - 0s 43ms/step - loss: 0.7174 - mean_squared_error: 0.7174 - val_loss: 0.7361 - val_mean_squared_error: 0.7361\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7139 - mean_squared_error: 0.71 - ETA: 0s - loss: 0.7135 - mean_squared_error: 0.71 - 0s 42ms/step - loss: 0.7135 - mean_squared_error: 0.7135 - val_loss: 0.7329 - val_mean_squared_error: 0.7329\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7077 - mean_squared_error: 0.70 - ETA: 0s - loss: 0.7100 - mean_squared_error: 0.71 - 0s 43ms/step - loss: 0.7100 - mean_squared_error: 0.7100 - val_loss: 0.7301 - val_mean_squared_error: 0.7301\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7054 - mean_squared_error: 0.70 - 0s 39ms/step - loss: 0.7070 - mean_squared_error: 0.7070 - val_loss: 0.7278 - val_mean_squared_error: 0.7278\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7041 - mean_squared_error: 0.70 - ETA: 0s - loss: 0.7046 - mean_squared_error: 0.70 - 0s 42ms/step - loss: 0.7046 - mean_squared_error: 0.7046 - val_loss: 0.7256 - val_mean_squared_error: 0.7256\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7025 - mean_squared_error: 0.70 - ETA: 0s - loss: 0.7023 - mean_squared_error: 0.70 - 0s 41ms/step - loss: 0.7023 - mean_squared_error: 0.7023 - val_loss: 0.7235 - val_mean_squared_error: 0.7235\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7016 - mean_squared_error: 0.70 - ETA: 0s - loss: 0.7001 - mean_squared_error: 0.70 - 0s 42ms/step - loss: 0.7001 - mean_squared_error: 0.7001 - val_loss: 0.7216 - val_mean_squared_error: 0.7216\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7068 - mean_squared_error: 0.70 - 0s 39ms/step - loss: 0.6982 - mean_squared_error: 0.6982 - val_loss: 0.7201 - val_mean_squared_error: 0.7201\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6985 - mean_squared_error: 0.69 - ETA: 0s - loss: 0.6965 - mean_squared_error: 0.69 - 0s 42ms/step - loss: 0.6965 - mean_squared_error: 0.6965 - val_loss: 0.7184 - val_mean_squared_error: 0.7184\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6995 - mean_squared_error: 0.69 - ETA: 0s - loss: 0.6950 - mean_squared_error: 0.69 - 0s 42ms/step - loss: 0.6950 - mean_squared_error: 0.6950 - val_loss: 0.7170 - val_mean_squared_error: 0.7170\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6857 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6935 - mean_squared_error: 0.69 - 0s 44ms/step - loss: 0.6935 - mean_squared_error: 0.6935 - val_loss: 0.7155 - val_mean_squared_error: 0.7155\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6949 - mean_squared_error: 0.69 - 0s 39ms/step - loss: 0.6920 - mean_squared_error: 0.6920 - val_loss: 0.7144 - val_mean_squared_error: 0.7144\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6923 - mean_squared_error: 0.69 - ETA: 0s - loss: 0.6908 - mean_squared_error: 0.69 - 0s 42ms/step - loss: 0.6908 - mean_squared_error: 0.6908 - val_loss: 0.7135 - val_mean_squared_error: 0.7135\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6902 - mean_squared_error: 0.69 - ETA: 0s - loss: 0.6898 - mean_squared_error: 0.68 - 0s 41ms/step - loss: 0.6898 - mean_squared_error: 0.6898 - val_loss: 0.7123 - val_mean_squared_error: 0.7123\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6782 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6885 - mean_squared_error: 0.68 - 0s 43ms/step - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.7112 - val_mean_squared_error: 0.7112\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6863 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6874 - mean_squared_error: 0.68 - 0s 43ms/step - loss: 0.6874 - mean_squared_error: 0.6874 - val_loss: 0.7101 - val_mean_squared_error: 0.7101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6830 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6865 - mean_squared_error: 0.68 - 0s 42ms/step - loss: 0.6865 - mean_squared_error: 0.6865 - val_loss: 0.7093 - val_mean_squared_error: 0.7093\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6878 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6857 - mean_squared_error: 0.68 - 0s 41ms/step - loss: 0.6857 - mean_squared_error: 0.6857 - val_loss: 0.7086 - val_mean_squared_error: 0.7086\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6875 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6849 - mean_squared_error: 0.68 - 0s 42ms/step - loss: 0.6849 - mean_squared_error: 0.6849 - val_loss: 0.7080 - val_mean_squared_error: 0.7080\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6841 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6843 - mean_squared_error: 0.68 - 0s 41ms/step - loss: 0.6843 - mean_squared_error: 0.6843 - val_loss: 0.7074 - val_mean_squared_error: 0.7074\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6858 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6836 - mean_squared_error: 0.68 - 0s 43ms/step - loss: 0.6836 - mean_squared_error: 0.6836 - val_loss: 0.7068 - val_mean_squared_error: 0.7068\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6884 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6830 - mean_squared_error: 0.68 - 0s 42ms/step - loss: 0.6830 - mean_squared_error: 0.6830 - val_loss: 0.7063 - val_mean_squared_error: 0.7063\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6832 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6824 - mean_squared_error: 0.68 - 0s 41ms/step - loss: 0.6824 - mean_squared_error: 0.6824 - val_loss: 0.7058 - val_mean_squared_error: 0.7058\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6710 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6819 - mean_squared_error: 0.68 - 0s 41ms/step - loss: 0.6819 - mean_squared_error: 0.6819 - val_loss: 0.7052 - val_mean_squared_error: 0.7052\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6829 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6813 - mean_squared_error: 0.68 - 0s 41ms/step - loss: 0.6813 - mean_squared_error: 0.6813 - val_loss: 0.7048 - val_mean_squared_error: 0.7048\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6867 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6808 - mean_squared_error: 0.68 - 0s 41ms/step - loss: 0.6808 - mean_squared_error: 0.6808 - val_loss: 0.7043 - val_mean_squared_error: 0.7043\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6783 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6803 - mean_squared_error: 0.6803 - val_loss: 0.7038 - val_mean_squared_error: 0.7038\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6853 - mean_squared_error: 0.68 - 0s 39ms/step - loss: 0.6798 - mean_squared_error: 0.6798 - val_loss: 0.7035 - val_mean_squared_error: 0.7035\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6776 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6795 - mean_squared_error: 0.67 - 0s 43ms/step - loss: 0.6795 - mean_squared_error: 0.6795 - val_loss: 0.7031 - val_mean_squared_error: 0.7031\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6844 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6791 - mean_squared_error: 0.67 - 0s 45ms/step - loss: 0.6791 - mean_squared_error: 0.6791 - val_loss: 0.7028 - val_mean_squared_error: 0.7028\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6845 - mean_squared_error: 0.68 - 0s 39ms/step - loss: 0.6787 - mean_squared_error: 0.6787 - val_loss: 0.7025 - val_mean_squared_error: 0.7025\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6804 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6783 - mean_squared_error: 0.67 - 0s 43ms/step - loss: 0.6783 - mean_squared_error: 0.6783 - val_loss: 0.7021 - val_mean_squared_error: 0.7021\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6778 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6780 - mean_squared_error: 0.67 - 0s 41ms/step - loss: 0.6780 - mean_squared_error: 0.6780 - val_loss: 0.7018 - val_mean_squared_error: 0.7018\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6726 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6776 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6776 - mean_squared_error: 0.6776 - val_loss: 0.7015 - val_mean_squared_error: 0.7015\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6757 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6773 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6773 - mean_squared_error: 0.6773 - val_loss: 0.7012 - val_mean_squared_error: 0.7012\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6747 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6769 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6769 - mean_squared_error: 0.6769 - val_loss: 0.7008 - val_mean_squared_error: 0.7008\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6710 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6766 - mean_squared_error: 0.6766 - val_loss: 0.7005 - val_mean_squared_error: 0.7005\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6759 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6764 - mean_squared_error: 0.6764 - val_loss: 0.7002 - val_mean_squared_error: 0.7002\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6820 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6760 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6760 - mean_squared_error: 0.6760 - val_loss: 0.6999 - val_mean_squared_error: 0.6999\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6750 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6758 - mean_squared_error: 0.67 - 0s 43ms/step - loss: 0.6758 - mean_squared_error: 0.6758 - val_loss: 0.6998 - val_mean_squared_error: 0.6998\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6724 - mean_squared_error: 0.67 - 0s 40ms/step - loss: 0.6756 - mean_squared_error: 0.6756 - val_loss: 0.6994 - val_mean_squared_error: 0.6994\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6783 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6753 - mean_squared_error: 0.67 - 0s 41ms/step - loss: 0.6753 - mean_squared_error: 0.6753 - val_loss: 0.6992 - val_mean_squared_error: 0.6992\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6774 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6751 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6751 - mean_squared_error: 0.6751 - val_loss: 0.6989 - val_mean_squared_error: 0.6989\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6783 - mean_squared_error: 0.67 - 0s 40ms/step - loss: 0.6748 - mean_squared_error: 0.6748 - val_loss: 0.6987 - val_mean_squared_error: 0.6987\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6794 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6746 - mean_squared_error: 0.67 - 0s 41ms/step - loss: 0.6746 - mean_squared_error: 0.6746 - val_loss: 0.6985 - val_mean_squared_error: 0.6985\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6740 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6744 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6744 - mean_squared_error: 0.6744 - val_loss: 0.6983 - val_mean_squared_error: 0.6983\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6739 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6743 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6743 - mean_squared_error: 0.6743 - val_loss: 0.6981 - val_mean_squared_error: 0.6981\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6685 - mean_squared_error: 0.66 - 0s 38ms/step - loss: 0.6741 - mean_squared_error: 0.6741 - val_loss: 0.6979 - val_mean_squared_error: 0.6979\n",
      "Epoch 63/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6815 - mean_squared_error: 0.68 - ETA: 0s - loss: 0.6739 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6739 - mean_squared_error: 0.6739 - val_loss: 0.6977 - val_mean_squared_error: 0.6977\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6737 - mean_squared_error: 0.67 - 0s 44ms/step - loss: 0.6737 - mean_squared_error: 0.6737 - val_loss: 0.6975 - val_mean_squared_error: 0.6975\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6765 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6735 - mean_squared_error: 0.6735 - val_loss: 0.6973 - val_mean_squared_error: 0.6973\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6700 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6734 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6734 - mean_squared_error: 0.6734 - val_loss: 0.6971 - val_mean_squared_error: 0.6971\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6709 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6732 - mean_squared_error: 0.6732 - val_loss: 0.6969 - val_mean_squared_error: 0.6969\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6718 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6730 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6730 - mean_squared_error: 0.6730 - val_loss: 0.6968 - val_mean_squared_error: 0.6968\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6647 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6729 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6729 - mean_squared_error: 0.6729 - val_loss: 0.6967 - val_mean_squared_error: 0.6967\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6728 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6728 - mean_squared_error: 0.6728 - val_loss: 0.6966 - val_mean_squared_error: 0.6966\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6744 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6726 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6726 - mean_squared_error: 0.6726 - val_loss: 0.6964 - val_mean_squared_error: 0.6964\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6701 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6725 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6725 - mean_squared_error: 0.6725 - val_loss: 0.6962 - val_mean_squared_error: 0.6962\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6692 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6724 - mean_squared_error: 0.6724 - val_loss: 0.6961 - val_mean_squared_error: 0.6961\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6752 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6723 - mean_squared_error: 0.67 - 0s 45ms/step - loss: 0.6723 - mean_squared_error: 0.6723 - val_loss: 0.6960 - val_mean_squared_error: 0.6960\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6782 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6722 - mean_squared_error: 0.67 - 0s 43ms/step - loss: 0.6722 - mean_squared_error: 0.6722 - val_loss: 0.6959 - val_mean_squared_error: 0.6959\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6697 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6721 - mean_squared_error: 0.67 - 0s 43ms/step - loss: 0.6721 - mean_squared_error: 0.6721 - val_loss: 0.6957 - val_mean_squared_error: 0.6957\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6691 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6719 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6719 - mean_squared_error: 0.6719 - val_loss: 0.6956 - val_mean_squared_error: 0.6956\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6702 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6718 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6718 - mean_squared_error: 0.6718 - val_loss: 0.6955 - val_mean_squared_error: 0.6955\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6751 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6717 - mean_squared_error: 0.67 - 0s 43ms/step - loss: 0.6717 - mean_squared_error: 0.6717 - val_loss: 0.6954 - val_mean_squared_error: 0.6954\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6717 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6717 - mean_squared_error: 0.6717 - val_loss: 0.6953 - val_mean_squared_error: 0.6953\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6694 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6716 - mean_squared_error: 0.67 - 0s 41ms/step - loss: 0.6716 - mean_squared_error: 0.6716 - val_loss: 0.6953 - val_mean_squared_error: 0.6953\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6737 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6715 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6715 - mean_squared_error: 0.6715 - val_loss: 0.6952 - val_mean_squared_error: 0.6952\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6730 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6714 - mean_squared_error: 0.67 - 0s 46ms/step - loss: 0.6714 - mean_squared_error: 0.6714 - val_loss: 0.6951 - val_mean_squared_error: 0.6951\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6696 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6713 - mean_squared_error: 0.67 - 0s 41ms/step - loss: 0.6713 - mean_squared_error: 0.6713 - val_loss: 0.6950 - val_mean_squared_error: 0.6950\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6712 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6712 - mean_squared_error: 0.6712 - val_loss: 0.6950 - val_mean_squared_error: 0.6950\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6634 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6711 - mean_squared_error: 0.67 - 0s 45ms/step - loss: 0.6711 - mean_squared_error: 0.6711 - val_loss: 0.6948 - val_mean_squared_error: 0.6948\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6739 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6710 - mean_squared_error: 0.67 - 0s 47ms/step - loss: 0.6710 - mean_squared_error: 0.6710 - val_loss: 0.6947 - val_mean_squared_error: 0.6947\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6712 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6709 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6709 - mean_squared_error: 0.6709 - val_loss: 0.6946 - val_mean_squared_error: 0.6946\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6757 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6708 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6708 - mean_squared_error: 0.6708 - val_loss: 0.6946 - val_mean_squared_error: 0.6946\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6720 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6708 - mean_squared_error: 0.6708 - val_loss: 0.6945 - val_mean_squared_error: 0.6945\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6742 - mean_squared_error: 0.67 - 0s 38ms/step - loss: 0.6707 - mean_squared_error: 0.6707 - val_loss: 0.6944 - val_mean_squared_error: 0.6944\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6703 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6706 - mean_squared_error: 0.67 - 0s 50ms/step - loss: 0.6706 - mean_squared_error: 0.6706 - val_loss: 0.6943 - val_mean_squared_error: 0.6943\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6686 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6706 - mean_squared_error: 0.6706 - val_loss: 0.6942 - val_mean_squared_error: 0.6942\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6705 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6705 - mean_squared_error: 0.6705 - val_loss: 0.6942 - val_mean_squared_error: 0.6942\n",
      "Epoch 95/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6694 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6704 - mean_squared_error: 0.67 - 0s 43ms/step - loss: 0.6704 - mean_squared_error: 0.6704 - val_loss: 0.6941 - val_mean_squared_error: 0.6941\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6781 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6703 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6703 - mean_squared_error: 0.6703 - val_loss: 0.6941 - val_mean_squared_error: 0.6941\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6636 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6703 - mean_squared_error: 0.6703 - val_loss: 0.6940 - val_mean_squared_error: 0.6940\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - 0s 38ms/step - loss: 0.6702 - mean_squared_error: 0.6702 - val_loss: 0.6939 - val_mean_squared_error: 0.6939\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6754 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6701 - mean_squared_error: 0.6701 - val_loss: 0.6939 - val_mean_squared_error: 0.6939\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6701 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6701 - mean_squared_error: 0.6701 - val_loss: 0.6938 - val_mean_squared_error: 0.6938\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6742 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6700 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6700 - mean_squared_error: 0.6700 - val_loss: 0.6937 - val_mean_squared_error: 0.6937\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6726 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6700 - mean_squared_error: 0.67 - 0s 42ms/step - loss: 0.6700 - mean_squared_error: 0.6700 - val_loss: 0.6937 - val_mean_squared_error: 0.6937\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6711 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6699 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6699 - mean_squared_error: 0.6699 - val_loss: 0.6936 - val_mean_squared_error: 0.6936\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6757 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6698 - mean_squared_error: 0.6698 - val_loss: 0.6936 - val_mean_squared_error: 0.6936\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6722 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6698 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6698 - mean_squared_error: 0.6698 - val_loss: 0.6936 - val_mean_squared_error: 0.6936\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6732 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6697 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6697 - mean_squared_error: 0.6697 - val_loss: 0.6935 - val_mean_squared_error: 0.6935\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6701 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6697 - mean_squared_error: 0.6697 - val_loss: 0.6934 - val_mean_squared_error: 0.6934\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6709 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6696 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6696 - mean_squared_error: 0.6696 - val_loss: 0.6934 - val_mean_squared_error: 0.6934\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6715 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6695 - mean_squared_error: 0.66 - 0s 46ms/step - loss: 0.6695 - mean_squared_error: 0.6695 - val_loss: 0.6933 - val_mean_squared_error: 0.6933\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6730 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6695 - mean_squared_error: 0.6695 - val_loss: 0.6933 - val_mean_squared_error: 0.6933\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6694 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6694 - mean_squared_error: 0.6694 - val_loss: 0.6932 - val_mean_squared_error: 0.6932\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6769 - mean_squared_error: 0.67 - 0s 41ms/step - loss: 0.6694 - mean_squared_error: 0.6694 - val_loss: 0.6932 - val_mean_squared_error: 0.6932\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6707 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6693 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6693 - mean_squared_error: 0.6693 - val_loss: 0.6931 - val_mean_squared_error: 0.6931\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6740 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6693 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6693 - mean_squared_error: 0.6693 - val_loss: 0.6930 - val_mean_squared_error: 0.6930\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6725 - mean_squared_error: 0.67 - 0s 38ms/step - loss: 0.6693 - mean_squared_error: 0.6693 - val_loss: 0.6930 - val_mean_squared_error: 0.6930\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6688 - mean_squared_error: 0.66 - 0s 38ms/step - loss: 0.6692 - mean_squared_error: 0.6692 - val_loss: 0.6929 - val_mean_squared_error: 0.6929\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6645 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6692 - mean_squared_error: 0.6692 - val_loss: 0.6929 - val_mean_squared_error: 0.6929\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6616 - mean_squared_error: 0.66 - 0s 38ms/step - loss: 0.6691 - mean_squared_error: 0.6691 - val_loss: 0.6929 - val_mean_squared_error: 0.6929\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6653 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6691 - mean_squared_error: 0.6691 - val_loss: 0.6928 - val_mean_squared_error: 0.6928\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6690 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6690 - mean_squared_error: 0.6690 - val_loss: 0.6928 - val_mean_squared_error: 0.6928\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6741 - mean_squared_error: 0.67 - 0s 40ms/step - loss: 0.6690 - mean_squared_error: 0.6690 - val_loss: 0.6928 - val_mean_squared_error: 0.6928\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6657 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6690 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6690 - mean_squared_error: 0.6690 - val_loss: 0.6928 - val_mean_squared_error: 0.6928\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6727 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6689 - mean_squared_error: 0.6689 - val_loss: 0.6927 - val_mean_squared_error: 0.6927\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6599 - mean_squared_error: 0.65 - 0s 40ms/step - loss: 0.6689 - mean_squared_error: 0.6689 - val_loss: 0.6926 - val_mean_squared_error: 0.6926\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6673 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6689 - mean_squared_error: 0.6689 - val_loss: 0.6926 - val_mean_squared_error: 0.6926\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6688 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6688 - mean_squared_error: 0.6688 - val_loss: 0.6925 - val_mean_squared_error: 0.6925\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6673 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6688 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6688 - mean_squared_error: 0.6688 - val_loss: 0.6924 - val_mean_squared_error: 0.6924\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6739 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6687 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6687 - mean_squared_error: 0.6687 - val_loss: 0.6924 - val_mean_squared_error: 0.6924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6687 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6687 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6687 - mean_squared_error: 0.6687 - val_loss: 0.6924 - val_mean_squared_error: 0.6924\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6711 - mean_squared_error: 0.67 - 0s 38ms/step - loss: 0.6687 - mean_squared_error: 0.6687 - val_loss: 0.6924 - val_mean_squared_error: 0.6924\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6694 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6686 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6686 - mean_squared_error: 0.6686 - val_loss: 0.6924 - val_mean_squared_error: 0.6924\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6703 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6686 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6686 - mean_squared_error: 0.6686 - val_loss: 0.6923 - val_mean_squared_error: 0.6923\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6679 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6686 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6686 - mean_squared_error: 0.6686 - val_loss: 0.6923 - val_mean_squared_error: 0.6923\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6740 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6685 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6685 - mean_squared_error: 0.6685 - val_loss: 0.6923 - val_mean_squared_error: 0.6923\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6697 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6685 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6685 - mean_squared_error: 0.6685 - val_loss: 0.6923 - val_mean_squared_error: 0.6923\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6625 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6685 - mean_squared_error: 0.66 - 0s 45ms/step - loss: 0.6685 - mean_squared_error: 0.6685 - val_loss: 0.6923 - val_mean_squared_error: 0.6923\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6685 - mean_squared_error: 0.6685 - val_loss: 0.6923 - val_mean_squared_error: 0.6923\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6684 - mean_squared_error: 0.6684 - val_loss: 0.6922 - val_mean_squared_error: 0.6922\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6699 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6684 - mean_squared_error: 0.6684 - val_loss: 0.6922 - val_mean_squared_error: 0.6922\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6733 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6683 - mean_squared_error: 0.6683 - val_loss: 0.6921 - val_mean_squared_error: 0.6921\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6700 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6683 - mean_squared_error: 0.6683 - val_loss: 0.6921 - val_mean_squared_error: 0.6921\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6741 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - 0s 46ms/step - loss: 0.6683 - mean_squared_error: 0.6683 - val_loss: 0.6921 - val_mean_squared_error: 0.6921\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6683 - mean_squared_error: 0.6683 - val_loss: 0.6921 - val_mean_squared_error: 0.6921\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6605 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6682 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6682 - mean_squared_error: 0.6682 - val_loss: 0.6920 - val_mean_squared_error: 0.6920\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6700 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6682 - mean_squared_error: 0.6682 - val_loss: 0.6920 - val_mean_squared_error: 0.6920\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6682 - mean_squared_error: 0.6682 - val_loss: 0.6920 - val_mean_squared_error: 0.6920\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6682 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6682 - mean_squared_error: 0.6682 - val_loss: 0.6920 - val_mean_squared_error: 0.6920\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6680 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6681 - mean_squared_error: 0.6681 - val_loss: 0.6920 - val_mean_squared_error: 0.6920\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6697 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6681 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6681 - mean_squared_error: 0.6681 - val_loss: 0.6919 - val_mean_squared_error: 0.6919\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6702 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6681 - mean_squared_error: 0.6681 - val_loss: 0.6919 - val_mean_squared_error: 0.6919\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6622 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6680 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6680 - mean_squared_error: 0.6680 - val_loss: 0.6918 - val_mean_squared_error: 0.6918\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6678 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6680 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6680 - mean_squared_error: 0.6680 - val_loss: 0.6918 - val_mean_squared_error: 0.6918\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6623 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6680 - mean_squared_error: 0.6680 - val_loss: 0.6918 - val_mean_squared_error: 0.6918\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6715 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6680 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6680 - mean_squared_error: 0.6680 - val_loss: 0.6918 - val_mean_squared_error: 0.6918\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6642 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6679 - mean_squared_error: 0.6679 - val_loss: 0.6918 - val_mean_squared_error: 0.6918\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6681 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6679 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6679 - mean_squared_error: 0.6679 - val_loss: 0.6918 - val_mean_squared_error: 0.6918\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6613 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6679 - mean_squared_error: 0.6679 - val_loss: 0.6917 - val_mean_squared_error: 0.6917\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6641 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6679 - mean_squared_error: 0.6679 - val_loss: 0.6917 - val_mean_squared_error: 0.6917\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6691 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6678 - mean_squared_error: 0.6678 - val_loss: 0.6917 - val_mean_squared_error: 0.6917\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6723 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6678 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6678 - mean_squared_error: 0.6678 - val_loss: 0.6917 - val_mean_squared_error: 0.6917\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6678 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6678 - mean_squared_error: 0.6678 - val_loss: 0.6917 - val_mean_squared_error: 0.6917\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6704 - mean_squared_error: 0.67 - 0s 38ms/step - loss: 0.6678 - mean_squared_error: 0.6678 - val_loss: 0.6917 - val_mean_squared_error: 0.6917\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6712 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6678 - mean_squared_error: 0.6678 - val_loss: 0.6917 - val_mean_squared_error: 0.6917\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6682 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6677 - mean_squared_error: 0.6677 - val_loss: 0.6916 - val_mean_squared_error: 0.6916\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6695 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6677 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6677 - mean_squared_error: 0.6677 - val_loss: 0.6916 - val_mean_squared_error: 0.6916\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6621 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6677 - mean_squared_error: 0.6677 - val_loss: 0.6916 - val_mean_squared_error: 0.6916\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6626 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6677 - mean_squared_error: 0.6677 - val_loss: 0.6916 - val_mean_squared_error: 0.6916\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6649 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6677 - mean_squared_error: 0.6677 - val_loss: 0.6916 - val_mean_squared_error: 0.6916\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6743 - mean_squared_error: 0.67 - 0s 40ms/step - loss: 0.6676 - mean_squared_error: 0.6676 - val_loss: 0.6916 - val_mean_squared_error: 0.6916\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6725 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6676 - mean_squared_error: 0.6676 - val_loss: 0.6916 - val_mean_squared_error: 0.6916\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6615 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6676 - mean_squared_error: 0.6676 - val_loss: 0.6915 - val_mean_squared_error: 0.6915\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6676 - mean_squared_error: 0.6676 - val_loss: 0.6915 - val_mean_squared_error: 0.6915\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6714 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6676 - mean_squared_error: 0.6676 - val_loss: 0.6915 - val_mean_squared_error: 0.6915\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6626 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6676 - mean_squared_error: 0.6676 - val_loss: 0.6916 - val_mean_squared_error: 0.6916\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6691 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6676 - mean_squared_error: 0.6676 - val_loss: 0.6915 - val_mean_squared_error: 0.6915\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6636 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6675 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6675 - mean_squared_error: 0.6675 - val_loss: 0.6915 - val_mean_squared_error: 0.6915\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6705 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6675 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6675 - mean_squared_error: 0.6675 - val_loss: 0.6915 - val_mean_squared_error: 0.6915\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6701 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6675 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6675 - mean_squared_error: 0.6675 - val_loss: 0.6915 - val_mean_squared_error: 0.6915\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6678 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6675 - mean_squared_error: 0.66 - 0s 46ms/step - loss: 0.6675 - mean_squared_error: 0.6675 - val_loss: 0.6915 - val_mean_squared_error: 0.6915\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6698 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6675 - mean_squared_error: 0.6675 - val_loss: 0.6915 - val_mean_squared_error: 0.6915\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6675 - mean_squared_error: 0.66 - 0s 47ms/step - loss: 0.6675 - mean_squared_error: 0.6675 - val_loss: 0.6914 - val_mean_squared_error: 0.6914\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6679 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6675 - mean_squared_error: 0.66 - 0s 45ms/step - loss: 0.6675 - mean_squared_error: 0.6675 - val_loss: 0.6914 - val_mean_squared_error: 0.6914\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6693 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6674 - mean_squared_error: 0.66 - 0s 47ms/step - loss: 0.6674 - mean_squared_error: 0.6674 - val_loss: 0.6914 - val_mean_squared_error: 0.6914\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6718 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6674 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6674 - mean_squared_error: 0.6674 - val_loss: 0.6914 - val_mean_squared_error: 0.6914\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6689 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6674 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6674 - mean_squared_error: 0.6674 - val_loss: 0.6913 - val_mean_squared_error: 0.6913\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6672 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6674 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6674 - mean_squared_error: 0.6674 - val_loss: 0.6913 - val_mean_squared_error: 0.6913\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6674 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6674 - mean_squared_error: 0.6674 - val_loss: 0.6913 - val_mean_squared_error: 0.6913\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6615 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6674 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6674 - mean_squared_error: 0.6674 - val_loss: 0.6913 - val_mean_squared_error: 0.6913\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6699 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6673 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6673 - mean_squared_error: 0.6673 - val_loss: 0.6913 - val_mean_squared_error: 0.6913\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6673 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6673 - mean_squared_error: 0.6673 - val_loss: 0.6912 - val_mean_squared_error: 0.6912\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6707 - mean_squared_error: 0.67 - 0s 38ms/step - loss: 0.6673 - mean_squared_error: 0.6673 - val_loss: 0.6912 - val_mean_squared_error: 0.6912\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6633 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6673 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6673 - mean_squared_error: 0.6673 - val_loss: 0.6912 - val_mean_squared_error: 0.6912\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6619 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6673 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6673 - mean_squared_error: 0.6673 - val_loss: 0.6912 - val_mean_squared_error: 0.6912\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6642 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6673 - mean_squared_error: 0.6673 - val_loss: 0.6912 - val_mean_squared_error: 0.6912\n",
      "Epoch 195/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6609 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6673 - mean_squared_error: 0.6673 - val_loss: 0.6912 - val_mean_squared_error: 0.6912\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6597 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6672 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6672 - mean_squared_error: 0.6672 - val_loss: 0.6911 - val_mean_squared_error: 0.6911\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6672 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6672 - mean_squared_error: 0.6672 - val_loss: 0.6911 - val_mean_squared_error: 0.6911\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6589 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6672 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6672 - mean_squared_error: 0.6672 - val_loss: 0.6910 - val_mean_squared_error: 0.6910\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6688 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6672 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6672 - mean_squared_error: 0.6672 - val_loss: 0.6910 - val_mean_squared_error: 0.6910\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6727 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6672 - mean_squared_error: 0.66 - 0s 45ms/step - loss: 0.6672 - mean_squared_error: 0.6672 - val_loss: 0.6910 - val_mean_squared_error: 0.6910\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6672 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6672 - mean_squared_error: 0.6672 - val_loss: 0.6910 - val_mean_squared_error: 0.6910\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6652 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6672 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6672 - mean_squared_error: 0.6672 - val_loss: 0.6910 - val_mean_squared_error: 0.6910\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6671 - mean_squared_error: 0.6671 - val_loss: 0.6910 - val_mean_squared_error: 0.6910\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6671 - mean_squared_error: 0.6671 - val_loss: 0.6909 - val_mean_squared_error: 0.6909\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6702 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6671 - mean_squared_error: 0.6671 - val_loss: 0.6909 - val_mean_squared_error: 0.6909\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6722 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6671 - mean_squared_error: 0.6671 - val_loss: 0.6909 - val_mean_squared_error: 0.6909\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6671 - mean_squared_error: 0.6671 - val_loss: 0.6909 - val_mean_squared_error: 0.6909\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6621 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6671 - mean_squared_error: 0.6671 - val_loss: 0.6909 - val_mean_squared_error: 0.6909\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6557 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6671 - mean_squared_error: 0.6671 - val_loss: 0.6909 - val_mean_squared_error: 0.6909\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6678 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6671 - mean_squared_error: 0.6671 - val_loss: 0.6908 - val_mean_squared_error: 0.6908\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6703 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6670 - mean_squared_error: 0.6670 - val_loss: 0.6908 - val_mean_squared_error: 0.6908\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6670 - mean_squared_error: 0.6670 - val_loss: 0.6908 - val_mean_squared_error: 0.6908\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6686 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6670 - mean_squared_error: 0.6670 - val_loss: 0.6908 - val_mean_squared_error: 0.6908\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6670 - mean_squared_error: 0.6670 - val_loss: 0.6908 - val_mean_squared_error: 0.6908\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6606 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6670 - mean_squared_error: 0.6670 - val_loss: 0.6908 - val_mean_squared_error: 0.6908\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6670 - mean_squared_error: 0.6670 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6717 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6670 - mean_squared_error: 0.6670 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6653 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6670 - mean_squared_error: 0.6670 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6709 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - 0s 46ms/step - loss: 0.6670 - mean_squared_error: 0.6670 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6642 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6725 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6734 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 46ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6715 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6639 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 49ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6643 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6907 - val_mean_squared_error: 0.6907\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6703 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6682 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6679 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6707 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6669 - mean_squared_error: 0.6669 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6646 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6684 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6644 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6653 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6681 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6628 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6906 - val_mean_squared_error: 0.6906\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6687 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6905 - val_mean_squared_error: 0.6905\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6715 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6905 - val_mean_squared_error: 0.6905\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6668 - mean_squared_error: 0.6668 - val_loss: 0.6905 - val_mean_squared_error: 0.6905\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6651 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6905 - val_mean_squared_error: 0.6905\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6677 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6905 - val_mean_squared_error: 0.6905\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6905 - val_mean_squared_error: 0.6905\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6642 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6905 - val_mean_squared_error: 0.6905\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6905 - val_mean_squared_error: 0.6905\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6636 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 46ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6905 - val_mean_squared_error: 0.6905\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6611 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6905 - val_mean_squared_error: 0.6905\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6675 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6904 - val_mean_squared_error: 0.6904\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6684 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6904 - val_mean_squared_error: 0.6904\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6645 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6904 - val_mean_squared_error: 0.6904\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6640 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6667 - mean_squared_error: 0.6667 - val_loss: 0.6904 - val_mean_squared_error: 0.6904\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6720 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6904 - val_mean_squared_error: 0.6904\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6638 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6904 - val_mean_squared_error: 0.6904\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6904 - val_mean_squared_error: 0.6904\n",
      "Epoch 257/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6692 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6649 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6674 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6675 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 47ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6603 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6696 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6685 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6672 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6724 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 45ms/step - loss: 0.6666 - mean_squared_error: 0.6666 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6710 - mean_squared_error: 0.67 - 0s 40ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6653 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6633 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6632 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6711 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6690 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6628 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 45ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6681 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6902 - val_mean_squared_error: 0.6902\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6645 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6902 - val_mean_squared_error: 0.6902\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6614 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6902 - val_mean_squared_error: 0.6902\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6902 - val_mean_squared_error: 0.6902\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6691 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6902 - val_mean_squared_error: 0.6902\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6665 - mean_squared_error: 0.6665 - val_loss: 0.6902 - val_mean_squared_error: 0.6902\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6613 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6902 - val_mean_squared_error: 0.6902\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6591 - mean_squared_error: 0.65 - 0s 39ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6902 - val_mean_squared_error: 0.6902\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6614 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6687 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6633 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6682 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6711 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6655 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6603 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6610 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6705 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6646 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6624 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6584 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6730 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6684 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6677 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6652 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6733 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6702 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6644 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6613 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6622 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6689 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6640 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6718 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6693 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6651 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6643 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6590 - mean_squared_error: 0.65 - 0s 39ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6698 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6682 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6647 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6654 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6735 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6685 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6698 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6656 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6685 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6616 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6663 - mean_squared_error: 0.6663 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6702 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6638 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6645 - mean_squared_error: 0.66 - 0s 38ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6707 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6647 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6701 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6680 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6900 - val_mean_squared_error: 0.6900\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6638 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6755 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6679 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6730 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 45ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6624 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6636 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6632 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6589 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6591 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6582 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6686 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6650 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6624 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 48ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6626 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6625 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6640 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - 0s 45ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6622 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6639 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6702 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 45ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6700 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 354/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6614 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6712 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6645 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6688 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6652 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6637 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6705 - mean_squared_error: 0.67 - 0s 38ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6673 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6667 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6656 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6645 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6711 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6705 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6642 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6707 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6676 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6652 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6673 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6708 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 46ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6606 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6602 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6654 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 45ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6617 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6657 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6661 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6650 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6793 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6661 - mean_squared_error: 0.6661 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6656 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 46ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6703 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6635 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6650 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6613 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6728 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6692 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6648 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6621 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6625 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6687 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6574 - mean_squared_error: 0.65 - 0s 39ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6651 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6653 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6607 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6723 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6706 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6634 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6590 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6617 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6635 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6633 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6612 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6607 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6611 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6648 - mean_squared_error: 0.66 - 0s 38ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6625 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6639 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6665 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6660 - mean_squared_error: 0.6660 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6664 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6589 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6682 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6629 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6657 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6679 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6575 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6649 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6899 - val_mean_squared_error: 0.6899\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6592 - mean_squared_error: 0.65 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6682 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6677 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6610 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6750 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6634 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6629 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6613 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6632 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6674 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6898 - val_mean_squared_error: 0.6898\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6594 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6624 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6693 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6640 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6700 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6640 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6690 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6683 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6654 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6640 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6713 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6612 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6649 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6573 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6678 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6647 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6677 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6700 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 453/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6622 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6630 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6692 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6654 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6614 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6646 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6671 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6702 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6690 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6691 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6659 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6602 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6659 - mean_squared_error: 0.6659 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6640 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6681 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6615 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6666 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6740 - mean_squared_error: 0.67 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6631 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6644 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6669 - mean_squared_error: 0.66 - 0s 38ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6679 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6693 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6674 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6677 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6662 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6635 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6698 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6704 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6696 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6605 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6591 - mean_squared_error: 0.65 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6751 - mean_squared_error: 0.67 - 0s 40ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6614 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6694 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6643 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6663 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6702 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6650 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6644 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6896 - val_mean_squared_error: 0.6896\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6668 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 44ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6670 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6625 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6674 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 41ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6678 - mean_squared_error: 0.66 - 0s 39ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6681 - mean_squared_error: 0.66 - 0s 40ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6660 - mean_squared_error: 0.66 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 42ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6730 - mean_squared_error: 0.67 - ETA: 0s - loss: 0.6658 - mean_squared_error: 0.66 - 0s 43ms/step - loss: 0.6658 - mean_squared_error: 0.6658 - val_loss: 0.6897 - val_mean_squared_error: 0.6897\n"
     ]
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "#data_train, data_test, labels_train, labels_test\n",
    "learning_rate = 1e-1\n",
    "epochs = 500\n",
    "batch_size = 400\n",
    "\n",
    "label_name = [\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]\n",
    "\n",
    "my_model = create_model(learning_rate, my_feature_layer_A)\n",
    "\n",
    "epochs, mse,val_mse = train_model(my_model, data_train,labels_train, epochs, \n",
    "                          label_name, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.6584 - mean_squared_error: 0.65 - 0s 1ms/step - loss: 0.6584 - mean_squared_error: 0.6584\n",
      "[0.6584183573722839, 0.6584183573722839]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k6a1_test</th>\n",
       "      <th>k6a2_test</th>\n",
       "      <th>k11_test</th>\n",
       "      <th>k12_test</th>\n",
       "      <th>k9a1_test</th>\n",
       "      <th>k9a2_test</th>\n",
       "      <th>k6a1_hat</th>\n",
       "      <th>k6a2_hat</th>\n",
       "      <th>k11_hat</th>\n",
       "      <th>k12_hat</th>\n",
       "      <th>k9a1_hat</th>\n",
       "      <th>k9a2_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>0.02823</td>\n",
       "      <td>0.029467</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.027512</td>\n",
       "      <td>0.042869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>0.02823</td>\n",
       "      <td>0.029467</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.027512</td>\n",
       "      <td>0.042869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>0.02823</td>\n",
       "      <td>0.029467</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.027512</td>\n",
       "      <td>0.042869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>0.02823</td>\n",
       "      <td>0.029467</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.027512</td>\n",
       "      <td>0.042869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>0.02823</td>\n",
       "      <td>0.029467</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.027512</td>\n",
       "      <td>0.042869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k6a1_test  k6a2_test  k11_test  k12_test  k9a1_test  k9a2_test  k6a1_hat  \\\n",
       "0        0.0        1.0       1.0       0.0       -1.0       -1.0  0.062683   \n",
       "1       -1.0        0.0       1.0       0.0        0.0        0.0  0.062683   \n",
       "2        0.0       -1.0       1.0      -1.0        0.0        1.0  0.062683   \n",
       "3        0.0        0.0       0.0      -1.0        0.0        0.0  0.062683   \n",
       "4        1.0       -1.0       0.0      -1.0       -1.0        1.0  0.062683   \n",
       "\n",
       "   k6a2_hat   k11_hat   k12_hat  k9a1_hat  k9a2_hat  \n",
       "0   0.02823  0.029467  0.025553  0.027512  0.042869  \n",
       "1   0.02823  0.029467  0.025553  0.027512  0.042869  \n",
       "2   0.02823  0.029467  0.025553  0.027512  0.042869  \n",
       "3   0.02823  0.029467  0.025553  0.027512  0.042869  \n",
       "4   0.02823  0.029467  0.025553  0.027512  0.042869  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = {name:np.array(value) for name, value in df_testing.items()}\n",
    "label=df_testing[label_name].to_numpy()\n",
    "#data_train, data_test, labels_train, labels_test\n",
    "plot_the_loss_curve(epochs, mse,val_mse)\n",
    "evaluation=my_model.evaluate(x = data_test, y = labels_test, batch_size=batch_size)\n",
    "predicted = my_model.predict(data_test)\n",
    "print(evaluation)\n",
    "\n",
    "\n",
    "\n",
    "df_test=pd.DataFrame(labels_test,columns=[\"k6a1_test\",\"k6a2_test\",\"k11_test\",\"k12_test\",\"k9a1_test\",\"k9a2_test\"])\n",
    "df_predict=pd.DataFrame(predicted,columns=[\"k6a1_hat\",\"k6a2_hat\",\"k11_hat\",\"k12_hat\",\"k9a1_hat\",\"k9a2_hat\"])\n",
    "pd.concat([df_test,df_predict], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.124  0.184  0.466  0.808  0.858  0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [ 0.462  0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [-0.932 -0.774 -0.706 -0.628 -0.488 -0.424 -0.34  -0.17  -0.086 -0.032\n",
      "   0.12   0.142  0.204  0.274  0.456  0.508  0.586  0.73   0.812  0.864\n",
      "   0.91   0.   ]\n",
      " [-0.42   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.   ]\n",
      " [-0.932 -0.772 -0.704 -0.628 -0.488 -0.424 -0.34  -0.178 -0.136 -0.084\n",
      "  -0.034  0.116  0.202  0.274  0.456  0.506  0.592  0.73   0.81   0.864\n",
      "   0.912  0.   ]]\n",
      "[[ 0.  1.  1.  0. -1. -1.]\n",
      " [-1.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1. -1.  0.  1.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 1. -1.  0. -1. -1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(data_test[0:5])\n",
    "print(labels_test[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
