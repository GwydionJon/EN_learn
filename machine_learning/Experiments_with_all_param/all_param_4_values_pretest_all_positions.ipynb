{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import kerastuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def plot_curve(epochs, hist, list_of_metrics,name):\n",
    "    \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch \"+name)\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    for m in list_of_metrics:\n",
    "        x = hist[m]\n",
    "        plt.plot(epochs[1:], x[1:], label=m)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "# for activation functions check https://keras.io/api/layers/activations/\n",
    "def create_model2(my_learning_rate,momentum,layers, my_feature_layer,my_metrics,my_act_function = \"softmax\"):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #model.add(my_feature_layer)\n",
    "\n",
    "    for layer in layers:\n",
    "        model.add(tf.keras.layers.Dense(units = layer, activation = my_act_function))\n",
    "    model.add(tf.keras.layers.Dense(units=8,name='Output', activation = 'relu'))                             \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=my_learning_rate,momentum=momentum),                                       \n",
    "                loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                metrics=my_metrics)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model,x_data, df_label, epochs, label_name,\n",
    "                batch_size=None,shuffle=True):\n",
    "    #features = {name:np.array(value) for name, value in dataset.items()}\n",
    "    label=df_label[label_name].to_numpy()\n",
    "    history = model.fit(x=x_data, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=shuffle,validation_split=0.2,\n",
    "                       callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)])\n",
    "  \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    return epochs, hist\n",
    "    \n",
    "    \n",
    "#returns dataframe\n",
    "def test_model(model,x_data, df_label ,label_name):\n",
    "    #features = {name:np.array(value) for name, value in dataset.items()}\n",
    "    label=df_label[label_name].to_numpy()\n",
    "   # print(label)\n",
    "    evaluation=model.evaluate(x = x_data, y = label, batch_size=batch_size)\n",
    "    predicted = model.predict(x_data)\n",
    "    \n",
    "    df_test=pd.DataFrame(label,columns=[label_name])\n",
    "   # print(predicted)\n",
    "    df_predict=pd.DataFrame(predicted,columns=[label+\"_pred\" for label in label_name])\n",
    "    return pd.concat([df_test,df_predict], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65464, 7)\n"
     ]
    }
   ],
   "source": [
    "#G:\\OneDrive - bwedu\\Master\\Forschungspraktikum\\Inga\\pc-forschi\\generated_Data\n",
    "all_data=pd.read_csv(\"G:\\OneDrive - bwedu\\Master\\Forschungspraktikum\\Inga\\pc-forschi\\generated_Data/all_param_4_values_complete.csv\")\n",
    "\n",
    "all_label_list=[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\",\"delta\",\"lambda\"]\n",
    "all_features_list=[\"all_maxima\",\"Intensity\"]\n",
    "\n",
    "#print(df_complete[\"all_maxima\"].values[10])\n",
    "\n",
    "\n",
    "all_maxima_array=np.asarray([  np.asarray([x for x in row.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"  \",\" \",5).replace(\" \",\";\").split(\";\") if x!=\"\"],dtype=np.float64)     for row in all_data[\"all_maxima\"] ])\n",
    "intensity_array=np.asarray([  np.asarray([x for x in row.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"  \",\" \",5).replace(\" \",\";\").split(\";\") if x!=\"\"],dtype=np.float64)     for row in all_data[\"Intensity\"] ])\n",
    "max_nr_of_peaks=max([len(i) for i in all_maxima_array])\n",
    "\n",
    "all_maxima_array_padded=np.zeros((all_maxima_array.shape[0],max_nr_of_peaks))\n",
    "#intensity_array_padded=np.zeros((intensity_array.shape[0],max_nr_of_peaks*))\n",
    "\n",
    "print(all_maxima_array_padded.shape)\n",
    "for i in range(len(all_maxima_array)):\n",
    "    for j in range(len(all_maxima_array[i])):\n",
    "        all_maxima_array_padded[i][j]=all_maxima_array[i][j]\n",
    "       # all_maxima_array_padded[i][j+7]=intensity_array[i][j]\n",
    "\n",
    "        \n",
    "        \n",
    "#print(all_maxima_array_padded)  \n",
    "df_label=all_data[all_label_list]\n",
    "\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split( all_maxima_array_padded, df_label  ,test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_A = []\n",
    "main_maximum = tf.feature_column.numeric_column(\"main_maximum\")\n",
    "feature_columns_A.append(main_maximum)\n",
    "no_of_max = tf.feature_column.numeric_column(\"no_of_max\")\n",
    "feature_columns_A.append(no_of_max)\n",
    "\n",
    "my_feature_layer_A = tf.keras.layers.DenseFeatures(feature_columns_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1450 - mean_absolute_error: 0.145 - ETA: 1s - loss: 0.1378 - mean_absolute_error: 0.137 - ETA: 1s - loss: 0.1279 - mean_absolute_error: 0.127 - ETA: 1s - loss: 0.1188 - mean_absolute_error: 0.118 - ETA: 1s - loss: 0.1101 - mean_absolute_error: 0.110 - ETA: 1s - loss: 0.1028 - mean_absolute_error: 0.102 - ETA: 1s - loss: 0.0979 - mean_absolute_error: 0.097 - ETA: 1s - loss: 0.0947 - mean_absolute_error: 0.094 - ETA: 1s - loss: 0.0922 - mean_absolute_error: 0.092 - ETA: 1s - loss: 0.0900 - mean_absolute_error: 0.090 - ETA: 1s - loss: 0.0885 - mean_absolute_error: 0.088 - ETA: 0s - loss: 0.0873 - mean_absolute_error: 0.087 - ETA: 0s - loss: 0.0861 - mean_absolute_error: 0.086 - ETA: 0s - loss: 0.0852 - mean_absolute_error: 0.085 - ETA: 0s - loss: 0.0844 - mean_absolute_error: 0.084 - ETA: 0s - loss: 0.0837 - mean_absolute_error: 0.083 - ETA: 0s - loss: 0.0831 - mean_absolute_error: 0.083 - ETA: 0s - loss: 0.0825 - mean_absolute_error: 0.082 - ETA: 0s - loss: 0.0820 - mean_absolute_error: 0.082 - ETA: 0s - loss: 0.0816 - mean_absolute_error: 0.081 - ETA: 0s - loss: 0.0812 - mean_absolute_error: 0.081 - ETA: 0s - loss: 0.0808 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0805 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0802 - mean_absolute_error: 0.080 - ETA: 0s - loss: 0.0799 - mean_absolute_error: 0.079 - ETA: 0s - loss: 0.0797 - mean_absolute_error: 0.079 - ETA: 0s - loss: 0.0794 - mean_absolute_error: 0.079 - ETA: 0s - loss: 0.0792 - mean_absolute_error: 0.079 - ETA: 0s - loss: 0.0790 - mean_absolute_error: 0.079 - ETA: 0s - loss: 0.0788 - mean_absolute_error: 0.078 - ETA: 0s - loss: 0.0786 - mean_absolute_error: 0.078 - 2s 6ms/step - loss: 0.0785 - mean_absolute_error: 0.0785 - val_loss: 0.0733 - val_mean_absolute_error: 0.0733\n",
      "Epoch 2/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0729 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0729 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0733 - mean_absolute_error: 0.073 - ETA: 1s - loss: 0.0732 - mean_absolute_error: 0.073 - ETA: 1s - loss: 0.0733 - mean_absolute_error: 0.073 - ETA: 1s - loss: 0.0734 - mean_absolute_error: 0.073 - ETA: 1s - loss: 0.0734 - mean_absolute_error: 0.073 - ETA: 1s - loss: 0.0734 - mean_absolute_error: 0.073 - ETA: 1s - loss: 0.0733 - mean_absolute_error: 0.073 - ETA: 1s - loss: 0.0733 - mean_absolute_error: 0.073 - ETA: 1s - loss: 0.0733 - mean_absolute_error: 0.073 - ETA: 1s - loss: 0.0733 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0733 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0733 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0733 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0732 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0732 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0731 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0731 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0731 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0731 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0731 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0731 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0731 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0731 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0731 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0730 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0730 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0730 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0730 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0730 - mean_absolute_error: 0.073 - ETA: 0s - loss: 0.0730 - mean_absolute_error: 0.073 - 2s 6ms/step - loss: 0.0730 - mean_absolute_error: 0.0730 - val_loss: 0.0728 - val_mean_absolute_error: 0.0728\n",
      "Epoch 3/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0709 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0727 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0727 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0728 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0728 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0729 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0729 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0728 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0728 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0728 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0727 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0727 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0727 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0727 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0727 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0727 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0727 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0726 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0726 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0726 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0726 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0726 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0726 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0726 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0726 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0725 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0725 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0725 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0725 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0725 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0725 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0725 - mean_absolute_error: 0.072 - 2s 6ms/step - loss: 0.0725 - mean_absolute_error: 0.0725 - val_loss: 0.0722 - val_mean_absolute_error: 0.0722\n",
      "Epoch 4/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0728 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0718 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0718 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0719 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0721 - mean_absolute_error: 0.072 - ETA: 1s - loss: 0.0721 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0721 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0721 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0721 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0721 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0721 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0720 - mean_absolute_error: 0.072 - ETA: 0s - loss: 0.0719 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0719 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0719 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0719 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0718 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0718 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0718 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0718 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0718 - mean_absolute_error: 0.071 - 2s 6ms/step - loss: 0.0718 - mean_absolute_error: 0.0718 - val_loss: 0.0715 - val_mean_absolute_error: 0.0715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0734 - mean_absolute_error: 0.073 - ETA: 1s - loss: 0.0711 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0711 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0710 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0710 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0711 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0711 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0712 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0711 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0711 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0711 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0711 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0711 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0710 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0710 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0710 - mean_absolute_error: 0.071 - ETA: 0s - loss: 0.0710 - mean_absolute_error: 0.071 - 2s 6ms/step - loss: 0.0710 - mean_absolute_error: 0.0710 - val_loss: 0.0706 - val_mean_absolute_error: 0.0706\n",
      "Epoch 6/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0718 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0708 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0708 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0709 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0709 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0710 - mean_absolute_error: 0.071 - ETA: 1s - loss: 0.0708 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0709 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0708 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0707 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0706 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0706 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0706 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0705 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0705 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0705 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0704 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0704 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0703 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0703 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0703 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0703 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0702 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0702 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0702 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0702 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0702 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0701 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0701 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0701 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0701 - mean_absolute_error: 0.070 - ETA: 0s - loss: 0.0701 - mean_absolute_error: 0.070 - 2s 6ms/step - loss: 0.0701 - mean_absolute_error: 0.0701 - val_loss: 0.0696 - val_mean_absolute_error: 0.0696\n",
      "Epoch 7/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0692 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0695 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0695 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0695 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0695 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0696 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0696 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0696 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0695 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0695 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0694 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0694 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0694 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0694 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0694 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0694 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0693 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0693 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0693 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0693 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0692 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0693 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0693 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0692 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0692 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0692 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0692 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0691 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0691 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0691 - mean_absolute_error: 0.069 - ETA: 0s - loss: 0.0691 - mean_absolute_error: 0.069 - 2s 6ms/step - loss: 0.0691 - mean_absolute_error: 0.0691 - val_loss: 0.0687 - val_mean_absolute_error: 0.0687\n",
      "Epoch 8/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0681 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0686 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0687 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0686 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0686 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0684 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0684 - mean_absolute_error: 0.068 - 2s 6ms/step - loss: 0.0684 - mean_absolute_error: 0.0684 - val_loss: 0.0682 - val_mean_absolute_error: 0.0682\n",
      "Epoch 9/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0706 - mean_absolute_error: 0.070 - ETA: 1s - loss: 0.0685 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0683 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0682 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0682 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0681 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0682 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0681 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0681 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - 2s 6ms/step - loss: 0.0680 - mean_absolute_error: 0.0680 - val_loss: 0.0680 - val_mean_absolute_error: 0.0680\n",
      "Epoch 10/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0678 - mean_absolute_error: 0.0678 - val_loss: 0.0678 - val_mean_absolute_error: 0.0678\n",
      "Epoch 11/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0677 - mean_absolute_error: 0.0677 - val_loss: 0.0678 - val_mean_absolute_error: 0.0678\n",
      "Epoch 12/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0692 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0683 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0681 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0676 - mean_absolute_error: 0.0676 - val_loss: 0.0677 - val_mean_absolute_error: 0.0677\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0654 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0675 - mean_absolute_error: 0.0675 - val_loss: 0.0676 - val_mean_absolute_error: 0.0676\n",
      "Epoch 14/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0690 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0681 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0675 - mean_absolute_error: 0.0675 - val_loss: 0.0676 - val_mean_absolute_error: 0.0676\n",
      "Epoch 15/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0697 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0675 - mean_absolute_error: 0.0675 - val_loss: 0.0676 - val_mean_absolute_error: 0.0676\n",
      "Epoch 16/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0660 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0674 - mean_absolute_error: 0.0674 - val_loss: 0.0675 - val_mean_absolute_error: 0.0675\n",
      "Epoch 17/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0674 - mean_absolute_error: 0.0674 - val_loss: 0.0675 - val_mean_absolute_error: 0.0675\n",
      "Epoch 18/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0674 - mean_absolute_error: 0.0674 - val_loss: 0.0674 - val_mean_absolute_error: 0.0674\n",
      "Epoch 19/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0660 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0673 - mean_absolute_error: 0.0673 - val_loss: 0.0674 - val_mean_absolute_error: 0.0674\n",
      "Epoch 20/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0653 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0673 - mean_absolute_error: 0.0673 - val_loss: 0.0674 - val_mean_absolute_error: 0.0674\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0690 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0673 - mean_absolute_error: 0.0673 - val_loss: 0.0674 - val_mean_absolute_error: 0.0674\n",
      "Epoch 22/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0673 - mean_absolute_error: 0.0673 - val_loss: 0.0674 - val_mean_absolute_error: 0.0674\n",
      "Epoch 23/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0659 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0673 - mean_absolute_error: 0.0673 - val_loss: 0.0674 - val_mean_absolute_error: 0.0674\n",
      "Epoch 24/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
      "Epoch 25/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
      "Epoch 26/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0683 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
      "Epoch 27/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0662 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
      "Epoch 28/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0689 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
      "Epoch 30/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0657 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
      "Epoch 31/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0682 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
      "Epoch 32/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0673 - val_mean_absolute_error: 0.0673\n",
      "Epoch 33/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0654 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 34/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 35/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 36/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0658 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0665 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 38/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0658 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 39/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 40/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0688 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 41/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 42/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0665 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 43/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 44/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0683 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 46/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0686 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 47/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 48/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 49/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0659 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0663 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 50/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0676 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 51/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 52/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0688 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0654 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 54/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0665 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0671 - mean_absolute_error: 0.0671 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 55/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 56/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 57/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0681 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0663 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 58/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 59/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 60/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0672 - val_mean_absolute_error: 0.0672\n",
      "Epoch 62/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0658 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 63/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0663 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0662 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 64/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0665 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 65/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0683 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 66/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 67/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 68/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0644 - mean_absolute_error: 0.064 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 70/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0660 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 7ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 71/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0663 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 7ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 72/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0657 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 73/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 74/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0654 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 7ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 75/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0661 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 7ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 76/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 7ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0652 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 7ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 78/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 79/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 7ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 80/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0662 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 7ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 81/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0689 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 7ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 82/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0679 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 83/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 7ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 84/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0683 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0680 - mean_absolute_error: 0.068 - ETA: 1s - loss: 0.0677 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 86/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0650 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 87/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 88/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0662 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 89/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 90/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0665 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 91/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0694 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 92/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0670 - mean_absolute_error: 0.0670 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.0678 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - 2s 6ms/step - loss: 0.0669 - mean_absolute_error: 0.0669 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 94/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - 2s 6ms/step - loss: 0.0669 - mean_absolute_error: 0.0669 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 95/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0660 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0665 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - 2s 6ms/step - loss: 0.0669 - mean_absolute_error: 0.0669 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 96/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0674 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - 2s 6ms/step - loss: 0.0669 - mean_absolute_error: 0.0669 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 97/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0698 - mean_absolute_error: 0.069 - ETA: 1s - loss: 0.0675 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0673 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0672 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - 2s 6ms/step - loss: 0.0669 - mean_absolute_error: 0.0669 - val_loss: 0.0671 - val_mean_absolute_error: 0.0671\n",
      "Epoch 98/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - 2s 6ms/step - loss: 0.0669 - mean_absolute_error: 0.0669 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 99/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0651 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0659 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0663 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0665 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0665 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0666 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - 2s 6ms/step - loss: 0.0669 - mean_absolute_error: 0.0669 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n",
      "Epoch 100/100\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.0654 - mean_absolute_error: 0.065 - ETA: 1s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0664 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0667 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0668 - mean_absolute_error: 0.066 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 1s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0670 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - 2s 7ms/step - loss: 0.0669 - mean_absolute_error: 0.0669 - val_loss: 0.0670 - val_mean_absolute_error: 0.0670\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "momentum=0.7\n",
    "epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "#specify the classification threshold\n",
    "classification_threshold = 0.15\n",
    "\n",
    "# Establish the metrics the model will measure.\n",
    "metric = [tf.keras.metrics.MeanAbsoluteError()]\n",
    "layers=[16,256,2048,64,16]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "my_model= create_model2(learning_rate,momentum,layers, my_feature_layer_A,metric,my_act_function=\"relu\")\n",
    "\n",
    "#lambda_train, lambda_test\n",
    "#delta_train, delta_test\n",
    "\n",
    "epochs_run, hist = train_model(my_model,x_train, y_train, epochs, \n",
    "                          all_label_list, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a graph of the metric(s) vs. epochs.\n",
    "#list_of_metrics_to_plot = ['accuracy'] \n",
    "#print(hist_delta.head())\n",
    "list_of_metrics_to_plot = ['mean_absolute_error',\"val_mean_absolute_error\"] \n",
    "plot_curve(epochs_run, hist, list_of_metrics_to_plot,\"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - ETA: 0s - loss: 0.0657 - mean_absolute_error: 0.065 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - ETA: 0s - loss: 0.0671 - mean_absolute_error: 0.067 - ETA: 0s - loss: 0.0669 - mean_absolute_error: 0.066 - 0s 2ms/step - loss: 0.0669 - mean_absolute_error: 0.0669\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(k6a1,)</th>\n",
       "      <th>(k6a2,)</th>\n",
       "      <th>(k11,)</th>\n",
       "      <th>(k12,)</th>\n",
       "      <th>(k9a1,)</th>\n",
       "      <th>(k9a2,)</th>\n",
       "      <th>(delta,)</th>\n",
       "      <th>(lambda,)</th>\n",
       "      <th>k6a1_pred</th>\n",
       "      <th>k6a2_pred</th>\n",
       "      <th>k11_pred</th>\n",
       "      <th>k12_pred</th>\n",
       "      <th>k9a1_pred</th>\n",
       "      <th>k9a2_pred</th>\n",
       "      <th>delta_pred</th>\n",
       "      <th>lambda_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.491036</td>\n",
       "      <td>0.385998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609849</td>\n",
       "      <td>0.429785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.018497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616637</td>\n",
       "      <td>0.386390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.029474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487260</td>\n",
       "      <td>0.268354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540803</td>\n",
       "      <td>0.315821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.016572</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381219</td>\n",
       "      <td>0.162248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524104</td>\n",
       "      <td>0.306387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421806</td>\n",
       "      <td>0.207314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.012198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396103</td>\n",
       "      <td>0.178726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537581</td>\n",
       "      <td>0.321644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403759</td>\n",
       "      <td>0.187575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558609</td>\n",
       "      <td>0.446262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.023358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586394</td>\n",
       "      <td>0.295806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473701</td>\n",
       "      <td>0.369659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451316</td>\n",
       "      <td>0.256370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427998</td>\n",
       "      <td>0.213786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531528</td>\n",
       "      <td>0.315898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513273</td>\n",
       "      <td>0.296964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600010</td>\n",
       "      <td>0.403692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474506</td>\n",
       "      <td>0.371004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507759</td>\n",
       "      <td>0.316679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466292</td>\n",
       "      <td>0.273627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.508457</td>\n",
       "      <td>0.294072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427674</td>\n",
       "      <td>0.213247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471411</td>\n",
       "      <td>0.280747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438621</td>\n",
       "      <td>0.336978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399971</td>\n",
       "      <td>0.285495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.029409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607386</td>\n",
       "      <td>0.351439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.508688</td>\n",
       "      <td>0.292345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598521</td>\n",
       "      <td>0.429105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574089</td>\n",
       "      <td>0.356518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538722</td>\n",
       "      <td>0.320924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.027765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512254</td>\n",
       "      <td>0.290508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461944</td>\n",
       "      <td>0.359292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.021392</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363271</td>\n",
       "      <td>0.142759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.468184</td>\n",
       "      <td>0.273891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.017250</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378555</td>\n",
       "      <td>0.159482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589312</td>\n",
       "      <td>0.302575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438590</td>\n",
       "      <td>0.225436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592806</td>\n",
       "      <td>0.383553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600744</td>\n",
       "      <td>0.492640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417528</td>\n",
       "      <td>0.221916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555097</td>\n",
       "      <td>0.338413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.027885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436072</td>\n",
       "      <td>0.153261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536257</td>\n",
       "      <td>0.346443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.026199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600471</td>\n",
       "      <td>0.330926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499758</td>\n",
       "      <td>0.279433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411316</td>\n",
       "      <td>0.194236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519863</td>\n",
       "      <td>0.301999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.590429</td>\n",
       "      <td>0.372225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    (k6a1,)  (k6a2,)  (k11,)  (k12,)  (k9a1,)  (k9a2,)  (delta,)  (lambda,)  \\\n",
       "0   -0.0333  -0.0333  0.1000 -0.1000  -0.0333  -0.0333    0.4667     0.5000   \n",
       "1   -0.0333  -0.0333 -0.0333  0.1000  -0.1000  -0.0333    0.6000     0.5000   \n",
       "2    0.1000  -0.0333  0.0333  0.0333  -0.1000  -0.0333    0.6000     0.5000   \n",
       "3    0.0333  -0.0333  0.0333 -0.0333   0.1000   0.0333    0.4667     0.3667   \n",
       "4   -0.0333  -0.0333 -0.1000 -0.0333   0.0333   0.0333    0.5333     0.3667   \n",
       "5   -0.0333   0.0333 -0.0333 -0.1000   0.1000  -0.1000    0.4000     0.1000   \n",
       "6    0.1000  -0.1000 -0.0333  0.0333  -0.0333  -0.0333    0.4667     0.5000   \n",
       "7    0.1000   0.0333  0.1000  0.1000   0.0333  -0.1000    0.4000     0.3667   \n",
       "8   -0.0333   0.0333  0.1000  0.1000   0.1000   0.1000    0.4000     0.2333   \n",
       "9   -0.0333  -0.0333  0.1000 -0.1000   0.1000   0.0333    0.4667     0.5000   \n",
       "10   0.1000   0.0333  0.0333 -0.1000   0.1000  -0.1000    0.4000     0.2333   \n",
       "11   0.1000   0.0333 -0.0333  0.0333   0.1000  -0.0333    0.5333     0.5000   \n",
       "12  -0.1000   0.1000  0.0333  0.1000   0.1000   0.1000    0.6000     0.2333   \n",
       "13   0.1000  -0.0333 -0.1000 -0.0333  -0.0333   0.1000    0.4667     0.3667   \n",
       "14  -0.0333  -0.1000  0.0333 -0.0333   0.0333  -0.0333    0.4667     0.1000   \n",
       "15   0.1000   0.0333 -0.0333 -0.1000  -0.0333   0.1000    0.4667     0.1000   \n",
       "16  -0.1000  -0.0333  0.0333 -0.1000  -0.1000   0.0333    0.5333     0.2333   \n",
       "17  -0.1000   0.1000 -0.0333  0.0333   0.1000   0.0333    0.5333     0.2333   \n",
       "18  -0.0333  -0.1000  0.0333 -0.0333  -0.0333   0.0333    0.6000     0.5000   \n",
       "19  -0.0333   0.0333 -0.0333 -0.1000  -0.1000   0.1000    0.4667     0.5000   \n",
       "20   0.0333   0.1000  0.1000  0.0333  -0.0333  -0.1000    0.4667     0.5000   \n",
       "21  -0.1000  -0.1000 -0.1000 -0.0333  -0.1000  -0.0333    0.4667     0.2333   \n",
       "22  -0.0333   0.0333  0.0333 -0.1000   0.1000  -0.1000    0.5333     0.2333   \n",
       "23   0.1000   0.0333  0.0333  0.1000   0.1000   0.1000    0.4667     0.1000   \n",
       "24  -0.0333  -0.1000 -0.0333  0.1000  -0.1000   0.0333    0.4667     0.3667   \n",
       "25  -0.1000   0.0333 -0.1000 -0.1000   0.1000   0.0333    0.4000     0.5000   \n",
       "26   0.1000   0.0333  0.0333 -0.0333   0.1000   0.0333    0.4000     0.2333   \n",
       "27   0.1000   0.1000  0.0333 -0.1000   0.1000   0.0333    0.6000     0.3667   \n",
       "28  -0.1000   0.1000 -0.0333  0.0333   0.0333  -0.1000    0.4667     0.5000   \n",
       "29  -0.1000   0.1000  0.0333 -0.0333   0.1000  -0.1000    0.6000     0.3667   \n",
       "30   0.0333   0.0333  0.1000  0.1000  -0.0333  -0.0333    0.6000     0.1000   \n",
       "31   0.0333  -0.1000 -0.1000  0.0333   0.0333   0.0333    0.5333     0.3667   \n",
       "32  -0.0333  -0.0333 -0.0333 -0.0333  -0.0333  -0.0333    0.5333     0.3667   \n",
       "33   0.0333  -0.0333 -0.0333  0.1000  -0.0333  -0.0333    0.4667     0.3667   \n",
       "34   0.1000  -0.1000  0.0333 -0.1000  -0.0333   0.0333    0.4000     0.1000   \n",
       "35  -0.0333   0.1000  0.0333  0.0333   0.0333  -0.1000    0.4000     0.5000   \n",
       "36   0.0333  -0.0333 -0.1000 -0.1000   0.0333   0.1000    0.4000     0.1000   \n",
       "37   0.0333  -0.1000 -0.0333 -0.1000   0.0333  -0.0333    0.6000     0.1000   \n",
       "38  -0.1000  -0.0333  0.1000  0.1000   0.1000  -0.0333    0.4000     0.3667   \n",
       "39   0.1000  -0.1000 -0.1000  0.0333   0.0333  -0.0333    0.6000     0.3667   \n",
       "40   0.0333  -0.0333  0.1000 -0.1000   0.1000  -0.0333    0.6000     0.5000   \n",
       "41   0.1000  -0.1000 -0.1000  0.1000  -0.1000  -0.1000    0.4000     0.3667   \n",
       "42   0.0333  -0.0333 -0.0333 -0.1000   0.0333  -0.0333    0.5333     0.3667   \n",
       "43  -0.1000  -0.1000 -0.1000 -0.1000   0.1000   0.1000    0.4667     0.1000   \n",
       "44   0.0333   0.1000 -0.0333 -0.0333   0.0333  -0.1000    0.5333     0.3667   \n",
       "45   0.1000  -0.1000 -0.0333 -0.1000   0.0333  -0.0333    0.6000     0.2333   \n",
       "46   0.0333  -0.0333 -0.0333  0.0333   0.1000  -0.1000    0.4667     0.5000   \n",
       "47  -0.1000   0.1000  0.0333  0.0333  -0.0333   0.0333    0.4000     0.2333   \n",
       "48  -0.0333   0.0333 -0.1000  0.0333  -0.0333  -0.1000    0.5333     0.1000   \n",
       "49  -0.0333   0.0333  0.0333 -0.1000   0.0333  -0.1000    0.6000     0.3667   \n",
       "\n",
       "    k6a1_pred  k6a2_pred  k11_pred  k12_pred  k9a1_pred  k9a2_pred  \\\n",
       "0    0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "1    0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "2    0.018497   0.000000  0.000000       0.0        0.0        0.0   \n",
       "3    0.029474   0.000000  0.000000       0.0        0.0        0.0   \n",
       "4    0.025799   0.000000  0.000000       0.0        0.0        0.0   \n",
       "5    0.016572   0.006605  0.000000       0.0        0.0        0.0   \n",
       "6    0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "7    0.004659   0.000000  0.000000       0.0        0.0        0.0   \n",
       "8    0.012198   0.000000  0.000000       0.0        0.0        0.0   \n",
       "9    0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "10   0.009805   0.000000  0.000000       0.0        0.0        0.0   \n",
       "11   0.000000   0.000000  0.010828       0.0        0.0        0.0   \n",
       "12   0.023358   0.000000  0.000000       0.0        0.0        0.0   \n",
       "13   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "14   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "15   0.003008   0.000000  0.000000       0.0        0.0        0.0   \n",
       "16   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "17   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "18   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "19   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "20   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "21   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "22   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "23   0.003203   0.000000  0.000000       0.0        0.0        0.0   \n",
       "24   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "25   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "26   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "27   0.029409   0.000000  0.000000       0.0        0.0        0.0   \n",
       "28   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "29   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "30   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "31   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "32   0.027765   0.000000  0.000000       0.0        0.0        0.0   \n",
       "33   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "34   0.021392   0.018435  0.000000       0.0        0.0        0.0   \n",
       "35   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "36   0.017250   0.008322  0.000000       0.0        0.0        0.0   \n",
       "37   0.023494   0.000000  0.000000       0.0        0.0        0.0   \n",
       "38   0.000013   0.000000  0.000000       0.0        0.0        0.0   \n",
       "39   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "40   0.000000   0.000000  0.029388       0.0        0.0        0.0   \n",
       "41   0.002948   0.000000  0.000000       0.0        0.0        0.0   \n",
       "42   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "43   0.027885   0.000000  0.000000       0.0        0.0        0.0   \n",
       "44   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "45   0.026199   0.000000  0.000000       0.0        0.0        0.0   \n",
       "46   0.028622   0.000000  0.000000       0.0        0.0        0.0   \n",
       "47   0.007993   0.000000  0.000000       0.0        0.0        0.0   \n",
       "48   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "49   0.000000   0.000000  0.000000       0.0        0.0        0.0   \n",
       "\n",
       "    delta_pred  lambda_pred  \n",
       "0     0.491036     0.385998  \n",
       "1     0.609849     0.429785  \n",
       "2     0.616637     0.386390  \n",
       "3     0.487260     0.268354  \n",
       "4     0.540803     0.315821  \n",
       "5     0.381219     0.162248  \n",
       "6     0.524104     0.306387  \n",
       "7     0.421806     0.207314  \n",
       "8     0.396103     0.178726  \n",
       "9     0.537581     0.321644  \n",
       "10    0.403759     0.187575  \n",
       "11    0.558609     0.446262  \n",
       "12    0.586394     0.295806  \n",
       "13    0.473701     0.369659  \n",
       "14    0.451316     0.256370  \n",
       "15    0.427998     0.213786  \n",
       "16    0.531528     0.315898  \n",
       "17    0.513273     0.296964  \n",
       "18    0.600010     0.403692  \n",
       "19    0.474506     0.371004  \n",
       "20    0.507759     0.316679  \n",
       "21    0.466292     0.273627  \n",
       "22    0.508457     0.294072  \n",
       "23    0.427674     0.213247  \n",
       "24    0.471411     0.280747  \n",
       "25    0.438621     0.336978  \n",
       "26    0.399971     0.285495  \n",
       "27    0.607386     0.351439  \n",
       "28    0.508688     0.292345  \n",
       "29    0.598521     0.429105  \n",
       "30    0.574089     0.356518  \n",
       "31    0.538722     0.320924  \n",
       "32    0.512254     0.290508  \n",
       "33    0.461944     0.359292  \n",
       "34    0.363271     0.142759  \n",
       "35    0.468184     0.273891  \n",
       "36    0.378555     0.159482  \n",
       "37    0.589312     0.302575  \n",
       "38    0.438590     0.225436  \n",
       "39    0.592806     0.383553  \n",
       "40    0.600744     0.492640  \n",
       "41    0.417528     0.221916  \n",
       "42    0.555097     0.338413  \n",
       "43    0.436072     0.153261  \n",
       "44    0.536257     0.346443  \n",
       "45    0.600471     0.330926  \n",
       "46    0.499758     0.279433  \n",
       "47    0.411316     0.194236  \n",
       "48    0.519863     0.301999  \n",
       "49    0.590429     0.372225  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_test_result=test_model(my_model,x_test,y_test,all_label_list)\n",
    "delta_test_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7396c898a1a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved_Models/lambda_100_best_model_main_max_err_0_009\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'my_model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
