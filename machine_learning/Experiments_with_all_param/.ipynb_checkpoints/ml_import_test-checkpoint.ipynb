{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import kerastuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_curve(epochs, hist, list_of_metrics,name):\n",
    "    \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch \"+name)\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    for m in list_of_metrics:\n",
    "        x = hist[m]\n",
    "        plt.plot(epochs[1:], x[1:], label=m)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "# for activation functions check https://keras.io/api/layers/activations/\n",
    "def create_model2(my_learning_rate,momentum,layers,my_metrics,my_act_function = \"softmax\"):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #model.add(my_feature_layer)\n",
    "\n",
    "    for layer in layers:\n",
    "        model.add(tf.keras.layers.Dense(units = layer, activation = my_act_function))\n",
    "    model.add(tf.keras.layers.Dense(units=15,name='Output', activation = 'softmax'))                             \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=my_learning_rate,momentum=momentum),                                       \n",
    "                loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                metrics=my_metrics)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model,x_data, y_data, epochs, label_name,\n",
    "                batch_size=None,shuffle=True):\n",
    "    #features = {name:np.array(value) for name, value in dataset.items()}\n",
    "    history = model.fit(x=x_data, y=y_data, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=shuffle,validation_split=0.2,\n",
    "                       callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)])\n",
    "  \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    return epochs, hist\n",
    "    \n",
    "    \n",
    "#returns dataframe\n",
    "def test_model(model,x_data, y_data ,label_name):\n",
    "    evaluation=model.evaluate(x = x_data, y = y_data, batch_size=batch_size)\n",
    "    predicted = model.predict(x_data)\n",
    "    df_test=pd.DataFrame(y_data,columns=[label_name])\n",
    "   # print(predicted)\n",
    "    df_predict=pd.DataFrame(predicted,columns=[label+\"_pred\" for label in label_name])\n",
    "    return pd.concat([df_test,df_predict], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta</th>\n",
       "      <th>lambda</th>\n",
       "      <th>all_maxima</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>overlap_s0_s2_k6a</th>\n",
       "      <th>overlap_s0_s2_k1</th>\n",
       "      <th>overlap_s0_s2_k9a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[0.466 0.54  0.612 0.67  0.742]</td>\n",
       "      <td>[104.475076  104.507572   87.7231385  58.12209...</td>\n",
       "      <td>[0.5232, 0.3386, 0.1098, 0.0239, 0.004]</td>\n",
       "      <td>[0.7501, 0.2155, 0.031, 0.003, 0.0002]</td>\n",
       "      <td>[0.8102, 0.1704, 0.018, 0.0013, 0.0001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>[0.51  0.584 0.65  0.712 0.778]</td>\n",
       "      <td>[121.232278  120.055307   85.8745546  56.17655...</td>\n",
       "      <td>[0.5232, 0.3386, 0.1098, 0.0239, 0.004]</td>\n",
       "      <td>[0.7501, 0.2155, 0.031, 0.003, 0.0002]</td>\n",
       "      <td>[0.9769, 0.0228, 0.0003, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>[0.482 0.556 0.628 0.686 0.756]</td>\n",
       "      <td>[101.883081  101.900808   85.5862194  56.79913...</td>\n",
       "      <td>[0.5232, 0.3386, 0.1098, 0.0239, 0.004]</td>\n",
       "      <td>[0.7501, 0.2155, 0.031, 0.003, 0.0002]</td>\n",
       "      <td>[0.8102, 0.1704, 0.018, 0.0013, 0.0001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>[0.418 0.492 0.564 0.622 0.692]</td>\n",
       "      <td>[101.197996  101.175315   85.035938   56.43656...</td>\n",
       "      <td>[0.5232, 0.3386, 0.1098, 0.0239, 0.004]</td>\n",
       "      <td>[0.7501, 0.2155, 0.031, 0.003, 0.0002]</td>\n",
       "      <td>[0.8102, 0.1704, 0.018, 0.0013, 0.0001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>[0.4   0.474 0.546 0.604 0.676]</td>\n",
       "      <td>[104.345828  104.372914   87.6137903  58.09441...</td>\n",
       "      <td>[0.5232, 0.3386, 0.1098, 0.0239, 0.004]</td>\n",
       "      <td>[0.7501, 0.2155, 0.031, 0.003, 0.0002]</td>\n",
       "      <td>[0.8102, 0.1704, 0.018, 0.0013, 0.0001]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    delta  lambda                       all_maxima  \\\n",
       "0  0.6000  0.1000  [0.466 0.54  0.612 0.67  0.742]   \n",
       "1  0.6000  0.2333  [0.51  0.584 0.65  0.712 0.778]   \n",
       "2  0.6000  0.2333  [0.482 0.556 0.628 0.686 0.756]   \n",
       "3  0.5333  0.2333  [0.418 0.492 0.564 0.622 0.692]   \n",
       "4  0.5333  0.1000  [0.4   0.474 0.546 0.604 0.676]   \n",
       "\n",
       "                                           Intensity  \\\n",
       "0  [104.475076  104.507572   87.7231385  58.12209...   \n",
       "1  [121.232278  120.055307   85.8745546  56.17655...   \n",
       "2  [101.883081  101.900808   85.5862194  56.79913...   \n",
       "3  [101.197996  101.175315   85.035938   56.43656...   \n",
       "4  [104.345828  104.372914   87.6137903  58.09441...   \n",
       "\n",
       "                         overlap_s0_s2_k6a  \\\n",
       "0  [0.5232, 0.3386, 0.1098, 0.0239, 0.004]   \n",
       "1  [0.5232, 0.3386, 0.1098, 0.0239, 0.004]   \n",
       "2  [0.5232, 0.3386, 0.1098, 0.0239, 0.004]   \n",
       "3  [0.5232, 0.3386, 0.1098, 0.0239, 0.004]   \n",
       "4  [0.5232, 0.3386, 0.1098, 0.0239, 0.004]   \n",
       "\n",
       "                         overlap_s0_s2_k1  \\\n",
       "0  [0.7501, 0.2155, 0.031, 0.003, 0.0002]   \n",
       "1  [0.7501, 0.2155, 0.031, 0.003, 0.0002]   \n",
       "2  [0.7501, 0.2155, 0.031, 0.003, 0.0002]   \n",
       "3  [0.7501, 0.2155, 0.031, 0.003, 0.0002]   \n",
       "4  [0.7501, 0.2155, 0.031, 0.003, 0.0002]   \n",
       "\n",
       "                         overlap_s0_s2_k9a  \n",
       "0  [0.8102, 0.1704, 0.018, 0.0013, 0.0001]  \n",
       "1       [0.9769, 0.0228, 0.0003, 0.0, 0.0]  \n",
       "2  [0.8102, 0.1704, 0.018, 0.0013, 0.0001]  \n",
       "3  [0.8102, 0.1704, 0.018, 0.0013, 0.0001]  \n",
       "4  [0.8102, 0.1704, 0.018, 0.0013, 0.0001]  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_labels_features=[\"delta\",\"lambda\",\"all_maxima\",\"Intensity\",\"overlap_s0_s2_k6a\",\"overlap_s0_s2_k1\",\"overlap_s0_s2_k9a\"]\n",
    "all_data=pd.read_csv(\"G:\\OneDrive - bwedu\\Master\\Forschungspraktikum\\Inga\\pc-forschi\\generated_Data/all_param_4_values_with_overlap.csv\")\n",
    "df_feature_labels=all_data[all_labels_features]\n",
    "\n",
    "max_no_of_peak_list=max(all_data[\"no_of_max\"])\n",
    "print(max_no_of_peak_list)\n",
    "df_feature_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert string lists into numpy arrays in dict\n",
    "\n",
    "all_maxima_array=np.asarray([  np.asarray([x for x in row.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"  \",\" \",5).replace(\" \",\";\").split(\";\") if x!=\"\"],dtype=np.float64)     for row in df_feature_labels[\"all_maxima\"] ])\n",
    "\n",
    "intensity_array=np.asarray([  np.asarray([x for x in row.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"  \",\" \",5).replace(\" \",\";\").split(\";\") if x!=\"\"],dtype=np.float64)     for row in df_feature_labels[\"Intensity\"] ])\n",
    "\n",
    "overlap_s0_s2_k6a_array=np.asarray([  np.asarray([x for x in row.replace(\",\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"  \",\" \",5).replace(\" \",\";\").split(\";\") if x!=\"\"],dtype=np.float64)     for row in df_feature_labels[\"overlap_s0_s2_k6a\"] ])\n",
    "\n",
    "overlap_s0_s2_k1_array=np.asarray([  np.asarray([x for x in row.replace(\",\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"  \",\" \",5).replace(\" \",\";\").split(\";\") if x!=\"\"],dtype=np.float64)     for row in df_feature_labels[\"overlap_s0_s2_k1\"] ])\n",
    "\n",
    "overlap_s0_s2_k9a_array=np.asarray([  np.asarray([x for x in row.replace(\",\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"  \",\" \",5).replace(\" \",\";\").split(\";\") if x!=\"\"],dtype=np.float64)     for row in df_feature_labels[\"overlap_s0_s2_k9a\"] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad all_maxima_array and intensity_array\n",
    "all_maxima_array_padded=np.zeros((len(all_maxima_array),max_no_of_peak_list))\n",
    "intensity_array_padded=np.zeros((len(intensity_array),max_no_of_peak_list))\n",
    "\n",
    "for i in range(len(all_maxima_array)):\n",
    "    for j in range(len(all_maxima_array[i])):\n",
    "        all_maxima_array_padded[i][j]=all_maxima_array[i][j]\n",
    "        intensity_array_padded[i][j]=intensity_array[i][j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_label=np.concatenate((overlap_s0_s2_k6a_array,overlap_s0_s2_k1_array,overlap_s0_s2_k9a_array),axis=1)\n",
    "concat_feature=np.concatenate((all_maxima_array_padded,intensity_array_padded),axis=1)\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split( concat_feature, concat_label  ,test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_35 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "280/280 [==============================] - 2s 7ms/step - loss: 0.1362 - mean_absolute_error: 0.1362 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 2/100\n",
      "280/280 [==============================] - 2s 7ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 3/100\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 4/100\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 5/100\n",
      "280/280 [==============================] - 2s 7ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 6/100\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 7/100\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 8/100\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 9/100\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 10/100\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 11/100\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 12/100\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 13/100\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 14/100\n",
      "280/280 [==============================] - 2s 7ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 15/100\n",
      "280/280 [==============================] - 2s 7ms/step - loss: 0.1333 - mean_absolute_error: 0.1333 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
      "Epoch 16/100\n",
      " 37/280 [==>...........................] - ETA: 1s - loss: 0.1333 - mean_absolute_error: 0.1333"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-efd407c8ba3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m epochs_run, hist = train_model(my_model,x_train, y_train, epochs, \n\u001b[1;32m---> 22\u001b[1;33m                           all_label_list, batch_size)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-112-fb90b30db5ad>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, x_data, y_data, epochs, label_name, batch_size, shuffle)\u001b[0m\n\u001b[0;32m     39\u001b[0m     history = model.fit(x=x_data, y=y_data, batch_size=batch_size,\n\u001b[0;32m     40\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)])\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    517\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \"\"\"\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "momentum=0.7\n",
    "epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "#specify the classification threshold\n",
    "classification_threshold = 0.15\n",
    "\n",
    "# Establish the metrics the model will measure.\n",
    "metric = [tf.keras.metrics.MeanAbsoluteError()]\n",
    "layers=[16,256,2048,64,16]\n",
    "\n",
    "\n",
    "all_label_list=[\"k6a 0\",\"k6a 1\",\"k6a 2\",\"k6a 3\",\"k6a 4\",\"k1 0\",\"k1 1\",\"k1 2\",\"k1 3\",\"k1 4\",\"k9a 0\",\"k9a 1\",\"k9a 2\",\"k9a 3\",\"k9a 4\"]\n",
    "\n",
    "my_model= create_model2(learning_rate,momentum,layers,metric,my_act_function=\"relu\")\n",
    "\n",
    "#lambda_train, lambda_test\n",
    "#delta_train, delta_test\n",
    "\n",
    "epochs_run, hist = train_model(my_model,x_train, y_train, epochs, \n",
    "                          all_label_list, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_metrics_to_plot = ['mean_absolute_error',\"val_mean_absolute_error\"] \n",
    "plot_curve(epochs_run, hist, list_of_metrics_to_plot,\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_list=['k6a 0',\"k6a 1\",\"k6a 2\",\"k6a 3\",\"k6a 4\",\"k1 0\",\"k1 1\",\"k1 2\",\"k1 3\",\"k1 4\",\"k9a 0\",\"k9a 1\",\"k9a 2\",\"k9a 3\",\"k9a 4\"]\n",
    "\n",
    "delta_test_result=test_model(my_model,x_test,y_test,all_label_list)\n",
    "\n",
    "columns_names=delta_test_result.columns\n",
    "\n",
    "compare_k6a=columns_names[[0,1,2,3,4,15,16,17,18,19]]\n",
    "compare_k1=columns_names[[5,6,7,8,9,20,21,22,23,24]]\n",
    "compare_k9a=columns_names[[10,11,12,13,14,25,26,27,28,29]]\n",
    "#print(compare_k6a)\n",
    "\n",
    "#delta_test_result[compare_k6a].head(50)\n",
    "#delta_test_result[compare_k1].head(50)\n",
    "delta_test_result[compare_k9a].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_test_result[compare_k9a].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Generate a large random dataset\n",
    "rs = np.random.RandomState(33)\n",
    "d = delta_test_result\n",
    "# Compute the correlation matrix\n",
    "corr = d.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From H:\\Users\\Gwydion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_Models/franck_condon_test_v2_err_0_015\\assets\n"
     ]
    }
   ],
   "source": [
    "#my_model.save(\"saved_Models/lambda_100_best_model_main_max_err_0_0027\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
