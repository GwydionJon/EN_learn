{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_maximum</th>\n",
       "      <th>all_maxima</th>\n",
       "      <th>no_of_max</th>\n",
       "      <th>k6a1</th>\n",
       "      <th>k6a2</th>\n",
       "      <th>k11</th>\n",
       "      <th>k12</th>\n",
       "      <th>k9a1</th>\n",
       "      <th>k9a2</th>\n",
       "      <th>Energy_highest_max_normalized</th>\n",
       "      <th>Energy_all_max_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.748</td>\n",
       "      <td>[-0.758 -0.69  -0.612 -0.472 -0.406 -0.328 -0....</td>\n",
       "      <td>18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.874</td>\n",
       "      <td>[0.121 0.155 0.194 0.264 0.297 0.336 0.424 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.574</td>\n",
       "      <td>[-0.574 -0.048  0.034  0.596  0.658]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.213</td>\n",
       "      <td>[0.213 0.476 0.517 0.798 0.829]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.732</td>\n",
       "      <td>[-0.928 -0.776 -0.708 -0.628 -0.486 -0.422 -0....</td>\n",
       "      <td>19</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.866</td>\n",
       "      <td>[0.036 0.112 0.146 0.186 0.257 0.289 0.33  0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.734</td>\n",
       "      <td>[-0.926 -0.778 -0.712 -0.628 -0.486 -0.422 -0....</td>\n",
       "      <td>19</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.867</td>\n",
       "      <td>[0.037 0.111 0.144 0.186 0.257 0.289 0.33  0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.560</td>\n",
       "      <td>[-0.56  -0.03   0.046  0.614  0.674]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.220</td>\n",
       "      <td>[0.22  0.485 0.523 0.807 0.837]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0.736</td>\n",
       "      <td>[-0.774 -0.706 -0.612 -0.488 -0.424 -0.34  -0....</td>\n",
       "      <td>17</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.868</td>\n",
       "      <td>[0.113 0.147 0.194 0.256 0.288 0.33  0.415 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>0.730</td>\n",
       "      <td>[-0.922 -0.776 -0.702 -0.624 -0.49  -0.42  -0....</td>\n",
       "      <td>19</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.865</td>\n",
       "      <td>[0.039 0.112 0.149 0.188 0.255 0.29  0.413 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>-0.574</td>\n",
       "      <td>[-0.574 -0.046  0.036  0.594  0.66 ]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.213</td>\n",
       "      <td>[0.213 0.477 0.518 0.797 0.83 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>0.736</td>\n",
       "      <td>[-0.932 -0.772 -0.736 -0.628 -0.492 -0.424 -0....</td>\n",
       "      <td>20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.868</td>\n",
       "      <td>[0.034 0.114 0.132 0.186 0.254 0.288 0.331 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>-0.702</td>\n",
       "      <td>[-0.932 -0.774 -0.702 -0.628 -0.488 -0.424 -0....</td>\n",
       "      <td>21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.149</td>\n",
       "      <td>[0.034 0.113 0.149 0.186 0.256 0.288 0.329 0.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     main_maximum                                         all_maxima  \\\n",
       "0           0.748  [-0.758 -0.69  -0.612 -0.472 -0.406 -0.328 -0....   \n",
       "1          -0.574               [-0.574 -0.048  0.034  0.596  0.658]   \n",
       "2           0.732  [-0.928 -0.776 -0.708 -0.628 -0.486 -0.422 -0....   \n",
       "3           0.734  [-0.926 -0.778 -0.712 -0.628 -0.486 -0.422 -0....   \n",
       "4          -0.560               [-0.56  -0.03   0.046  0.614  0.674]   \n",
       "..            ...                                                ...   \n",
       "674         0.736  [-0.774 -0.706 -0.612 -0.488 -0.424 -0.34  -0....   \n",
       "675         0.730  [-0.922 -0.776 -0.702 -0.624 -0.49  -0.42  -0....   \n",
       "676        -0.574               [-0.574 -0.046  0.036  0.594  0.66 ]   \n",
       "677         0.736  [-0.932 -0.772 -0.736 -0.628 -0.492 -0.424 -0....   \n",
       "678        -0.702  [-0.932 -0.774 -0.702 -0.628 -0.488 -0.424 -0....   \n",
       "\n",
       "     no_of_max  k6a1  k6a2   k11   k12  k9a1  k9a2  \\\n",
       "0           18  0.25  0.25  0.25  0.25  0.25  0.25   \n",
       "1            5  0.25  0.25  0.25  0.25  0.25  0.50   \n",
       "2           19  0.25  0.25  0.25  0.25  0.25  0.75   \n",
       "3           19  0.25  0.25  0.25  0.25  0.50  0.25   \n",
       "4            5  0.25  0.25  0.25  0.25  0.50  0.50   \n",
       "..         ...   ...   ...   ...   ...   ...   ...   \n",
       "674         17  0.75  0.75  0.25  0.75  0.75  0.75   \n",
       "675         19  0.75  0.75  0.50  0.25  0.25  0.25   \n",
       "676          5  0.75  0.75  0.50  0.25  0.25  0.50   \n",
       "677         20  0.75  0.75  0.50  0.25  0.25  0.75   \n",
       "678         21  0.75  0.75  0.50  0.25  0.50  0.25   \n",
       "\n",
       "     Energy_highest_max_normalized  \\\n",
       "0                            0.874   \n",
       "1                            0.213   \n",
       "2                            0.866   \n",
       "3                            0.867   \n",
       "4                            0.220   \n",
       "..                             ...   \n",
       "674                          0.868   \n",
       "675                          0.865   \n",
       "676                          0.213   \n",
       "677                          0.868   \n",
       "678                          0.149   \n",
       "\n",
       "                             Energy_all_max_normalized  \n",
       "0    [0.121 0.155 0.194 0.264 0.297 0.336 0.424 0.4...  \n",
       "1                      [0.213 0.476 0.517 0.798 0.829]  \n",
       "2    [0.036 0.112 0.146 0.186 0.257 0.289 0.33  0.4...  \n",
       "3    [0.037 0.111 0.144 0.186 0.257 0.289 0.33  0.4...  \n",
       "4                      [0.22  0.485 0.523 0.807 0.837]  \n",
       "..                                                 ...  \n",
       "674  [0.113 0.147 0.194 0.256 0.288 0.33  0.415 0.4...  \n",
       "675  [0.039 0.112 0.149 0.188 0.255 0.29  0.413 0.4...  \n",
       "676                    [0.213 0.477 0.518 0.797 0.83 ]  \n",
       "677  [0.034 0.114 0.132 0.186 0.254 0.288 0.331 0.4...  \n",
       "678  [0.034 0.113 0.149 0.186 0.256 0.288 0.329 0.4...  \n",
       "\n",
       "[679 rows x 11 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spectra=pd.read_csv(\"spectrum_energy_input_numberOfPeaks.csv\",index_col=[0])\n",
    "x_data=np.asarray([df_spectra[\"no_of_max\"].values]).transpose()\n",
    "x_data_max=max(x_data)\n",
    "x_data=x_data/x_data_max\n",
    "#x_data=np.asarray([df_spectra[[\"no_of_max\",\"Energy_highest_max_normalized\"]].to_numpy()])[0]\n",
    "\n",
    "y_data=np.asarray([df_spectra[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]].to_numpy()])[0]\n",
    "df_spectra.head(-50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 6)\n",
      "(729, 1)\n",
      "[[0.25 0.25 0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25 0.25 0.5 ]\n",
      " [0.25 0.25 0.25 0.25 0.25 0.75]\n",
      " ...\n",
      " [0.75 0.75 0.75 0.75 0.75 0.25]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.5 ]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.75]]\n"
     ]
    }
   ],
   "source": [
    "print(y_data.shape)\n",
    "\n",
    "print(x_data.shape)\n",
    "\n",
    "\n",
    "print(y_data)\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "le = MultiLabelBinarizer()\n",
    "le.fit(y_data)\n",
    "y_data_enc=le.transform(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#always seems to leave some values at zero\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    #model.add(Dense(25, activation='relu'))\n",
    "    #model.add(Dense(10, activation='relu'))\n",
    "    print(n_outputs)\n",
    "    model.add(Dense(n_outputs, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def get_model2(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=n_inputs, kernel_initializer='ones', activation='relu'))\n",
    "   # model.add(Dense(5, activation='sigmoid'))\n",
    "   # model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "    #model.add(Dense(10, activation='relu'))\n",
    "    print(n_outputs)\n",
    "    model.add(Dense(n_outputs, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(lr=1e-5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, epochs):\n",
    "    results = list()\n",
    "    n_inputs = X.shape[1]\n",
    "    print(n_inputs)\n",
    "    n_outputs = y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        \n",
    "       # print(X_train[0],y_train[0])\n",
    "        #print(len(X_train))\n",
    "        #print(X_train,y_train)\n",
    "        # define model\n",
    "        model = get_model2(n_inputs, n_outputs)\n",
    "        # fit model\n",
    "        #print(len(X_train))\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=epochs)\n",
    "        # make a prediction on the test set\n",
    "        yhat = model.predict(X_test)\n",
    "        # round probabilities to class labels\n",
    "        yhat = yhat\n",
    "        # calculate accuracy\n",
    "        \n",
    "        rse=model.evaluate(X_test,y_test)\n",
    "        \n",
    "        #print(y_test,yhat)\n",
    "        \n",
    "        \n",
    "        # store result\n",
    "        #print( rse)\n",
    "        results.append(rse)\n",
    "    \n",
    "    #y_predict1=[yhat[i][0] for i in range(len(yhat))]\n",
    "   # y_predict2=[yhat[i][1] for i in range(len(yhat))]\n",
    "   #y_test1=[y_test[i][0] for i in range(len(y_test))]\n",
    "   # y_test2=[y_test[i][1] for i in range(len(y_test))]\n",
    "   # print(y_test)\n",
    "   # print(yhat)\n",
    "   \n",
    "    \n",
    "    df_test=pd.DataFrame(y_test,columns=[\"k6a1_test\",\"k6a2_test\",\"k11_test\",\"k12_test\",\"k9a1_test\",\"k9a2_test\"])\n",
    "    df_hat=pd.DataFrame(yhat,columns=[\"k6a1_hat\",\"k6a2_hat\",\"k11_hat\",\"k12_hat\",\"k9a1_hat\",\"k9a2_hat\"])\n",
    "   # df_test=pd.DataFrame(y_test,columns=[\"NO_test\"])\n",
    "   # df_hat=pd.DataFrame(yhat,columns=[\"NO_hat\"])\n",
    "\n",
    "    return results,pd.concat([df_test,df_hat], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 60, 70, 80, 90, 100, 110, 120, 130, 140]\n",
      "1\n",
      "6\n",
      "12/12 [==============================] - 0s 417us/step - loss: 0.1243\n",
      "6\n",
      "12/12 [==============================] - 0s 417us/step - loss: 0.1677\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "epochs_list=[]\n",
    "complete_range=[]\n",
    "for i in range(50,150,10):\n",
    "    complete_range.append(i)\n",
    "\n",
    "\n",
    "print(complete_range)\n",
    "#for i in complete_range:#\n",
    "#    epochs_list.append(i)\n",
    "#    results.append( evaluate_model(x_data,y_data,epochs_list[-1])[0])\n",
    "\n",
    "results,compare =evaluate_model(x_data,y_data,7500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12430655211210251, 0.1676531881093979]\n",
      "Accuracy: 0.146 (0.022)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k6a1_test</th>\n",
       "      <th>k6a2_test</th>\n",
       "      <th>k11_test</th>\n",
       "      <th>k12_test</th>\n",
       "      <th>k9a1_test</th>\n",
       "      <th>k9a2_test</th>\n",
       "      <th>k6a1_hat</th>\n",
       "      <th>k6a2_hat</th>\n",
       "      <th>k11_hat</th>\n",
       "      <th>k12_hat</th>\n",
       "      <th>k9a1_hat</th>\n",
       "      <th>k9a2_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k6a1_test  k6a2_test  k11_test  k12_test  k9a1_test  k9a2_test  k6a1_hat  \\\n",
       "0       0.25       0.25      0.25      0.25       0.25       0.50       0.0   \n",
       "1       0.25       0.25      0.25      0.25       0.75       0.50       0.0   \n",
       "2       0.25       0.25      0.25      0.50       0.25       0.50       0.0   \n",
       "3       0.25       0.25      0.25      0.50       0.50       0.25       0.0   \n",
       "4       0.25       0.25      0.25      0.50       0.50       0.75       0.0   \n",
       "\n",
       "   k6a2_hat  k11_hat   k12_hat  k9a1_hat  k9a2_hat  \n",
       "0  0.492517      0.0  0.501101       0.0  0.506498  \n",
       "1  0.492517      0.0  0.501101       0.0  0.506498  \n",
       "2  0.490054      0.0  0.500998       0.0  0.503816  \n",
       "3  0.492517      0.0  0.501101       0.0  0.506498  \n",
       "4  0.492517      0.0  0.501101       0.0  0.506498  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results_avg=[ sum(res)/len(res) for res in results   ]\n",
    "\n",
    "print(results)\n",
    "#plt.plot(epochs_list,results_avg)\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(583, 6)\n"
     ]
    }
   ],
   "source": [
    "#Validation is now done in the .fit() function\n",
    "# testing data is now only used for final evaulation\n",
    "\n",
    "df_spectra_new=pd.read_csv(\"spectrum_energy_input_numberOfPeaks.csv\",index_col=[0])\n",
    "x_data_max_new=max(df_spectra_new[\"no_of_max\"])\n",
    "\n",
    "df_training = df_spectra_new.sample(frac=0.8,random_state=10)\n",
    "df_testing=df_spectra_new.drop(df_training.index)\n",
    "\n",
    "\n",
    "x_data_train=np.asarray([df_training[\"no_of_max\"].values]).transpose()\n",
    "x_data_train=x_data_train/x_data_max_new\n",
    "\n",
    "x_data_test=np.asarray([df_testing[\"no_of_max\"].values]).transpose()\n",
    "x_data_test=x_data_test/x_data_max_new\n",
    "\n",
    "y_data_train=np.asarray([df_training[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]].to_numpy()])[0]\n",
    "y_data_test=np.asarray([df_testing[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]].to_numpy()])[0]\n",
    "\n",
    "print(y_data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the plot_the_loss_curve function.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def plot_the_loss_curve(epochs, mse,val_mse):\n",
    "    \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "\n",
    "    plt.plot(epochs, mse, label=\"Loss\")\n",
    "    plt.plot(epochs, val_mse, label=\"Val Loss\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
    "    plt.show()  \n",
    "\n",
    "print(\"Defined the plot_the_loss_curve function.\")\n",
    "\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='linear'))\n",
    "    #model.add(Dense(25, activation='relu'))\n",
    "    #model.add(Dense(10, activation='relu'))\n",
    "    print(n_outputs)\n",
    "    model.add(Dense(n_outputs, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, x_data,y_data, epochs, \n",
    "                batch_size=None):\n",
    "    \"\"\"Train the model by feeding it data.\"\"\"\n",
    "    \n",
    "    \n",
    "    history = model.fit(x=x_data, y=y_data, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, verbose=0,validation_split=0.2) \n",
    "    \n",
    "    epochs = history.epoch\n",
    "  \n",
    "    hist = pd.DataFrame(history.history)\n",
    "    #hist.head()\n",
    "    #mse = hist[\"mean_squared_error\"]\n",
    "    \n",
    "    return hist,epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Final evaluation: 0.04393370449542999 0.04432019591331482\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 300\n",
    "batch_size = 500\n",
    "my_model=get_model(x_data_train.shape[1],y_data_train.shape[1])\n",
    "df_hist,epochs = train_model(my_model, x_data_train,y_data_train, epochs, \n",
    "                          batch_size)\n",
    "\n",
    "df_hist.head()\n",
    "mse = df_hist[\"mean_squared_error\"].to_numpy()\n",
    "val_mse = df_hist[\"val_mean_squared_error\"].to_numpy()\n",
    "print(\"Final evaluation:\", mse[-1], val_mse[-1] )\n",
    "plot_the_loss_curve(epochs, mse,val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0424 - mean_squared_error: 0.0424\n",
      "[0.042446088045835495, 0.042446088045835495]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k6a1_test</th>\n",
       "      <th>k6a2_test</th>\n",
       "      <th>k11_test</th>\n",
       "      <th>k12_test</th>\n",
       "      <th>k9a1_test</th>\n",
       "      <th>k9a2_test</th>\n",
       "      <th>k6a1_hat</th>\n",
       "      <th>k6a2_hat</th>\n",
       "      <th>k11_hat</th>\n",
       "      <th>k12_hat</th>\n",
       "      <th>k9a1_hat</th>\n",
       "      <th>k9a2_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.402714</td>\n",
       "      <td>0.511183</td>\n",
       "      <td>0.506417</td>\n",
       "      <td>0.475340</td>\n",
       "      <td>0.483286</td>\n",
       "      <td>0.475403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.551619</td>\n",
       "      <td>0.495908</td>\n",
       "      <td>0.499437</td>\n",
       "      <td>0.504692</td>\n",
       "      <td>0.513478</td>\n",
       "      <td>0.513122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.402714</td>\n",
       "      <td>0.511183</td>\n",
       "      <td>0.506417</td>\n",
       "      <td>0.475340</td>\n",
       "      <td>0.483286</td>\n",
       "      <td>0.475403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.402714</td>\n",
       "      <td>0.511183</td>\n",
       "      <td>0.506417</td>\n",
       "      <td>0.475340</td>\n",
       "      <td>0.483286</td>\n",
       "      <td>0.475403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.368351</td>\n",
       "      <td>0.514708</td>\n",
       "      <td>0.508028</td>\n",
       "      <td>0.468567</td>\n",
       "      <td>0.476319</td>\n",
       "      <td>0.466699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k6a1_test  k6a2_test  k11_test  k12_test  k9a1_test  k9a2_test  k6a1_hat  \\\n",
       "0       0.25       0.25      0.25      0.25       0.50       0.50  0.402714   \n",
       "1       0.25       0.25      0.25      0.25       0.75       0.75  0.551619   \n",
       "2       0.25       0.25      0.25      0.50       0.50       0.50  0.402714   \n",
       "3       0.25       0.25      0.25      0.50       0.75       0.25  0.402714   \n",
       "4       0.25       0.25      0.50      0.50       0.50       0.50  0.368351   \n",
       "\n",
       "   k6a2_hat   k11_hat   k12_hat  k9a1_hat  k9a2_hat  \n",
       "0  0.511183  0.506417  0.475340  0.483286  0.475403  \n",
       "1  0.495908  0.499437  0.504692  0.513478  0.513122  \n",
       "2  0.511183  0.506417  0.475340  0.483286  0.475403  \n",
       "3  0.511183  0.506417  0.475340  0.483286  0.475403  \n",
       "4  0.514708  0.508028  0.468567  0.476319  0.466699  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation=my_model.evaluate(x = x_data_test, y = y_data_test, batch_size=batch_size)\n",
    "predicted = my_model.predict(x_data_test)\n",
    "print(evaluation)\n",
    "\n",
    "df_test=pd.DataFrame(y_data_test,columns=[\"k6a1_test\",\"k6a2_test\",\"k11_test\",\"k12_test\",\"k9a1_test\",\"k9a2_test\"])\n",
    "df_predict=pd.DataFrame(predicted,columns=[\"k6a1_hat\",\"k6a2_hat\",\"k11_hat\",\"k12_hat\",\"k9a1_hat\",\"k9a2_hat\"])\n",
    "pd.concat([df_test,df_predict], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
