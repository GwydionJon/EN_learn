{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_maximum</th>\n",
       "      <th>all_maxima</th>\n",
       "      <th>no_of_max</th>\n",
       "      <th>k6a1</th>\n",
       "      <th>k6a2</th>\n",
       "      <th>k11</th>\n",
       "      <th>k12</th>\n",
       "      <th>k9a1</th>\n",
       "      <th>k9a2</th>\n",
       "      <th>Energy_highest_max_normalized</th>\n",
       "      <th>Energy_all_max_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.748</td>\n",
       "      <td>[-0.758 -0.69  -0.612 -0.472 -0.406 -0.328 -0....</td>\n",
       "      <td>18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.874</td>\n",
       "      <td>[0.121 0.155 0.194 0.264 0.297 0.336 0.424 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.574</td>\n",
       "      <td>[-0.574 -0.048  0.034  0.596  0.658]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.213</td>\n",
       "      <td>[0.213 0.476 0.517 0.798 0.829]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.732</td>\n",
       "      <td>[-0.928 -0.776 -0.708 -0.628 -0.486 -0.422 -0....</td>\n",
       "      <td>19</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.866</td>\n",
       "      <td>[0.036 0.112 0.146 0.186 0.257 0.289 0.33  0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.734</td>\n",
       "      <td>[-0.926 -0.778 -0.712 -0.628 -0.486 -0.422 -0....</td>\n",
       "      <td>19</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.867</td>\n",
       "      <td>[0.037 0.111 0.144 0.186 0.257 0.289 0.33  0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.560</td>\n",
       "      <td>[-0.56  -0.03   0.046  0.614  0.674]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.220</td>\n",
       "      <td>[0.22  0.485 0.523 0.807 0.837]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0.736</td>\n",
       "      <td>[-0.774 -0.706 -0.612 -0.488 -0.424 -0.34  -0....</td>\n",
       "      <td>17</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.868</td>\n",
       "      <td>[0.113 0.147 0.194 0.256 0.288 0.33  0.415 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>0.730</td>\n",
       "      <td>[-0.922 -0.776 -0.702 -0.624 -0.49  -0.42  -0....</td>\n",
       "      <td>19</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.865</td>\n",
       "      <td>[0.039 0.112 0.149 0.188 0.255 0.29  0.413 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>-0.574</td>\n",
       "      <td>[-0.574 -0.046  0.036  0.594  0.66 ]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.213</td>\n",
       "      <td>[0.213 0.477 0.518 0.797 0.83 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>0.736</td>\n",
       "      <td>[-0.932 -0.772 -0.736 -0.628 -0.492 -0.424 -0....</td>\n",
       "      <td>20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.868</td>\n",
       "      <td>[0.034 0.114 0.132 0.186 0.254 0.288 0.331 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>-0.702</td>\n",
       "      <td>[-0.932 -0.774 -0.702 -0.628 -0.488 -0.424 -0....</td>\n",
       "      <td>21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.149</td>\n",
       "      <td>[0.034 0.113 0.149 0.186 0.256 0.288 0.329 0.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     main_maximum                                         all_maxima  \\\n",
       "0           0.748  [-0.758 -0.69  -0.612 -0.472 -0.406 -0.328 -0....   \n",
       "1          -0.574               [-0.574 -0.048  0.034  0.596  0.658]   \n",
       "2           0.732  [-0.928 -0.776 -0.708 -0.628 -0.486 -0.422 -0....   \n",
       "3           0.734  [-0.926 -0.778 -0.712 -0.628 -0.486 -0.422 -0....   \n",
       "4          -0.560               [-0.56  -0.03   0.046  0.614  0.674]   \n",
       "..            ...                                                ...   \n",
       "674         0.736  [-0.774 -0.706 -0.612 -0.488 -0.424 -0.34  -0....   \n",
       "675         0.730  [-0.922 -0.776 -0.702 -0.624 -0.49  -0.42  -0....   \n",
       "676        -0.574               [-0.574 -0.046  0.036  0.594  0.66 ]   \n",
       "677         0.736  [-0.932 -0.772 -0.736 -0.628 -0.492 -0.424 -0....   \n",
       "678        -0.702  [-0.932 -0.774 -0.702 -0.628 -0.488 -0.424 -0....   \n",
       "\n",
       "     no_of_max  k6a1  k6a2   k11   k12  k9a1  k9a2  \\\n",
       "0           18  0.25  0.25  0.25  0.25  0.25  0.25   \n",
       "1            5  0.25  0.25  0.25  0.25  0.25  0.50   \n",
       "2           19  0.25  0.25  0.25  0.25  0.25  0.75   \n",
       "3           19  0.25  0.25  0.25  0.25  0.50  0.25   \n",
       "4            5  0.25  0.25  0.25  0.25  0.50  0.50   \n",
       "..         ...   ...   ...   ...   ...   ...   ...   \n",
       "674         17  0.75  0.75  0.25  0.75  0.75  0.75   \n",
       "675         19  0.75  0.75  0.50  0.25  0.25  0.25   \n",
       "676          5  0.75  0.75  0.50  0.25  0.25  0.50   \n",
       "677         20  0.75  0.75  0.50  0.25  0.25  0.75   \n",
       "678         21  0.75  0.75  0.50  0.25  0.50  0.25   \n",
       "\n",
       "     Energy_highest_max_normalized  \\\n",
       "0                            0.874   \n",
       "1                            0.213   \n",
       "2                            0.866   \n",
       "3                            0.867   \n",
       "4                            0.220   \n",
       "..                             ...   \n",
       "674                          0.868   \n",
       "675                          0.865   \n",
       "676                          0.213   \n",
       "677                          0.868   \n",
       "678                          0.149   \n",
       "\n",
       "                             Energy_all_max_normalized  \n",
       "0    [0.121 0.155 0.194 0.264 0.297 0.336 0.424 0.4...  \n",
       "1                      [0.213 0.476 0.517 0.798 0.829]  \n",
       "2    [0.036 0.112 0.146 0.186 0.257 0.289 0.33  0.4...  \n",
       "3    [0.037 0.111 0.144 0.186 0.257 0.289 0.33  0.4...  \n",
       "4                      [0.22  0.485 0.523 0.807 0.837]  \n",
       "..                                                 ...  \n",
       "674  [0.113 0.147 0.194 0.256 0.288 0.33  0.415 0.4...  \n",
       "675  [0.039 0.112 0.149 0.188 0.255 0.29  0.413 0.4...  \n",
       "676                    [0.213 0.477 0.518 0.797 0.83 ]  \n",
       "677  [0.034 0.114 0.132 0.186 0.254 0.288 0.331 0.4...  \n",
       "678  [0.034 0.113 0.149 0.186 0.256 0.288 0.329 0.4...  \n",
       "\n",
       "[679 rows x 11 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spectra=pd.read_csv(\"spectrum_energy_input_numberOfPeaks.csv\",index_col=[0])\n",
    "x_data=np.asarray([df_spectra[\"no_of_max\"].values]).transpose()\n",
    "x_data_max=max(x_data)\n",
    "x_data=x_data/x_data_max\n",
    "#x_data=np.asarray([df_spectra[[\"no_of_max\",\"Energy_highest_max_normalized\"]].to_numpy()])[0]\n",
    "\n",
    "y_data=np.asarray([df_spectra[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]].to_numpy()])[0]\n",
    "df_spectra.head(-50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 6)\n",
      "(729, 1)\n",
      "[[0.25 0.25 0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25 0.25 0.5 ]\n",
      " [0.25 0.25 0.25 0.25 0.25 0.75]\n",
      " ...\n",
      " [0.75 0.75 0.75 0.75 0.75 0.25]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.5 ]\n",
      " [0.75 0.75 0.75 0.75 0.75 0.75]]\n"
     ]
    }
   ],
   "source": [
    "print(y_data.shape)\n",
    "\n",
    "print(x_data.shape)\n",
    "\n",
    "\n",
    "print(y_data)\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "le = MultiLabelBinarizer()\n",
    "le.fit(y_data)\n",
    "y_data_enc=le.transform(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#always seems to leave some values at zero\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    #model.add(Dense(25, activation='relu'))\n",
    "    #model.add(Dense(10, activation='relu'))\n",
    "    print(n_outputs)\n",
    "    model.add(Dense(n_outputs, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def get_model2(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=n_inputs, kernel_initializer='ones', activation='relu'))\n",
    "   # model.add(Dense(5, activation='sigmoid'))\n",
    "   # model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "    #model.add(Dense(10, activation='relu'))\n",
    "    print(n_outputs)\n",
    "    model.add(Dense(n_outputs, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(lr=1e-5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, epochs):\n",
    "    results = list()\n",
    "    n_inputs = X.shape[1]\n",
    "    print(n_inputs)\n",
    "    n_outputs = y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        \n",
    "       # print(X_train[0],y_train[0])\n",
    "        #print(len(X_train))\n",
    "        #print(X_train,y_train)\n",
    "        # define model\n",
    "        model = get_model2(n_inputs, n_outputs)\n",
    "        # fit model\n",
    "        #print(len(X_train))\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=epochs)\n",
    "        # make a prediction on the test set\n",
    "        yhat = model.predict(X_test)\n",
    "        # round probabilities to class labels\n",
    "        yhat = yhat\n",
    "        # calculate accuracy\n",
    "        \n",
    "        rse=model.evaluate(X_test,y_test)\n",
    "        \n",
    "        #print(y_test,yhat)\n",
    "        \n",
    "        \n",
    "        # store result\n",
    "        #print( rse)\n",
    "        results.append(rse)\n",
    "    \n",
    "    #y_predict1=[yhat[i][0] for i in range(len(yhat))]\n",
    "   # y_predict2=[yhat[i][1] for i in range(len(yhat))]\n",
    "   #y_test1=[y_test[i][0] for i in range(len(y_test))]\n",
    "   # y_test2=[y_test[i][1] for i in range(len(y_test))]\n",
    "   # print(y_test)\n",
    "   # print(yhat)\n",
    "   \n",
    "    \n",
    "    df_test=pd.DataFrame(y_test,columns=[\"k6a1_test\",\"k6a2_test\",\"k11_test\",\"k12_test\",\"k9a1_test\",\"k9a2_test\"])\n",
    "    df_hat=pd.DataFrame(yhat,columns=[\"k6a1_hat\",\"k6a2_hat\",\"k11_hat\",\"k12_hat\",\"k9a1_hat\",\"k9a2_hat\"])\n",
    "   # df_test=pd.DataFrame(y_test,columns=[\"NO_test\"])\n",
    "   # df_hat=pd.DataFrame(yhat,columns=[\"NO_hat\"])\n",
    "\n",
    "    return results,pd.concat([df_test,df_hat], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 60, 70, 80, 90, 100, 110, 120, 130, 140]\n",
      "1\n",
      "6\n",
      "12/12 [==============================] - 0s 417us/step - loss: 0.1243\n",
      "6\n",
      "12/12 [==============================] - 0s 417us/step - loss: 0.1677\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "epochs_list=[]\n",
    "complete_range=[]\n",
    "for i in range(50,150,10):\n",
    "    complete_range.append(i)\n",
    "\n",
    "\n",
    "print(complete_range)\n",
    "#for i in complete_range:#\n",
    "#    epochs_list.append(i)\n",
    "#    results.append( evaluate_model(x_data,y_data,epochs_list[-1])[0])\n",
    "\n",
    "results,compare =evaluate_model(x_data,y_data,7500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12430655211210251, 0.1676531881093979]\n",
      "Accuracy: 0.146 (0.022)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k6a1_test</th>\n",
       "      <th>k6a2_test</th>\n",
       "      <th>k11_test</th>\n",
       "      <th>k12_test</th>\n",
       "      <th>k9a1_test</th>\n",
       "      <th>k9a2_test</th>\n",
       "      <th>k6a1_hat</th>\n",
       "      <th>k6a2_hat</th>\n",
       "      <th>k11_hat</th>\n",
       "      <th>k12_hat</th>\n",
       "      <th>k9a1_hat</th>\n",
       "      <th>k9a2_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k6a1_test  k6a2_test  k11_test  k12_test  k9a1_test  k9a2_test  k6a1_hat  \\\n",
       "0       0.25       0.25      0.25      0.25       0.25       0.50       0.0   \n",
       "1       0.25       0.25      0.25      0.25       0.75       0.50       0.0   \n",
       "2       0.25       0.25      0.25      0.50       0.25       0.50       0.0   \n",
       "3       0.25       0.25      0.25      0.50       0.50       0.25       0.0   \n",
       "4       0.25       0.25      0.25      0.50       0.50       0.75       0.0   \n",
       "\n",
       "   k6a2_hat  k11_hat   k12_hat  k9a1_hat  k9a2_hat  \n",
       "0  0.492517      0.0  0.501101       0.0  0.506498  \n",
       "1  0.492517      0.0  0.501101       0.0  0.506498  \n",
       "2  0.490054      0.0  0.500998       0.0  0.503816  \n",
       "3  0.492517      0.0  0.501101       0.0  0.506498  \n",
       "4  0.492517      0.0  0.501101       0.0  0.506498  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results_avg=[ sum(res)/len(res) for res in results   ]\n",
    "\n",
    "print(results)\n",
    "#plt.plot(epochs_list,results_avg)\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(583, 6)\n"
     ]
    }
   ],
   "source": [
    "#Validation is now done in the .fit() function\n",
    "# testing data is now only used for final evaulation\n",
    "\n",
    "df_spectra_new=pd.read_csv(\"spectrum_energy_input_numberOfPeaks.csv\",index_col=[0])\n",
    "x_data_max_new=max(df_spectra_new[\"no_of_max\"])\n",
    "\n",
    "df_training = df_spectra_new.sample(frac=0.8,random_state=10)\n",
    "df_testing=df_spectra_new.drop(df_training.index)\n",
    "\n",
    "\n",
    "x_data_train=np.asarray([df_training[\"no_of_max\"].values]).transpose()\n",
    "x_data_train=x_data_train/x_data_max_new\n",
    "\n",
    "x_data_test=np.asarray([df_testing[\"no_of_max\"].values]).transpose()\n",
    "x_data_test=x_data_test/x_data_max_new\n",
    "\n",
    "y_data_train=np.asarray([df_training[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]].to_numpy()])[0]\n",
    "y_data_test=np.asarray([df_testing[[\"k6a1\",\"k6a2\",\"k11\",\"k12\",\"k9a1\",\"k9a2\"]].to_numpy()])[0]\n",
    "\n",
    "print(y_data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the plot_the_loss_curve function.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def plot_the_loss_curve(epochs, mse,val_mse):\n",
    "    \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "\n",
    "    plt.plot(epochs, mse, label=\"Loss\")\n",
    "    plt.plot(epochs, val_mse, label=\"Val Loss\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
    "    plt.show()  \n",
    "\n",
    "print(\"Defined the plot_the_loss_curve function.\")\n",
    "\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='linear'))\n",
    "    model.add(tf.keras.layers.Sum())\n",
    "   # model.add(Dense(500, activation='linear'))\n",
    "   # model.add(Dense(10, activation='linear'))\n",
    "   # print(n_outputs)\n",
    "    model.add(Dense(n_outputs, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, x_data,y_data, epochs, \n",
    "                batch_size=None):\n",
    "    \"\"\"Train the model by feeding it data.\"\"\"\n",
    "    \n",
    "    \n",
    "    history = model.fit(x=x_data, y=y_data, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, verbose=0,validation_split=0.2) \n",
    "    \n",
    "    epochs = history.epoch\n",
    "  \n",
    "    hist = pd.DataFrame(history.history)\n",
    "    #hist.head()\n",
    "    #mse = hist[\"mean_squared_error\"]\n",
    "    \n",
    "    return hist,epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.layers' has no attribute 'Sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-175-b1273bce1013>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmy_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_data_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m df_hist,epochs = train_model(my_model, x_data_train,y_data_train, epochs, \n\u001b[0;32m      5\u001b[0m                           batch_size)\n",
      "\u001b[1;32m<ipython-input-174-e98bf0c9fcae>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(n_inputs, n_outputs)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'he_uniform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m    \u001b[1;31m# model.add(Dense(500, activation='linear'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m    \u001b[1;31m# model.add(Dense(10, activation='linear'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras.layers' has no attribute 'Sum'"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "batch_size = 500\n",
    "my_model=get_model(x_data_train.shape[1],y_data_train.shape[1])\n",
    "df_hist,epochs = train_model(my_model, x_data_train,y_data_train, epochs, \n",
    "                          batch_size)\n",
    "\n",
    "df_hist.head()\n",
    "mse = df_hist[\"mean_squared_error\"].to_numpy()\n",
    "val_mse = df_hist[\"val_mean_squared_error\"].to_numpy()\n",
    "print(\"Final evaluation:\", mse[-1], val_mse[-1] )\n",
    "plot_the_loss_curve(epochs, mse,val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation=my_model.evaluate(x = x_data_test, y = y_data_test, batch_size=batch_size)\n",
    "predicted = my_model.predict(x_data_test)\n",
    "print(evaluation)\n",
    "\n",
    "df_test=pd.DataFrame(y_data_test,columns=[\"k6a1_test\",\"k6a2_test\",\"k11_test\",\"k12_test\",\"k9a1_test\",\"k9a2_test\"])\n",
    "df_predict=pd.DataFrame(predicted,columns=[\"k6a1_hat\",\"k6a2_hat\",\"k11_hat\",\"k12_hat\",\"k9a1_hat\",\"k9a2_hat\"])\n",
    "pd.concat([df_test,df_predict], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
